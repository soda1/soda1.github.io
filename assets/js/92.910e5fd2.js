(window.webpackJsonp=window.webpackJsonp||[]).push([[92],{452:function(s,t,a){"use strict";a.r(t);var n=a(4),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h4",{attrs:{id:"分区机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分区机制"}},[s._v("#")]),s._v(" 分区机制")]),s._v(" "),t("p",[s._v("分区的作用主要是为了提高负载均衡的能力，数据的读写都是在分区这个粒度上进行的，从而实现了系统的可伸缩性")]),s._v(" "),t("h5",{attrs:{id:"分区策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分区策略"}},[s._v("#")]),s._v(" 分区策略")]),s._v(" "),t("p",[s._v("分区策略决定者生产者将消息发送至哪个区，如果生产者要定义一个分区策略，要在客户端实现"),t("code",[s._v("org.apache.kafka.clients.producer.Partitioner")]),s._v("接口，常见分区策略如下：")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("轮询策略（ Round-robin）")]),s._v(" "),t("p",[s._v("Kafka默认策略，顺序分配，就是取余操作，$ partition_index = n % partition_num $，n表示第n条消息。轮询策略有着很好的负载均衡表现。")])]),s._v(" "),t("li",[t("p",[s._v("随机策略（Randomness）")]),s._v(" "),t("p",[s._v("随机返回一个partition")])]),s._v(" "),t("li",[t("p",[s._v("按消息键保序策略")]),s._v(" "),t("p",[s._v("Kafka允许为每条消息都定义一个消息键，可以通过对键进行hash从而保存到特定的partition中。这也是Kafka的默认策略之一，假设客户端没有自定义策略，如果是消息中带着Key，那么就会执行这个策略，否则就使用轮询策略")])])]),s._v(" "),t("p",[s._v("spring boot实现例子")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyPartitioner")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("implements")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Partitioner")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Override")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("partition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),s._v(" s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" o"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("byte")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" bytes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),s._v(" o1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("byte")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" bytes1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Cluster")]),s._v(" cluster"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("List")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PartitionInfo")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" partitionInfos "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cluster"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("availablePartitionsForTopic")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ThreadLocalRandom")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("current")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("nextInt")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("partitionInfos"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("size")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("num"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" num"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("p",[s._v("配置partitioner路径，这个在yml中没有找到属性，用代码来配置")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("    "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Bean")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("producerConfigs")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Object")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" props "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HashMap")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("BOOTSTRAP_SERVERS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"192.168.3.100:9092"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("KEY_SERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("IntegerSerializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("VALUE_SERIALIZER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("StringSerializer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerConfig")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("PARTITIONER_CLASS_CONFIG")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MyPartitioner")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// See https://kafka.apache.org/documentation/#producerconfigs for more properties")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" props"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Bean")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ProducerFactory")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("producerFactory")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("DefaultKafkaProducerFactory")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("producerConfigs")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@Bean")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaTemplate")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("kafkaTemplate")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("KafkaTemplate")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("producerFactory")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br")])]),t("h4",{attrs:{id:"消息解压缩"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息解压缩"}},[s._v("#")]),s._v(" 消息解压缩")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("Producer端压缩")]),s._v(" "),t("p",[s._v("Producer客户端开启压缩算法只要在"),t("code",[s._v("compression.type")]),s._v("配置指定的类型算法即可，在Producer端配置好处在于有利于网络传输")])]),s._v(" "),t("li",[t("p",[s._v("Broker端压缩")]),s._v(" "),t("p",[s._v("Broker也有可能会对消息进行压缩，有如下情况")]),s._v(" "),t("p",[s._v("情况1：Broker端和Producer端压缩算法不一致产生")]),s._v(" "),t("p",[s._v("情况2：因消息版本不同原因发生的兼容格式转换产生")])]),s._v(" "),t("li",[t("p",[s._v("Broker端解压")]),s._v(" "),t("p",[s._v("Broker端需要对接收到的消息进行验证，比如CRC校验，因此会解压消息")])]),s._v(" "),t("li",[t("p",[s._v("Consumer端解压")]),s._v(" "),t("p",[s._v("Consumer消费消息需要先解压还原消息")])])]),s._v(" "),t("p",[s._v("消息解压缩整个流程可以概况为一句话：Producer 端压缩、Broker 端保持、Consumer 端解压。")]),s._v(" "),t("p",[s._v("压缩算法比较")]),s._v(" "),t("p",[s._v("吞吐量：LZ4 > Snappy > zstd 和 GZIP")]),s._v(" "),t("p",[s._v("压缩比：zstd > LZ4 > GZIP > Snappy")]),s._v(" "),t("h4",{attrs:{id:"无消息丢失配置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#无消息丢失配置"}},[s._v("#")]),s._v(" 无消息丢失配置")]),s._v(" "),t("p",[s._v("Producer")]),s._v(" "),t("ul",[t("li",[s._v("Producer发送消息要使用带回调的send(msg, callback)")]),s._v(" "),t("li",[s._v("Producer设置acks=all，表示所有in-sync replicas都已经接收到消息了，消息才算发送成功")]),s._v(" "),t("li",[s._v("Producers设置retries，消息发送失败时应当重试多次，还不行再另作处理")])]),s._v(" "),t("p",[s._v("Broker端")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("unclean.leader.election.enable = false，落后太多的副本不应当竞选leader")])]),s._v(" "),t("li",[t("p",[s._v("replication.factor >= 3，将副本多保存几份")])]),s._v(" "),t("li",[t("p",[s._v("min.insync.replicas > 1，这个配置是保证当Producer的ack=all时，Broker端至少存在多少个in-sync replicas才能进行写入。可参考"),t("a",{attrs:{href:"https://accu.org/journals/overload/28/159/kozlovski/",title:"Kafka Acks Explained",target:"_blank",rel:"noopener noreferrer"}},[s._v("文章"),t("OutboundLink")],1),s._v("。")])])]),s._v(" "),t("p",[s._v("要配置replication.factor > min.insync.replicas，否则一个副本挂了分区就不可用了。推荐成replication.factor = min.insync.replicas + 1")]),s._v(" "),t("p",[s._v("Consumer")]),s._v(" "),t("ul",[t("li",[s._v("enable.auto.commit设置为false，改为手动提交，并采用手动提交位移")])]),s._v(" "),t("h4",{attrs:{id:"拦截器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#拦截器"}},[s._v("#")]),s._v(" 拦截器")]),s._v(" "),t("p",[s._v("todo")]),s._v(" "),t("h4",{attrs:{id:"producer一次发送流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#producer一次发送流程"}},[s._v("#")]),s._v(" Producer一次发送流程")]),s._v(" "),t("p",[s._v("步骤如下：")]),s._v(" "),t("ol",[t("li",[s._v("构造生产者对象所需的参数对象")]),s._v(" "),t("li",[s._v("根据参数创建KafkaProducer对象实例")]),s._v(" "),t("li",[s._v("调用send方法发送消息")]),s._v(" "),t("li",[s._v("调用close方法释放资源")])]),s._v(" "),t("p",[s._v("深入：")]),s._v(" "),t("ol",[t("li",[s._v("在创建KafkaProducer对象时后台会创建一个名为Seeder的线程，该线程会与 bootstrap.servers配置的所有Broker进行Tcp连接，用于获取集群元数据信息。")]),s._v(" "),t("li",[s._v("Producer会通过metadata.max.age.ms 参数来定期地去更新元数据信息，默认时5分钟。")]),s._v(" "),t("li",[s._v("在发送消息时，Producer会从元数据缓存中找到需要发送的Broker信息，建立Tcp连接来发送信息")])]),s._v(" "),t("h4",{attrs:{id:"message-delivery-semantics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#message-delivery-semantics"}},[s._v("#")]),s._v(" Message Delivery Semantics")]),s._v(" "),t("p",[s._v("有如下三种语义保证：")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("最多一次（at most once）：消息可能会丢失，但绝不会被重复发送")])]),s._v(" "),t("li",[t("p",[s._v("至少一次（at least once）：消息不会丢失，但有可能被重复发送")])]),s._v(" "),t("li",[t("p",[s._v("精确一次（exactly once）：消息不会丢失，也不会被重复发送")])])]),s._v(" "),t("p",[s._v("Kafka默认提供at least once的可靠性保证，提供了重试的机制。")]),s._v(" "),t("h5",{attrs:{id:"kafka如何保证exactly-once"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka如何保证exactly-once"}},[s._v("#")]),s._v(" Kafka如何保证exactly once")]),s._v(" "),t("h6",{attrs:{id:"幂等性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#幂等性"}},[s._v("#")]),s._v(" 幂等性")]),s._v(" "),t("p",[s._v("在0.11版本开始支持，Broker给每个Producer分配一个ID，且Producer的每条信息都会有一个序列号用来去重信息。可以通过指定"),t("code",[s._v("enable.idempotence=true")]),s._v("来配置幂等Producer")]),s._v(" "),t("p",[s._v("Kafka只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区 上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不 能实现跨会话的幂等性。这里的会话，你可以理解为 Producer 进程的一次运行。当你重启了 Producer 进程之后，这种幂等性保证就丧失了。")]),s._v(" "),t("h6",{attrs:{id:"事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#事务"}},[s._v("#")]),s._v(" 事务")]),s._v(" "),t("p",[s._v("从0.11版本开始支持，通过"),t("code",[s._v("置 isolation.level")]),s._v("来设置事务级别，有以下参数")]),s._v(" "),t("ul",[t("li",[s._v("read_uncommitted：默认值，表明Consumer可以读取事务型Producer写入的任何消息")]),s._v(" "),t("li",[s._v("read_committed：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消 息")])]),s._v(" "),t("p",[s._v("事务型Producer通过流程代码控制，类似mysql那样(begin, commit)")]),s._v(" "),t("p",[s._v("事务可以保证跨分区，跨会话的幂等。")]),s._v(" "),t("h4",{attrs:{id:"消费机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消费机制"}},[s._v("#")]),s._v(" 消费机制")]),s._v(" "),t("h5",{attrs:{id:"consumer-group"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consumer-group"}},[s._v("#")]),s._v(" Consumer Group")]),s._v(" "),t("p",[s._v("Consumer Group 是 Kafka 提供的可扩展且具 有容错性的消费者机制。每个组都有一个Group ID， 组内存在多个消费实例共同消费Topic所有的Partition，"),t("strong",[s._v("一个Partition只能被分配给组内一个Consumer消费")]),s._v("。")]),s._v(" "),t("h6",{attrs:{id:"实现两大模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实现两大模型"}},[s._v("#")]),s._v(" 实现两大模型")]),s._v(" "),t("p",[s._v("Consumer Group是Kafka实现两个模型的机制")]),s._v(" "),t("ul",[t("li",[s._v("只有一个组进行消费Topic，那么就是队列模型")]),s._v(" "),t("li",[s._v("多个组消费Topic，那么就是发布/订阅模型")])]),s._v(" "),t("h5",{attrs:{id:"standalone-consumer"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#standalone-consumer"}},[s._v("#")]),s._v(" Standalone Consumer")]),s._v(" "),t("p",[s._v("相当于只有一个Consumer的消费组，也需要Group ID标识")]),s._v(" "),t("h5",{attrs:{id:"consumer-offsets"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consumer-offsets"}},[s._v("#")]),s._v(" _consumer_offsets")]),s._v(" "),t("p",[s._v("_consumer_offsets是Kafka内部Topic，它的主要作用就是为了保持Consumer消费的位移信息，它是一个普通的Topic，可以对它进行操作，但请不要这么做")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("创建时机")]),s._v(" "),t("p",[s._v("当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题，默认分区数是50，副本数3。可以通过"),t("code",[s._v("offsets.topic.num.partitions")]),s._v("、"),t("code",[s._v("offsets.topic.replication.factor")]),s._v("配置，但不建议")])]),s._v(" "),t("li",[t("p",[s._v("消息格式")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("位移信息格式")]),s._v(" "),t("p",[s._v("保存的消息格式是KV对，Key用<Group ID, Topic, Partition>来标识， Value保存位移值")])]),s._v(" "),t("li",[t("p",[s._v("保存 Consumer Group 信息的消息")]),s._v(" "),t("p",[s._v("用于注册Consumer Group")])]),s._v(" "),t("li",[t("p",[s._v("tombstone消息")]),s._v(" "),t("p",[s._v("删除 Group 过期位移甚至是删除 Group 的消息")])])])]),s._v(" "),t("li",[t("p",[s._v("Group数据保存在哪个区？")]),s._v(" "),t("p"),t("p",[t("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML",display:"true"}},[t("mjx-math",{staticClass:"MJX-TEX",attrs:{display:"true"}},[t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"p"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"a"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"r"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"t"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"i"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"t"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"i"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"n"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"I"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"d"}})],1),t("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"="}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[t("mjx-c",{attrs:{c:"M"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"a"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"t"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"h"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"."}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"a"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"b"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"s"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"g"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"r"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"u"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"p"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"I"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"d"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"."}})],1),t("mjx-mi",{staticClass:"mjx-i",attrs:{space:"2"}},[t("mjx-c",{attrs:{c:"h"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"a"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"s"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"h"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"d"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"e"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"("}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1),t("mjx-mi",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:"%"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"f"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"f"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"s"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"e"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"t"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"s"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"T"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"p"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"i"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"c"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"P"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"a"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"r"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"t"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"i"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"t"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"i"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"n"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"C"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"o"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"u"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"n"}})],1),t("mjx-mi",{staticClass:"mjx-i"},[t("mjx-c",{attrs:{c:"t"}})],1),t("mjx-mo",{staticClass:"mjx-n"},[t("mjx-c",{attrs:{c:")"}})],1)],1)],1)],1),t("p")]),s._v(" "),t("li",[t("p",[s._v("Compact 策略")]),s._v(" "),t("p",[s._v("Kafka 使用Compact 策略来删除位移主题中的过期消息，避免该主题无限期 膨胀。过期定义：对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志 的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。")]),s._v(" "),t("p",[s._v("Kafka 提供了专门的后台线程（ Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删 除数据")])])]),s._v(" "),t("h5",{attrs:{id:"coordinator组件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#coordinator组件"}},[s._v("#")]),s._v(" Coordinator组件")]),s._v(" "),t("p",[s._v("每个Broker都有各自的Coordinator组件，它是专门为Consumer Group服务的，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理")]),s._v(" "),t("p",[s._v("如何知道Group被哪个Coordinator管理？")]),s._v(" "),t("ol",[t("li",[s._v("确定由的哪个_consumer_offsets分区来保存该 Group 数据（_consumer_offsets保存算法）")]),s._v(" "),t("li",[s._v("找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。")])]),s._v(" "),t("h5",{attrs:{id:"rebalance"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rebalance"}},[s._v("#")]),s._v(" Rebalance")]),s._v(" "),t("p",[s._v("Kafka对Consumer Group重新分配Partition的过程称为Rebalance。Rebalance 发生时，Group 下所有的 Consumer 实例都会协调在一起共同参与，在协调者组件的帮助下，完成订阅主题分区的分配")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("何时触发？")]),s._v(" "),t("ul",[t("li",[s._v("组成员数改变")]),s._v(" "),t("li",[s._v("订阅主题数改变")]),s._v(" "),t("li",[s._v("订阅主题分区数改变")])])]),s._v(" "),t("li",[t("p",[s._v("产生影响")]),s._v(" "),t("p",[s._v("在Rebalance过程中，所有的Consumer都会停止消费，如果有Consumer正在消费消息的话，将会导致消息重复消费问题")])]),s._v(" "),t("li",[t("p",[s._v("Coordinator如何判断Consumer实例退组")]),s._v(" "),t("p",[s._v("心跳机制，每个Consumer都会定期的向Coordinator发送心跳，如果不能及时发送心跳，那么Coordinator就会认为该Consumer退组，进而开始Rebalance。")]),s._v(" "),t("p",[s._v("Consumer端相关参数")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("heartbeat.interval.ms")]),s._v("：心跳请求频率参数")]),s._v(" "),t("li",[t("code",[s._v("max.poll.interval.ms")]),s._v("： 两次调 用 poll 方法的最大时间间隔。它的默认值是 5 分钟。在两次调用poll的间隔间，业务逻辑处理时间过长，超出配置值，那么Consumer就会自动退组")]),s._v(" "),t("li",[t("code",[s._v("session.timout.ms")]),s._v("：存活时间间隔，默认10s。表明如果10s内没有任何心跳请求，Coordinator就判断Consumer已经退出")])]),s._v(" "),t("p",[s._v("推荐配置：")]),s._v(" "),t("p",[t("code",[s._v("session.timeout.ms = 6s")])]),s._v(" "),t("p",[t("code",[s._v("heartbeat.interval.ms = 2s")])]),s._v(" "),t("p",[t("code",[s._v("max.poll.interval.ms")]),s._v("设置为业务逻辑处理最长时间")])])]),s._v(" "),t("h6",{attrs:{id:"rebalance要点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rebalance要点"}},[s._v("#")]),s._v(" Rebalance要点")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("通知机制")]),s._v(" "),t("p",[s._v("当发生Rebalance时，Coordinator将”REBALANCE_IN_PROGRESS“封装进心跳请求响应里面，Consumer也因此知道了重平衡马上就要开始了")])]),s._v(" "),t("li",[t("p",[s._v("Consumer Group状态机")]),s._v(" "),t("p",[s._v("Kafka为消费组定义了5种状态")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230303190703.png",alt:""}})]),s._v(" "),t("p",[s._v("状态机流转如下")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230303190823.png",alt:""}})]),s._v(" "),t("p",[s._v("一个消费者组最开始是 Empty 状态，当重平衡过程开启后，它会被置于 PreparingRebalance 状态等待成员加入，之后变更到 CompletingRebalance 状态等待分配方案，最后流转到 Stable 状态完成重平衡")]),s._v(" "),t("p",[s._v("如果组在Empty状态下的存在很长时间（整个组停掉长时间不在消费），位移数据可能会被删除")])])]),s._v(" "),t("h6",{attrs:{id:"consumer重平衡步骤"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consumer重平衡步骤"}},[s._v("#")]),s._v(" Consumer重平衡步骤")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("加入组（JoinGroup请求）")]),s._v(" "),t("p",[s._v("每个组员都会将自己订阅信息上报，Coordinator会从组员中选出Leader Consumer，一般的第一个请求者。选举完后会将所有的订阅信息发送的Leaders Consumer，由其制定分配")])]),s._v(" "),t("li",[t("p",[s._v("等待Leader Consumers分配方案（SyncGroup请求）")]),s._v(" "),t("p",[s._v("Leaders Consumer完成分配方案后向Coordinate发送SyncGroup请求，同时其他组员也会发送SyncGroup请求，但没有实际内容。最后统一以响应的方式分发给所有组员")])])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230303192421.png",alt:""}})]),s._v(" "),t("center",[s._v("JoinGroup请求")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230303192537.png",alt:""}})]),s._v(" "),t("center",[s._v("SyncGroup请求")]),s._v(" "),t("h5",{attrs:{id:"位移提交"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#位移提交"}},[s._v("#")]),s._v(" 位移提交")]),s._v(" "),t("p",[t("strong",[s._v("Consumer需要为分配给它的每个分区提交各自的位移数据")]),s._v("，用来表示消费进度。比如提交位移进度X表示X以下都已经被消费")]),s._v(" "),t("p",[s._v("提交方式：")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("自动提交")]),s._v(" "),t("p",[s._v("自动提交保证at least one，这就意味着可能存在消息重复消费，比如Consumer 正在消费时宕机了，产生了Rebalance，分配完后其他Consumer会从它消费的所有Partition的最近一次提交位移处开始消费，从而导致重复消费")]),s._v(" "),t("blockquote",[t("p",[s._v("By default, the consumer is configured to auto-commit offsets. Using auto-commit gives you “at least once” delivery: Kafka guarantees that no messages will be missed, but duplicates are possible. Auto-commit basically works as a cron with a period set through the "),t("code",[s._v("auto.commit.interval.ms")]),s._v(" configuration property. If the consumer crashes, then after a restart or a rebalance, the position of all partitions owned by the crashed consumer will be reset to the last committed offset. When this happens, the last committed position may be as old as the auto-commit interval itself. Any messages which have arrived since the last commit will have to be read again. "),t("a",{attrs:{href:"https://docs.confluent.io/platform/current/clients/consumer.html#ak-consumer-configuration",target:"_blank",rel:"noopener noreferrer"}},[s._v("consumer doc"),t("OutboundLink")],1)])]),s._v(" "),t("p",[s._v("通过"),t("code",[s._v("enable.auto.commit")]),s._v("设置是否开启，默认是开启的")]),s._v(" "),t("p",[t("code",[s._v("auto.commit.interval.ms")]),s._v("表示自动提交间隔，默认值为5s")]),s._v(" "),t("p",[s._v("自动提交逻辑是在poll方法里面执行的，每次poll的时候都会判断是否需要自动提交，大概逻辑如下")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("第一次poll\t\t设置提交时间为5s后\n\t+10s \n第二次poll\t\t两次poll间隔为10s，比5s大就自动提交，然后设置下次提交时间为15s\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])])]),s._v(" "),t("li",[t("p",[s._v("手动提交")]),s._v(" "),t("p",[s._v("将"),t("code",[s._v("enable.auto.commit")]),s._v("设置为false即可，Kafka提供同步和异步提交两种方式")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("同步提交")]),s._v(" "),t("p",[s._v("使用KafkaConsumer#commitSync方法，提供重试机制，同步提交会影响TPS")])]),s._v(" "),t("li",[t("p",[s._v("异步提交")]),s._v(" "),t("p",[s._v("使用 KafkaConsumer#commitAsync()方法，没有重试机制，异步方式重试机制是没有意义的")]),s._v(" "),t("p",[s._v("异步提交可能会导致消息丢失，Kafka提供回调函数，可以通过回调函数时进行失败逻辑处理")])])]),s._v(" "),t("p",[s._v("将同步提交和异步提交结合")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    \t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecords")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" records "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" \n    \tconsumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("poll")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Duration")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("ofSeconds")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n     \t"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("process")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("records"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 处理消息")]),s._v("\n \t\t"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("commitAysnc")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 使用异步提交规避阻塞")]),s._v("\n \t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("catch")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Exception")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n \t"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("handle")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 处理异常")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("finally")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n \t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n \t\tconsumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("commitSync")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 最后一次提交使用同步阻塞式提交")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("finally")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n \t\tconsumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("close")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br")])]),t("p",[s._v("也可以使用"),t("code",[s._v("commitSync(final Map<TopicPartition, OffsetAndMetadata> offsets)")]),s._v("及"),t("code",[s._v("commitAsync(final Map<TopicPartition, OffsetAndMetadata> offsets, OffsetCommitCallback callback)")]),s._v("进行小批量提交，比如每消费一百条提交一次")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("private")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OffsetAndMetadata")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" offsets "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HashMap")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" count "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n……\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n \t"),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecords")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" records "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" consumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("poll")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Duration")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("ofSeconds")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n \t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ConsumerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" records"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n \t\t"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("process")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 处理消息")]),s._v("\n \t\toffsets"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TopicPartition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("topic")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("partition")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n \t\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("OffsetAndMetadata")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("offset")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("；\n \t\t"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v("（count "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("）\n \t\t\tconsumer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("commitAsync")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("offsets"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 回调处理逻辑是 n")]),s._v("\n \t\tcount"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br")])])])]),s._v(" "),t("p",[s._v("自动提交和手动提交都无法避免消息重复消息问题，需要在业务上做去重")]),s._v(" "),t("h5",{attrs:{id:"consumer建立tcp连接种类"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consumer建立tcp连接种类"}},[s._v("#")]),s._v(" Consumer建立TCP连接种类")]),s._v(" "),t("p",[s._v("有3类TCP连接")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("发起 FindCoordinator 请求时（第一类）")]),s._v(" "),t("p",[s._v("创建TCP连接，发送FindCoordinator请求到"),t("code",[s._v("bootstrap.servers")]),s._v("的任意服务器，得到管理它的Broker元数据")])]),s._v(" "),t("li",[t("p",[s._v("连接Coordinator（第二类）")]),s._v(" "),t("p",[s._v("创建与Coordinator的TCP连接，这样才能开启组协调操作")])]),s._v(" "),t("li",[t("p",[s._v("消费消息时（第三类）")]),s._v(" "),t("p",[s._v("Consumer为每个要消费的分区创建于该分区领导者副本所在的Broker连接的TCP")])])]),s._v(" "),t("p",[s._v("当第三类连接建立时，Consumer会kill掉第一类TCP连接")]),s._v(" "),t("h5",{attrs:{id:"消费进度监控"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消费进度监控"}},[s._v("#")]),s._v(" 消费进度监控")]),s._v(" "),t("ul",[t("li",[s._v("Lag：表示消费消息落后生产消息程度，比如产生了100万条消息，当前消费了80万条，那么消息滞后了20万条，即Lag=20w")]),s._v(" "),t("li",[s._v("Lead：表示最新消费消息的位移和分区第一条位移的差值，比如当前消费位移为5，第一条位移为0，那么Lead=5")])]),s._v(" "),t("p",[s._v("使用JMX监控")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230303160430.png",alt:"image-20230303160423390"}})]),s._v(" "),t("h4",{attrs:{id:"副本机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#副本机制"}},[s._v("#")]),s._v(" 副本机制")]),s._v(" "),t("p",[s._v("Kafka采用了基于领导者的（Leader-based）的副本机制。")]),s._v(" "),t("ol",[t("li",[s._v("副本分为Leader和Follower副本，Follower会自动追随Leader")]),s._v(" "),t("li",[s._v("只有Leader对外提供服务，Follower从Leader异步拉取消息")]),s._v(" "),t("li",[s._v("如果Leader挂了，Kafka会进行重新选举")])]),s._v(" "),t("h5",{attrs:{id:"in-sync-replicas-isr"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#in-sync-replicas-isr"}},[s._v("#")]),s._v(" In-sync Replicas（ISR）")]),s._v(" "),t("p",[s._v("与Leader保持同步的副本称为ISR，是否保持同步的标准就是Broker 端参数 "),t("code",[s._v("replica.lag.time.max.ms")]),s._v("参数值，默认10s。它表示的是Follower能够落后Leader的最长时间")]),s._v(" "),t("p",[s._v("Kafka在启动时会开启两个任务，一是定期检查是否需要缩减或扩大ISR集合，周期是"),t("code",[s._v("是replica.lag.time.max.ms")]),s._v("一半；二是定期检查isrChangeSet（缓存ISR变更记录集合），如果Set有变更记录，那么会在zk中持久化一个节点 。controller节点注册的watcher能感知到ISR的变化然后向它所管理的Broker节点发送更新元数据请求，最后删除处理过的节点")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("踢出ISR")]),s._v(" "),t("p",[s._v("如果Follower在超出了"),t("code",[s._v("replica.lag.time.max.ms")]),s._v("时间后还出于落后状态，那就会被踢出ISR。")])]),s._v(" "),t("li",[t("p",[s._v("进入ISR")]),s._v(" "),t("p",[s._v("当检查到Follower的High Watermark追赶上Leader时就扩充ISR")])])]),s._v(" "),t("h5",{attrs:{id:"unclean-leader-election"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#unclean-leader-election"}},[s._v("#")]),s._v(" Unclean Leader Election")]),s._v(" "),t("p",[s._v("Unclean Leader Election指的是当ISR为空（Leader也不在了）时，是否允许Kafka在非同步副本中选举新的Leader，如果不允许，那么分区就失效了。")]),s._v(" "),t("p",[s._v("通过Broker 端参数 "),t("code",[s._v("unclean.leader.election.enable")]),s._v("控制是否开启")]),s._v(" "),t("p",[s._v("开启选项可能会造成数据丢夫，好处在于提高了可用性")]),s._v(" "),t("h5",{attrs:{id:"high-watermark-hw"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#high-watermark-hw"}},[s._v("#")]),s._v(" High Watermark(HW)")]),s._v(" "),t("p",[s._v("Kafka用High Watermark来表征消息位移，有以下作用")]),s._v(" "),t("ul",[t("li",[s._v("定义消息可见性，即分区哪些消息可被消费")]),s._v(" "),t("li",[s._v("帮助Kafka完成副本同步")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230305165243.png",alt:""}})]),s._v(" "),t("p",[s._v("同一个副本对象，其高 水位值不会大于 LEO（Log End Offset) 值")]),s._v(" "),t("h6",{attrs:{id:"更新机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#更新机制"}},[s._v("#")]),s._v(" 更新机制")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230305165811.png",alt:""}})]),s._v(" "),t("p",[s._v("每个副本都会保存HW和LEO两个属性，而Leader所在的Broker也会保存所有Follower的副本，用于帮助Leader确定其HW。")]),s._v(" "),t("p",[t("strong",[s._v("Leader下更新逻辑")])]),s._v(" "),t("p",[s._v("处理Producer消息")]),s._v(" "),t("ol",[t("li",[s._v("消息写入磁盘")]),s._v(" "),t("li",[s._v("更新分区HW\n"),t("ol",[t("li",[s._v("获取Leader所在Broker保存的Followers的LEO值{LEO-1，LEO-2...}")]),s._v(" "),t("li",[s._v("更新HW=min(leader-LEO, LEO-1, LEO-2.....)")])])])]),s._v(" "),t("p",[s._v("处理Follower拉取消息")]),s._v(" "),t("ol",[t("li",[s._v("根据Follower发送来的LEO读取消息数据")]),s._v(" "),t("li",[s._v("将Follower发送来的LEO更新到Broker保存的对应副本中")]),s._v(" "),t("li",[s._v("更新分区HW（同上）")])]),s._v(" "),t("p",[t("strong",[s._v("Follower下更新逻辑")])]),s._v(" "),t("p",[s._v("从Leader处拉取消息：")]),s._v(" "),t("ol",[t("li",[s._v("将消息写入磁盘")]),s._v(" "),t("li",[s._v("更新LEO")]),s._v(" "),t("li",[s._v("更新HW\n"),t("ol",[t("li",[s._v("获取Leader发送来的leader-LEO")]),s._v(" "),t("li",[s._v("获取更新过的currentLEO")]),s._v(" "),t("li",[s._v("更新高水位为min(leader-LEO, currentLEO)")])])])]),s._v(" "),t("p",[t("strong",[s._v("更新存在问题")])]),s._v(" "),t("p",[s._v("HW的更新通常需要额外一轮的拉取请求才能完成，容易引发以下问题")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("备份数据丢失")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230305172705.png",alt:""}})]),s._v(" "),t("p",[s._v("如图所示，当A更新完HW后，B还未来得及更新就宕机了，重启后HW还是为1，此时向A发送Fetch请求，如果A恰好又宕机了，那么B就会成为Leader，后面A重启后向B发送Fetch请求，HW将更新为1，从而丢失数据")])]),s._v(" "),t("li",[t("p",[s._v("备份数据不一致")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230305235446.png",alt:""}})]),s._v(" "),t("p",[s._v("如图所示，当A的HW=2 和B的HW=1时同时发生了宕机，B重启后成为了Leader，此时Producer发送了消息给B，B就会覆盖消息2且HW也会更新为2，后面A重启回来会执行日志截断，但发现分区的HW和自己的HW都是2，故不作任何调整，从而引起数据不一致")]),s._v(" "),t("p",[t("strong",[s._v("leader epoch")])]),s._v(" "),t("p",[s._v("Kafka从0.11引入leader epoch，从而规避以上问题。leader epoch实际是一对值（epoch， offset），epoch表示版本号，从0开始，每当leader角色发生变更就+1，offset表示写入该epoch的第一条消息位移。")]),s._v(" "),t("p",[s._v("Kafka Broker 会在内存中为每个分区都缓存  epoch 数据，同时它还将这些 信息持久化到一个 checkpoint 文件中。如果Leader 是首次写入消息，那么Broker会向缓存中增加一个 epoch 条目，否则就不做更新。")]),s._v(" "),t("p",[s._v("解决数据丢失")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230306010801.png",alt:""}})]),s._v(" "),t("p",[s._v("副本B重启后向A发送LeaderEpochRequest获取A的LEO值，发现A的LEO不比自己的小，且epoch中的offset也没有比2大，因此无需执行任何日志截断")]),s._v(" "),t("p",[s._v("当B成为Leader时,[epoch = 1, offset = 3],A重启后会向B发送LeaderEpochRequest去获取Leader的LEO值，发现其LEO比B的小且epoch中的offset也没有比3大，因此也无需截断")]),s._v(" "),t("p",[s._v("注意只有Follower才会执行日志截断，Leader是不会执行日志截断的")])])]),s._v(" "),t("h4",{attrs:{id:"broker"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#broker"}},[s._v("#")]),s._v(" Broker")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230306151424.png",alt:""}})]),s._v(" "),t("p",[s._v("todo：外网暂未找到相关资料")]),s._v(" "),t("h5",{attrs:{id:"broker网络模型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#broker网络模型"}},[s._v("#")]),s._v(" Broker网络模型")]),s._v(" "),t("p",[s._v("Broker网络层采用了Reactor模式，有个核心组件SocketServer，线程模型如下：")]),s._v(" "),t("ul",[t("li",[s._v("一个Acceptor线程接收请求")]),s._v(" "),t("li",[s._v("N个Processor线程,每个Processor都有自己的selector,从每个连接中读取请求")]),s._v(" "),t("li",[s._v("M个Handler线程处理请求,并将产生的请求返回给Processor线程用于写回客户端")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230303184103.png",alt:""}})]),s._v(" "),t("h4",{attrs:{id:"controller"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#controller"}},[s._v("#")]),s._v(" Controller")]),s._v(" "),t("p",[s._v("控制器组件（Controller）是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。Kafka集群通过选举选出Controller。JMX指标为"),t("code",[s._v("activeController")])]),s._v(" "),t("h5",{attrs:{id:"作用"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#作用"}},[s._v("#")]),s._v(" 作用")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("主题管理（创建、删除、增加分区）")])]),s._v(" "),t("li",[t("p",[s._v("分区重分配")])]),s._v(" "),t("li",[t("p",[s._v(".Preferred 领导者选举")]),s._v(" "),t("p",[s._v("Preferred选举是Kafka为了避免部分Broker负载过重而提供的一种换Leader方案")])]),s._v(" "),t("li",[t("p",[s._v("集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）")])]),s._v(" "),t("li",[t("p",[s._v("数据服务（集群元数据信息）")]),s._v(" "),t("p",[s._v("Controller会有整个集群最完整的元数据信息，Zookeeper也会保存一份，Controller的初始化元数据信息由Zookeeper提供")])])]),s._v(" "),t("h5",{attrs:{id:"如何选举"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何选举"}},[s._v("#")]),s._v(" 如何选举")]),s._v(" "),t("p",[s._v("当Broker启动时，会尝试在Zookeeper中/controller节点，第一个创建成功的Broker会被选举为Controller")]),s._v(" "),t("h5",{attrs:{id:"失效处理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#失效处理"}},[s._v("#")]),s._v(" 失效处理")]),s._v(" "),t("p",[s._v("当Controller所在的Broker出现异常退出了集群，Zookeeper通过Watch机制感应并将/controller节点删除，之后存活的Broker会开始进行选举，选举成功的Broker会从Zookeeper中读取元数据信息，进行初始化。")]),s._v(" "),t("h5",{attrs:{id:"内部设计结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#内部设计结构"}},[s._v("#")]),s._v(" 内部设计结构")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/soda1/img/main/20230304145246.png",alt:""}})]),s._v(" "),t("h4",{attrs:{id:"动态broker参数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#动态broker参数"}},[s._v("#")]),s._v(" 动态Broker参数")]),s._v(" "),t("p",[s._v("从1.1版本开始， Brokers Configs增加Update Model列，有三类值")]),s._v(" "),t("ul",[t("li",[s._v("read-olny：表示修改只能重启Broker后才能生效")]),s._v(" "),t("li",[s._v("per-broker: 属于动态参数，修改后只在对应Broker上生效")]),s._v(" "),t("li",[s._v("cluster-wide：属于动态参数，修改后整个集群生效")])]),s._v(" "),t("p",[t("s",[s._v("优先级别： per-broker > cluster-wide > read-only> Kafka默认值")])]),s._v(" "),t("p",[t("strong",[s._v("使用场景")])]),s._v(" "),t("ul",[t("li",[s._v("动态调整 Broker 端各种线程池大小，实时应对突发流量")]),s._v(" "),t("li",[s._v("动态调整 Broker 端连接信息或安全配置信息")]),s._v(" "),t("li",[s._v("动态更新 SSL Keystore 有效期")]),s._v(" "),t("li",[s._v("动态调整 Broker 端 Compact 操作性能")]),s._v(" "),t("li",[s._v("实时变更 JMX 指标收集器 (JMX Metrics Reporter)")])]),s._v(" "),t("p",[t("strong",[s._v("如何配置")])]),s._v(" "),t("p",[s._v("使用kafka-config.sh")]),s._v(" "),t("h4",{attrs:{id:"重设消费组位移"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#重设消费组位移"}},[s._v("#")]),s._v(" 重设消费组位移")]),s._v(" "),t("p",[t("strong",[s._v("策略")])]),s._v(" "),t("ul",[t("li",[s._v("Earliest：把位移调整到当前最早位移处")]),s._v(" "),t("li",[s._v("Latest：把位移调整到当前最新位移处")]),s._v(" "),t("li",[s._v("Current：把位移调整到当前最新提交位移处")]),s._v(" "),t("li",[s._v("Specified-Offset：把位移调整到指定位移处")]),s._v(" "),t("li",[s._v("Shift-By-N：把位移调整到当前位移 +N处（N可为负值）")]),s._v(" "),t("li",[s._v("DateTime：把位移调整到大于给定时间的最小位移处")]),s._v(" "),t("li",[s._v("Duration：把位移调整到距离当前时间指定间隔位移处")])]),s._v(" "),t("p",[t("strong",[s._v("方法")])]),s._v(" "),t("ul",[t("li",[s._v("通过Java API重设位移：调用KafkaConsumer的seek方法，或者它的变种方法seekToBeginning和seekToEnd")]),s._v(" "),t("li",[s._v("用脚本kafka-consumer-groups脚本")])]),s._v(" "),t("h4",{attrs:{id:"脚本工具"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#脚本工具"}},[s._v("#")]),s._v(" 脚本工具")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("kafka-acls：设置Kafka权限")])]),s._v(" "),t("li",[t("p",[s._v("kafka-broker-api-versions：验证不同Kafka版本直接服务器与客户端的适配性")])]),s._v(" "),t("li",[t("p",[s._v("kafka-config：动态参数配置")])]),s._v(" "),t("li",[t("p",[s._v("kafka-console-consumer：消费组脚本")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" test-topic "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--group")]),s._v(" test-group --from-beginning --consumer-property "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("enable.auto.commit")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("false \n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#指定了 group 信息。如果没有指定的话，每次运行 Console Consumer，它都会自动生成一个新的消费者组来消费")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])])]),s._v(" "),t("li",[t("p",[s._v("kafka-console-producer：生产者脚本")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("bin/kafka-console-producer.sh --broker-list kafka-host:port "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" test-topic --request-required-acks "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-1")]),s._v(" --producer-property "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("compression.type")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("lz4\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])])])]),s._v(" "),t("p",[s._v("#指定生产者参数 acks 为 -1，同时启用了 LZ4 的压缩算法。这个脚本可以很方便地让我们使用控制台来向 Kafka 的指定主题发送消息")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("\n- kafka-producer-perf-test：生产者测试工具\n\n```bash\nbin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4\n#向指定主题发送了 1 千万条消息，每条消息大小是 1KB。\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("ul",[t("li",[t("p",[s._v("kafka-consumer-perf-test：消费者测试工具")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--messages")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000000")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" test-topic\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])])]),s._v(" "),t("li",[t("p",[s._v("kafka-consumer-groups：查看消费组位移")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--describe")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--group")]),s._v(" test-group\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])])]),s._v(" "),t("li",[t("p",[s._v("kafka-dump-log：查看kafka消息文件内容，包含各自元数据信息")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[s._v("$ bin/kafka-dump-log.sh "),t("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--files")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v("/data_dir/kafka_1/test-topic-1/00000000000000000000.log \n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])])]),s._v(" "),t("li",[t("p",[s._v("kafka-log-dirs：查询各个Broker上日志路线下的磁盘占用情况")])]),s._v(" "),t("li",[t("p",[s._v("kafka-mirror-maker：实现集群消息同步")])]),s._v(" "),t("li",[t("p",[s._v("kafka-preferred-replica-election：执行 Preferred Leader 选举的")])]),s._v(" "),t("li",[t("p",[s._v("kafka-reassign-partitions：执行分区副本迁移及副本文件路径迁移")])]),s._v(" "),t("li",[t("p",[s._v("kafka-topics：主题管理")])])]),s._v(" "),t("p",[s._v("所有的脚本都可以用 --help来查看选项，比如"),t("code",[s._v("./kafka-console-consumer.sh --help")])])],1)}),[],!1,null,null,null);t.default=e.exports}}]);