<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Eric&#39;s blog</title>
  
  
  <link href="http://soda1.github.io/atom.xml" rel="self"/>
  
  <link href="http://soda1.github.io/"/>
  <updated>2023-04-13T11:54:18.700Z</updated>
  <id>http://soda1.github.io/</id>
  
  <author>
    <name>Eric</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Config(Hoxton.SR8)</title>
    <link href="http://soda1.github.io/2023/04/04/spring/spring%20cloud/Config/"/>
    <id>http://soda1.github.io/2023/04/04/spring/spring%20cloud/Config/</id>
    <published>2023-04-04T13:56:16.000Z</published>
    <updated>2023-04-13T11:54:18.700Z</updated>
    
    <content type="html"><![CDATA[<p>随着项目的迭代，微服务的数量不断增多，我们需要高效的管理配置，spring cloud config可以帮我们解决此问题</p><p>spring cloud config分为config server和config client两部分，具有以下特点</p><ol><li>集中管理配置。一个使用微服务架构的应用系统可能会包含成百上千个微服务，因此集中管理配置是非常有必要的；</li><li>不同环境，不同配置。例如，数据源配置在不同的环境（开发、测试、预发布、生产等）中是不同的；</li><li>运行期间可动态调整。例如，我们可根据各个微服务的负载情况，动态调整数据源连接池大小或熔断阈值，并且在调整配置时不停止微服务；</li><li>配置修改后可自动更新。如配置内容发生变化，微服务能够自动更新配置。</li></ol><h4 id="config-server"><a href="#config-server" class="headerlink" title="config server"></a>config server</h4><p>config server是一个可横向扩展、集中式的配置服务器，它用于集中管理应用程序在不同环境下的配置，默认使用git存储配置内容</p><h5 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h5><ol><li><p>加依赖</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre></li><li><p>加注解</p><pre><code class="java">@SpringBootApplication@EnableConfigServerpublic class ConfigServerApplication &#123;    public static void main(String[] args) &#123;    SpringApplication.run(ConfigServerApplication.class, args);    &#125;&#125;</code></pre></li><li><p>写配置</p><pre><code class="java">server:  port: 8094spring:  application:    name: config-server  cloud:    config:      server:        git:          uri: file://F:\Java\Code\SpringCloud/config-repo # 具体仓库地址</code></pre><p>这里配置的是本地仓库，方便测试。如果要配置线上的，需要账户密码</p><pre><code class="yml">server:  port: 8094spring:  application:    name: config-server  cloud:    config:      server:        git:          uri:  https://git.xxx/repo.git # 具体仓库地址          # Git仓库账号          username:          # Git仓库密码          password:    </code></pre></li></ol><h5 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h5><p>config server提供了api，可以用来访问git仓库中的配置文件</p><pre><code>/&#123;application&#125;/&#123;profile&#125;[/&#123;label&#125;]/&#123;application&#125;-&#123;profile&#125;.yml/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.yml/&#123;application&#125;-&#123;profile&#125;.properties/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.properties</code></pre><p>其中的占位符表示如下</p><ul><li>application: 表示微服务名称，即配置的<code>spring.application.name</code></li><li>profile: 表示当前的环境，local、feature、dev、test、prod</li><li>label: 表示git仓库分支，feature、develop、test、master，当然默认的话是master</li></ul><h5 id="配置的继承与组合"><a href="#配置的继承与组合" class="headerlink" title="配置的继承与组合"></a>配置的继承与组合</h5><p>假设有一个应用：<code>config-client</code> ，其profile是dev，那么其实Spring Cloud Config会查找如下几个文件：</p><ul><li><code>config-client-dev.yml</code></li><li><code>config-client.yml</code></li><li><code>application-dev.yml</code></li><li><code>application.yml</code></li></ul><p>对于相同属性的配置，从上至下优先级逐渐递减；最终获得的配置属性是四个文件的组合。由此，不难分析，可如下规划几个配置文件：</p><ul><li><code>config-client-dev.yml</code> 作为指定应用在指定profile下的配置文件</li><li><code>config-client.yml</code> 作为制定应用在任何profile下都通用的配置文件</li><li><code>application-dev.yml</code> 作为所有应用在指定profile下的配置文件</li><li><code>application.yml</code> 作为所有应用在任何profile下都通用的配置文件</li></ul><pre><code class="yml"># config-client-dev.ymlmysql:  username: eric-dev345  password: 123-dev  url: http://localhost:8090-dev</code></pre><pre><code class="yml">#config-client.ymlmysql:  username: eric  password: 123  url: http://localhost:8090  signature: &#39;fafafafa&#39;</code></pre><p>访问<code>http://localhost:8094/config-client-dev.yml</code>可以看到<code>config-client-dev.yml</code>并组合<code>config-client.yml</code></p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230404144705.png" alt="image-20230404144658518" loading="lazy"></p><h5 id="git仓库配置"><a href="#git仓库配置" class="headerlink" title="git仓库配置"></a>git仓库配置</h5><ul><li><p>占位符配置</p><pre><code class="yml">server:  port: 8094spring:  application:    name: config-server  cloud:    config:      server:        git:          uri: file://F:\Java\Code\SpringCloud/&#123;application&#125; # 具体仓库地址</code></pre><p>如我们从<a href="http://localhost:8094/config-client/dev%E5%8E%BB%E8%8E%B7%E5%8F%96%E7%9A%84%E8%AF%9D%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BC%9A%E5%B0%86application%E8%87%AA%E5%8A%A8%E5%8D%A0%E4%BD%8D%E4%B8%BAconfig-client%EF%BC%8C%E5%8D%B3%E5%8E%BB%60file://F:/Java/Code/SpringCloud/config-client%60%E8%BF%99%E4%B8%AA%E4%BB%93%E5%BA%93%E7%9A%84%E6%A0%B9%E7%9B%AE%E5%BD%95%E4%B8%8B%E6%89%BE%60config-client-dev.yml%60%E8%B5%84%E6%BA%90">http://localhost:8094/config-client/dev去获取的话，那么会将application自动占位为config-client，即去`file://F:\Java\Code\SpringCloud/config-client`这个仓库的根目录下找`config-client-dev.yml`资源</a></p></li><li><p>模式匹配</p><pre><code class="yml">server:  port: 8094spring:  application:    name: config-server  cloud:    config:      server:        git:          uri: file://F:\Java\Code\SpringCloud/config-repo # 具体仓库地址          repos:            config-client:              pattern: config-client/*              uri: file://F:\Java\Code\SpringCloud/config-client</code></pre><p> 模式匹配指的是带有通配符的{application}/{profile}名称的列表。比如config-client仓库，它只匹配<a href="http://localhost:8094/config-client/*%E7%9A%84%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E3%80%82">http://localhost:8094/config-client/*的应用程序配置文件。</a></p><p>如果不匹配任何模式，则使用<code>spring.cloud.config.server.git.uri</code>定义的URL</p></li><li><p>搜索目录</p><pre><code class="yml">server:  port: 8094spring:  application:    name: config-server  cloud:    config:      server:        git:          uri: file://F:\Java\Code\SpringCloud/config-repo # 具体仓库地址          search-path: config-client, foo*</code></pre><p>Config Server就会在Git仓库根目录、config-client子目录、以及所有以foo开始的子目录中查找配置文件。</p></li></ul><h5 id="配置属性加密"><a href="#配置属性加密" class="headerlink" title="配置属性加密"></a>配置属性加密</h5><p>对于配置文件中账户密码一般都需要加密存储，config server为配置内容提供了加解密支持</p><p><strong>安装JCE</strong></p><p>Java 8 JCE的地址：<a href="http://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html">http://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html</a> 。</p><p><strong>加解密端点</strong></p><ul><li>加密：<code>curl $CONFIG_URL/encrypt -d 想要加密的内容</code></li><li>解密：<code>curl $CONFIG_URL/decrypt -d 想要解密的密文</code></li></ul><p><strong>配置</strong></p><p>在config server的<code>bootstrap.yml</code>中添加加密配置</p><ul><li><p>对称加密</p><pre><code class="yml">encrypt:  key: foo  # 设置对称密钥</code></pre><p>启动后输入命令</p><pre><code class="bash">curl http://localhost:8094/encrypt -d mysecret</code></pre><p>返回<code>7c5fab34141a8b743242f176cf913d56656e99e49db4065f6d2d7534b5a99307</code>加密串</p><pre><code class="bash">curl http://localhost:8094/decrypt -d 7c5fab34141a8b743242f176cf913d56656e99e49db4065f6d2d7534b5a99307</code></pre><p>返回<code>mysecret</code> ，说明能够正常解密</p></li></ul><h4 id="config-client"><a href="#config-client" class="headerlink" title="config client"></a>config client</h4><h5 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h5><ol><li><p>加依赖</p><pre><code class="xml">&lt;dependency&gt;  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;  &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre></li><li><p>加配置</p><pre><code class="yml"># application.ymlserver:  port: 8095</code></pre><pre><code class="yml"># bootstrap.ymlspring:  application:    name: config-client    # 对应config server所获取的配置文件的&#123;application&#125;  cloud:    config:      uri: http://localhost:8094/      profile: dev            # profile对应config server所获取的配置文件中的&#123;profile&#125;       label: master           # 指定Git仓库的分支，对应config server所获取的配置文件的&#123;label&#125;</code></pre></li><li><p>测试</p><pre><code class="java">@RestController@RequestMapping(&quot;/properties&quot;)public class PropertiesController &#123;  @Value(&quot;$&#123;mysql.username&#125;&quot;)  private String username;  @GetMapping(&quot;/username&quot;)  public String getUsername()&#123;    return this.username;  &#125;  ... &#125;</code></pre><p>访问<code>http://localhost:8095/properties/username</code>可返回git仓库中的配置属性</p></li></ol><h5 id="配置动态刷新"><a href="#配置动态刷新" class="headerlink" title="配置动态刷新"></a>配置动态刷新</h5><ul><li><p>加依赖</p><pre><code class="xml">        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre></li><li><p>配置暴露端点</p><pre><code class="yml">management:  endpoints:    web:      exposure:        include: refresh</code></pre></li><li><p>在待刷新属性所在类上添加<code>@RefreshScope</code></p><pre><code class="java">@RestController@RefreshScope  //配置动态刷新@RequestMapping(&quot;/properties&quot;)public class PropertiesController &#123;  @Value(&quot;$&#123;mysql.username&#125;&quot;)  private String username;    ...&#125;</code></pre></li></ul><p>在修改username属性后，只需执行如下请求即可刷新该属性</p><pre><code class="bash">curl -X POST http://localhost:8095/actuator/refresh</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;随着项目的迭代，微服务的数量不断增多，我们需要高效的管理配置，spring cloud config可以帮我们解决此问题&lt;/p&gt;
&lt;p&gt;spring cloud config分为config server和config client两部分，具有以下特点&lt;/p&gt;
&lt;ol&gt;
&lt;</summary>
      
    
    
    
    <category term="spring cloud" scheme="http://soda1.github.io/categories/spring-cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>Zuul(Hoxton.SR8)</title>
    <link href="http://soda1.github.io/2023/04/03/spring/spring%20cloud/Zuul/"/>
    <id>http://soda1.github.io/2023/04/03/spring/spring%20cloud/Zuul/</id>
    <published>2023-04-03T16:21:57.000Z</published>
    <updated>2023-04-13T11:54:18.700Z</updated>
    
    <content type="html"><![CDATA[<p>当外部完成一个功能时，可能需要调用多个微服务接口，存在以下问题</p><ul><li>鉴权问题，每一个服务都要实现鉴权逻辑或调用鉴权服务</li><li>客户端需要请求不同的微服务，增加了复杂性</li><li>存在跨域请求</li></ul><p>服务网关可以解决上述问题，通过服务网关统一向外系统提供REST API的过程中，除了具备<code>服务路由</code>、<code>均衡负载</code>功能之外，它还具备了<code>权限控制</code>等功能。</p><h4 id="Zuul简介"><a href="#Zuul简介" class="headerlink" title="Zuul简介"></a>Zuul简介</h4><p>Zuul是Netflix开源的微服务网关，它可以和Eureka、Ribbon、Hystrix等组件配合使用。Zuul的核心是一系列的过滤器，这些过滤器帮助我们完成以下功能：</p><ul><li>身份认证与安全：识别每个资源的验证要求，并拒绝那些与要求不符的请求；</li><li>审查与监控：在边缘位置追踪有意义的数据和统计结果，从而为我们带来精确的生产视图；</li><li>动态路由：动态地将请求路由到不同的后端集群；</li><li>压力测试：逐渐增加指向集群的流量，以了解性能；</li><li>负载分配：为每一种负载类型分配对应容量，并弃用超出限定值的请求；</li><li>静态响应处理：在边缘位置直接建立部分响应，从而避免其转发到内部集群；</li><li>多区域弹性：跨越AWS Region进行请求路由，旨在实现ELB（Elastic Load Balancing）使用的多样化；以及让系统的边缘更贴近系统的使用者。</li></ul><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><ol><li><p>加依赖</p><pre><code class="xml">&lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre></li><li><p>加注解</p><pre><code class="java">@SpringBootApplication@EnableZuulProxypublic class ZuulApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(ZuulApplication.class);    &#125;&#125;</code></pre></li><li><p>配置</p><pre><code class="yml">zuul:  routes:    provider:      path: /provider-server/** # **：表示可以匹配多层路径 *：表示只能匹配一层      url: http://localhost:8087</code></pre><p>测试</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230403200851.png" alt="image-20230403200851299" loading="lazy"></p></li></ol><h4 id="搭配服务发现组件"><a href="#搭配服务发现组件" class="headerlink" title="搭配服务发现组件"></a>搭配服务发现组件</h4><ol><li><p>引入eureka</p><pre><code class="xml"> &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre></li><li><p>开启Eureka发现功能</p><pre><code class="java">@SpringBootApplication@EnableEurekaClient@EnableZuulProxypublic class ZuulApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(ZuulApplication.class);    &#125;&#125;</code></pre></li><li><p>配置Eureka及修改路由</p><pre><code class="yml">zuul:  routes:    provider:      path: /provider-server/**      service-id: provider-servereureka:  client:    service-url:      defaultZone: http://peer1:8085/eureka/,http://peer2:8086/eureka/    register-with-eureka: true    instance:      lease-renewal-interval-in-seconds: 30</code></pre><p>路由可以简化如下</p><pre><code class="yml">zuul:  routes:    service-provider: /service-provider/** # 这里是映射路径</code></pre></li></ol><h4 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h4><ul><li><p><code>zuul.prefix</code>：配置url前缀</p><pre><code class="yml">zuul:  prefix: /api  routes:    service-provider: /service-provider/**</code></pre><p>访问<code>/api/service-provider/book/list</code>会被转发到<code>/service-provider/book/list</code></p></li><li><p><code>zuul.ignored-services</code>：忽略要代理的服务，多个用,隔开。*表示忽略所有，除了routes下的配置</p><pre><code class="yml">zuul:  ignored-services: &#39;*&#39;   # 使用&#39;*&#39;可忽略所有微服务  routes:    provider-server: /service-provider/**#只代理provider-server</code></pre><pre><code class="yml">zuul:  ignored-services: provider-server</code></pre><p>忽略provider-server</p></li></ul><h4 id="过滤器ZuulFilter"><a href="#过滤器ZuulFilter" class="headerlink" title="过滤器ZuulFilter"></a>过滤器ZuulFilter</h4><p>ZuulFilter是过滤器的顶级父类。在这里我们看一下其中定义的4个最重要的方法：</p><pre><code class="java">public abstract ZuulFilter implements IZuulFilter&#123;    abstract public String filterType();    abstract public int filterOrder();    boolean shouldFilter();// 来自IZuulFilter    Object run() throws ZuulException;// IZuulFilter&#125;</code></pre><ul><li><code>shouldFilter</code>：返回一个<code>Boolean</code>值，判断该过滤器是否需要执行。返回true执行，返回false不执行。</li><li><code>run</code>：过滤器的具体业务逻辑。</li><li><code>filterType</code>：返回字符串，代表过滤器的类型。包含以下4种：<ul><li><code>pre</code>：请求在被路由之前执行</li><li><code>route</code>：在路由请求时调用</li><li><code>post</code>：在route和errror过滤器之后调用</li><li><code>error</code>：处理请求时发生错误调用</li></ul></li><li><code>filterOrder</code>：通过返回的int值来定义过滤器的执行顺序，数字越小优先级越高。</li></ul><h5 id="过滤器执行生命周期"><a href="#过滤器执行生命周期" class="headerlink" title="过滤器执行生命周期"></a>过滤器执行生命周期</h5><p>这张是Zuul官网提供的请求生命周期图，清晰的表现了一个请求在各个过滤器的执行顺序。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20210317104851.png" alt="1543054221479" loading="lazy"></p><p>正常流程：</p><ul><li>请求到达首先会经过pre类型过滤器，而后到达route类型，进行路由，请求就到达真正的服务提供者，执行请求，返回结果后，会到达post过滤器。而后返回响应。</li></ul><p>异常流程：</p><ul><li>整个过程中，pre或者route过滤器出现异常，都会直接进入error过滤器，在error处理完毕后，会将请求交给POST过滤器，最后返回给用户。</li><li>如果是error过滤器自己出现异常，最终也会进入POST过滤器，将最终结果返回给请求客户端。</li><li>如果是POST过滤器出现异常，会跳转到error过滤器，但是与pre和route不同的是，请求不会再到达POST过滤器了。</li></ul><h5 id="自定义过滤器"><a href="#自定义过滤器" class="headerlink" title="自定义过滤器"></a>自定义过滤器</h5><p>定义一个验证过滤器，如果请求中有access-token参数，则认为请求有效，放行。</p><pre><code class="java">@Componentpublic class LoginFilter extends ZuulFilter &#123;    /**     * 过滤器类型，前置过滤器     * @return     */    @Override    public String filterType() &#123;        return &quot;pre&quot;;    &#125;    /**     * 过滤器的执行顺序     * @return     */    @Override    public int filterOrder() &#123;        return 1;    &#125;    /**     * 该过滤器是否生效     * @return     */    @Override    public boolean shouldFilter() &#123;        return true;    &#125;    /**     * 登陆校验逻辑     * @return     * @throws ZuulException     */    @Override    public Object run() throws ZuulException &#123;        // 获取zuul提供的上下文对象        RequestContext context = RequestContext.getCurrentContext();        // 从上下文对象中获取请求对象        HttpServletRequest request = context.getRequest();        // 获取token信息        String token = request.getParameter(&quot;access-token&quot;);        // 判断        if (StringUtils.isBlank(token)) &#123;           //过滤请求,设置为false表示请求不会进入后台路由，但是还是会走其他的filter            context.setSendZuulResponse(false);            // 设置响应状态码，401            context.setResponseStatusCode(HttpStatus.SC_UNAUTHORIZED);            // 设置响应内容，会覆盖后台路由传出来的内容            context.setResponseBody(&quot;&#123;\&quot;status\&quot;:\&quot;401\&quot;, \&quot;text\&quot;:\&quot;request error!\&quot;&#125;&quot;);        &#125;        // 校验通过，把登陆信息放入上下文信息，继续向后执行        context.set(&quot;token&quot;, token);        return null;    &#125;&#125;</code></pre><h4 id="负载均衡和熔断"><a href="#负载均衡和熔断" class="headerlink" title="负载均衡和熔断"></a>负载均衡和熔断</h4><p>Zuul中默认就已经集成了Ribbon负载均衡和Hystix熔断机制。但是所有的超时策略都是走的默认值，比如熔断超时时间只有1S，很容易就触发了。因此建议我们手动进行配置：</p><pre><code class="yaml">hystrix:  command:    default:      execution:        isolation:          thread:            timeoutInMilliseconds: 2000 # 设置hystrix的超时时间为6000ms</code></pre><p>指定服务超时</p><pre><code class="yml">hystrix:  command:    &lt;server-name&gt;:      execution:        isolation:          thread:            timeoutInMilliseconds: 2000 # 设置hystrix的超时时间为6000ms</code></pre><h4 id="Zuul超时"><a href="#Zuul超时" class="headerlink" title="Zuul超时"></a>Zuul超时</h4><p>由于Zuul是集成Ribbon和Hystrix的，在使用Zuul时可以配置Hystrix和Ribbon的参数来调整路由各种超时时间等配置。</p><ul><li><p>url方式去配置路由</p><pre><code class="yml">#使用zuul超时设置配置套接字超时和读取超时zuul:    host:        connect-timeout-millis：1000        socket-timeout-millis：1000</code></pre></li><li><p>serviceId方式配置路由</p><pre><code class="yml">#全局配置套接字超时和读取超时ribbon:    ReadTimeout: 1000 #该参数用来设置路由转发请求的超时时间    ConnectTimeout: 1000 #该参数用来设置路由转发请求的时候，创建请求连接超时时间#配置指定服务的超时时间&lt;client&gt;:    ribbon:        ReadTimeout: 1000 #该参数用来设置路由转发请求的超时时间        ConnectTimeout: 1000 #该参数用来设置路由转发请求的时候，创建请求连接超时时间</code></pre></li></ul><h4 id="定义fallback"><a href="#定义fallback" class="headerlink" title="定义fallback"></a>定义fallback</h4><p>在zuul中，定义hystrix的fallback要实现FallbackProvider接口</p><pre><code class="java">@Componentpublic class ProviderFallBack implements FallbackProvider &#123;    /**     * 指定fallback 服务, 返回 */null 表示default fallback     * @return     */    @Override    public String getRoute() &#123;        return &quot;*&quot;;    &#125;    /**     * 实现fallback返回     * @param route     * @param cause     * @return     */    @Override    public ClientHttpResponse fallbackResponse(String route, Throwable cause) &#123;        ClientHttpResponse fallback = fallback(HttpStatus.SERVICE_UNAVAILABLE, &quot;服务出错啦&quot;);        return fallback;    &#125;    private ClientHttpResponse fallback(HttpStatus status,  String body) &#123;       return new ClientHttpResponse()&#123;           //除了close，其他方法都实现，否则可能报错            @Override            public HttpHeaders getHeaders() &#123;                HttpHeaders headers = new HttpHeaders();                headers.setContentType(MediaType.APPLICATION_JSON);                return headers;            &#125;           @Override           public InputStream getBody() throws IOException &#123;;               return new ByteArrayInputStream(body.getBytes(&quot;utf-8&quot;));           &#125;            @Override            public HttpStatus getStatusCode() throws IOException &#123;                return status;            &#125;            @Override            public int getRawStatusCode() throws IOException &#123;                return status.value();            &#125;            @Override            public String getStatusText() throws IOException &#123;                return status.getReasonPhrase();            &#125;            @Override            public void close() &#123;            &#125;        &#125;;    &#125;&#125;</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;当外部完成一个功能时，可能需要调用多个微服务接口，存在以下问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;鉴权问题，每一个服务都要实现鉴权逻辑或调用鉴权服务&lt;/li&gt;
&lt;li&gt;客户端需要请求不同的微服务，增加了复杂性&lt;/li&gt;
&lt;li&gt;存在跨域请求&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;服务网关可以</summary>
      
    
    
    
    <category term="spring cloud" scheme="http://soda1.github.io/categories/spring-cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>Hystrix(Hoxton.SR8)</title>
    <link href="http://soda1.github.io/2023/04/02/spring/spring%20cloud/Hystrix/"/>
    <id>http://soda1.github.io/2023/04/02/spring/spring%20cloud/Hystrix/</id>
    <published>2023-04-02T23:25:46.000Z</published>
    <updated>2023-04-13T11:54:18.700Z</updated>
    
    <content type="html"><![CDATA[<p>在微服务中，服务间的调用关系非常复杂，如果某个服务不可用或存在高延迟，有可能会发生级联失败。比如A服务需要调用B服务，如果B服务不可用或存在高延迟，A对B的请求可能将会开始排队，这会导致A的资源耗尽，从而导致A也不可用</p><p>hystrix是由netflix开源的延迟和容错库，用于隔离访问远程系统/服务，防止出现级联失败，同时也提供了实时测量数据用于诊断问题</p><p>主要通过以下几点实现延迟和容错</p><ul><li><p>线程隔离</p><p>hystrix会为每个依赖服务分配一个很小的线程池，如果线程池已满，调用将被立即拒绝，默认不采用排队，从而加速失败判定</p></li><li><p>跳闸机制</p><p>当服务调用错误率超过一定阈值后，hystrix就会自动/手动跳闸，进入断开状态，停止请求服务一段时间</p></li><li><p>回退机制</p><p>当请求失败，超时，被拒绝或断路器打开时，hsytrix会执行回退逻辑</p></li><li><p>自我修复</p><p>断路器打开一段时间后，会自动进入半开状态，允许部分请求通过，如果服务可用就会回到闭合状态，否则又进入断开状态</p></li><li><p>监控</p><p>hystrix提供实时监控功能，可以监控运行指标及配置变化，帮助诊断问题</p></li></ul><h4 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h4><ol><li><p>引入依赖</p><pre><code class="yml">        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre></li><li><p>开启hystrix</p><pre><code class="java">@EnableCircuitBreaker@SpringBootApplicationpublic class HystrixApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(HystrixApplication.class);    &#125;&#125;</code></pre></li></ol><ol start="3"><li><p>使用<code>@HystrixConmand</code>注解</p><pre><code class="java">    @HystrixCommand(fallbackMethod = &quot;errorFall&quot;)    @GetMapping(&quot;/error&quot;)    public String error() &#123;        String errInfo = restTemplate.getForObject(&quot;http://localhost:8087/hystrix/error&quot;, String.class);        System.out.printf(errInfo);        return errInfo;    &#125;public String errorFall()&#123;        return &quot;error fall back&quot;;    &#125;</code></pre><p><code>errorFall</code>方法是回退处理逻辑，<strong>它的参数和返回值要和<code>@HystrixCommand</code>标注的方法一样</strong>，当请求服务不可用时就会返回回退逻辑信息</p><p>也可以为一个类指定默认的回退处理逻辑，在类上加上注解<code>@DefaultProperties&quot;</code></p><pre><code class="java">@Controller@RequestMapping(&quot;consumer/user&quot;)@DefaultProperties(defaultFallback = &quot;fallBackMethod&quot;) // 指定一个类的默认回退逻辑public class UserController &#123;    @Autowired    private RestTemplate restTemplate;    @GetMapping    @ResponseBody    @HystrixCommand //标注加入断路器    public String queryUserById(@RequestParam(&quot;id&quot;) Long id) &#123;        String user = this.restTemplate.getForObject(&quot;http://service-provider/user/&quot; + id, String.class);        return user;    &#125;&#125;</code></pre></li></ol><h4 id="属性配置"><a href="#属性配置" class="headerlink" title="属性配置"></a>属性配置</h4><ul><li><p>全局配置</p><p>使用<code>hystrix.command.default.属性</code>进行全局配置，比如超时配置如下</p><pre><code class="yml">hystrix:  command:    default:      execution:        isolation:          thread:            timeoutInMilliseconds: 6000 # 设置hystrix的超时时间为6000ms</code></pre></li><li><p>按Command Key配置</p><p>使用<code>hystrix.command.comandKey.属性</code>配置单个熔断器属性</p><pre><code class="yml">hystrix:  command:    timeoutKey:      execution:        isolation:          thread:            timeoutInMilliseconds: 1000 # 设置hystrix的超时时间为6000ms</code></pre><pre><code class="java">@HystrixCommand(fallbackMethod = &quot;errorFall1&quot;, commandKey = &quot;timeoutKey&quot;)@GetMapping(&quot;/timeout/&#123;time&#125;&quot;)public String timeout(@PathVariable(&quot;time&quot;) Integer time) &#123;    String errInfo = restTemplate.getForObject(&quot;http://localhost:8087/hystrix/timeout/&quot; + time, String.class);    return errInfo;&#125;</code></pre></li></ul><h4 id="断路器机制"><a href="#断路器机制" class="headerlink" title="断路器机制"></a>断路器机制</h4><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230403131243.png" loading="lazy"></p><p>断路器有三个状态</p><ol><li>Closed：关闭状态，所有请求正常访问</li><li>Open：打开状态，所有请求进行降级处理。hystrix会对请求情况计数，当一定时间内失败请求百分比达到阈值，就会触发熔断，断路器处于打开状态。默认在10s内如果请求数大于等于20次时，有50%的失败请求就会触发熔断</li><li>Half Open：半开状态，当断路器处于Open状态时，会进入一段休眠时间（默认5s），随后断路器会自动进入半开状态，部分请求会被通过，如果这些请求都成功了，那么就会闭合断路器，否则会回到断开状态，再次进行休眠</li></ol><h4 id="hystrix状态查看"><a href="#hystrix状态查看" class="headerlink" title="hystrix状态查看"></a>hystrix状态查看</h4><p>Hystrix可以通过<a href="http://localhost:port/actuator/health来查看状态">http://localhost:port/actuator/health来查看状态</a></p><ol><li><p>加actuator依赖</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre></li><li><p>配置组件细节展示</p><pre><code class="yml">management:  endpoint:    health:      show-details: always      show-components: always</code></pre></li><li><p>查看状态</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20210318155023.png" alt="image-20210318155023139" loading="lazy"></p></li></ol><center> 熔断状态<center><h4 id="hystrix-dashboard"><a href="#hystrix-dashboard" class="headerlink" title="hystrix dashboard"></a>hystrix dashboard</h4><p>它的作用是将监控数据图表化</p><p><strong>使用</strong></p><ol><li><p>加依赖</p><pre><code class="yml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre></li><li><p>加注解</p><pre><code class="java">@EnableHystrixDashboard@SpringBootApplicationpublic class HystrixDashBoardApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(HystrixDashBoardApplication.class);    &#125;&#125;</code></pre></li><li><p>配置端口</p><pre><code class="yml">server:  port: 8092</code></pre></li></ol><p>启动后在浏览器输入<a href="http://localhost:8092/hystrix/%E5%B0%B1%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E7%9B%91%E6%8E%A7%E9%A1%B5%E9%9D%A2%E4%BA%86">http://localhost:8092/hystrix/就可以看到监控页面了</a></p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230403153209.png" loading="lazy"></p><ol start="4"><li><p>在要监控的应用加入<code>spring-boot-starter-actuator</code>依赖，然后配置暴露actuator/hystrix.stream路径</p><pre><code class="yml">#配置组件暴露细节management:  endpoint:    health:      show-details: always      show-components: always  #暴露actuator/hystrix.stream路径  endpoints:    web:      exposure:        include: &#39;hystrix.stream&#39;</code></pre></li><li><p>将<code>http://ip:port/actuator/hystrix.stream</code>在页面输入后并起好标题点击Monitor Stream后即可看到如下监控页面</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230403153929.png" alt="image-20230403153929901" loading="lazy"></p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在微服务中，服务间的调用关系非常复杂，如果某个服务不可用或存在高延迟，有可能会发生级联失败。比如A服务需要调用B服务，如果B服务不可用或存在高延迟，A对B的请求可能将会开始排队，这会导致A的资源耗尽，从而导致A也不可用&lt;/p&gt;
&lt;p&gt;hystrix是由netflix开源的延</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Feign(Hoxton.SR8)</title>
    <link href="http://soda1.github.io/2023/03/31/spring/spring%20cloud/Feign/"/>
    <id>http://soda1.github.io/2023/03/31/spring/spring%20cloud/Feign/</id>
    <published>2023-03-31T15:16:39.000Z</published>
    <updated>2023-04-13T11:54:18.700Z</updated>
    
    <content type="html"><![CDATA[<p>Feign是一个声明式的HTTP客户端，相比于RestTemplate，它更加容易维护及使用</p><h4 id="引入Feign"><a href="#引入Feign" class="headerlink" title="引入Feign"></a>引入Feign</h4><ol><li><p>加依赖</p><pre><code class="xml">        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre></li><li><p>加注解</p><pre><code class="java">@SpringBootApplication@EnableFeignClientspublic class FeignApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(FeignApplication.class);    &#125;&#125;</code></pre></li><li><p>配置</p><pre><code class="java">@FeignClient(name = &quot;provider-server&quot;)public interface ProviderFeign &#123;</code></pre></li></ol><pre><code>   @RequestMapping(method = RequestMethod.GET, value = &quot;/book/&#123;bookName&#125;&quot;)   String getBook(@PathVariable(&quot;bookName&quot;) String name);   @RequestMapping(method = RequestMethod.POST, value = &quot;/book/&quot;, consumes = &quot;application/json&quot;)   String addBook(@RequestBody String name);   @RequestMapping(method = RequestMethod.DELETE, value = &quot;/book/&#123;bookName&#125;&quot;)   String deleteBook(@PathVariable(&quot;bookName&quot;) String name);   @RequestMapping(method = RequestMethod.GET, value = &quot;/book/list&#125;&quot;)   Set&lt;String&gt; bookList();</code></pre><p>   }</p><pre><code>`@FeignClient`声明这是一个Feign客户端，主要配置参数有- name：表示服务的实例名称- configuration：客户端配置类，比如配置Client的Log级别- fallback：接口调用时触发熔断或错误时的回退处理，此类必须要实现指定的Feign客户端接口#### 参数构造- `@PathVariable`表示参数应映射到url路径上  ```java@RequestMapping(method = RequestMethod.GET, value = &quot;/book/&#123;bookName&#125;&quot;)   String getBook(@PathVariable(&quot;bookName&quot;) String name);</code></pre><ul><li><p><code>@RequestParam</code>表示参数应映射到url的查询参数上</p><pre><code class="java">@RequestLine(&quot;GET /users&quot;)List&lt;User&gt; getUsersByName(@RequestParam(&quot;name&quot;) String name);</code></pre></li><li><p><code>@RequestBody</code>表示参数应放入请求体</p><pre><code class="java">@RequestLine(&quot;POST /users&quot;)void createUser(@RequestBody User user);</code></pre></li><li><p><code>@HeaderMap</code>表示Map的head参数应映射到head上</p><pre><code class="java">@RequestLine(&quot;GET /users&quot;)List&lt;User&gt; getUsers(@HeaderMap Map&lt;String, String&gt; headers);</code></pre></li><li><p><code>@QueryMap</code> 表示Map里面的参数映射到url的查询参数上</p><pre><code class="java">@RequestLine(&quot;GET /users&quot;)List&lt;User&gt; getUsers(@QueryMap Map&lt;String, String&gt; params);</code></pre></li></ul><h4 id="属性配置"><a href="#属性配置" class="headerlink" title="属性配置"></a>属性配置</h4><ul><li><p>yml配置</p><p>通过<code>feign.client.config.feignName.属性</code>来对属性进行配置</p><pre><code class="yml">feign:  client:    config:      provider-server:          connectTimeout: 5000  # 相当于Request.Options        readTimeout: 5000     # 相当于Request.Options        # 配置Feign的日志级别，相当于代码配置方式中的Logger        loggerLevel: full        # Feign的错误解码器，相当于代码配置方式中的ErrorDecoder        errorDecoder: com.example.SimpleErrorDecoder</code></pre><p>如果想配置通用属性，使用<code>feign.client.default-config.属性</code></p></li><li><p>代码配置</p><p>编写一个配置类，并将其配置为<code>@FeignClient</code>的<code>configuration</code>属性的值</p><pre><code class="java">@FeignClient(name = &quot;provider-server&quot;, configuration = ProviderFeignConfig.class)public interface ProviderFeign &#123;&#125;class ProviderFeignConfig&#123;    @Bean    public Logger.Level  logger()&#123;        return Logger.Level.FULL;    &#125;&#125;</code></pre><p>如果要配置通用属性，可以在配置类加上<code>@Configuraiton</code>，使得配置被Spring扫描到，为所有的Feign客户端共享。一般不建议这么做，容易成坑</p><p>可配置属性查看<a href="https://docs.spring.io/spring-cloud-openfeign/docs/2.2.5.RELEASE/reference/html/appendix.html">Page</a></p></li></ul><h5 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h5><p>feign可配置的日志级别如下</p><ul><li>NONE：【性能最佳，适用于生产】不记录任何日志信息，这是默认值。</li><li>BASIC：【适用于生产环境追踪问题】仅记录请求的方法，URL以及响应状态码和执行时间</li><li>HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息</li><li>FULL：【比较适用于开发及测试环境定位问题】记录所有请求和响应的明细，包括头信息、请求体、元数据。</li></ul><p>如何配置</p><ol><li><p>yml配置feign客户端日志为debug</p><pre><code class="yml">logging:  level:    com.eric.study.cloud.feign.api.ProviderFeign: debug</code></pre></li><li><p>配置Feign日志打印级别</p><pre><code class="java">@FeignClient(name = &quot;provider-server&quot;, configuration = ProviderFeignConfig.class)public interface ProviderFeign &#123;&#125;class ProviderFeignConfig&#123;    @Bean    public Logger.Level  logger()&#123;        return Logger.Level.FULL;    &#125;&#125;</code></pre></li></ol><h5 id="请求压缩"><a href="#请求压缩" class="headerlink" title="请求压缩"></a>请求压缩</h5><p>支持对请求和响应进行GZIP压缩</p><ol><li><p>压缩开启</p><pre><code class="properties">feign.compression.request.enabled=truefeign.compression.response.enabled=true</code></pre></li><li><p>对要压缩的数据类型及数据大小</p><pre><code class="properties">feign.compression.request.enabled=truefeign.compression.request.mime-types=text/xml,application/xml,application/jsonfeign.compression.request.min-request-size=2048</code></pre></li></ol><h4 id="hystrix配置"><a href="#hystrix配置" class="headerlink" title="hystrix配置"></a>hystrix配置</h4><p>feign已经整合了hystrix，可以通过配置<code>feign.hystrix.enable=true</code>开启，然后</p><ol><li><p>定义一个实现feign client的类</p><pre><code class="java">@Componentpublic class ProviderFallBack implements ProviderFeign &#123;</code></pre></li></ol><pre><code>   @Override   public String getBook(String bookName) &#123;       return &quot;sever bash&quot;;   &#125;   ....</code></pre><p>   }</p><pre><code>2. 然后配置`@feignClient`属性`fallback`值```java@FeignClient(    name = &quot;provider-server&quot;,fallback = ProviderFallBack.class)</code></pre><p>如果要获取造成fallback的异常，需要如下配置</p><ol><li><p>定义一个实现FallbackFactory的类</p><pre><code class="java">@Componentpublic class ProviderFeignFallbackFactory implements FallbackFactory&lt;ProviderFeign&gt; &#123;  @Override  public ProviderFeign create(Throwable cause) &#123;    return new ProviderFeign() &#123;      Logger logger = LoggerFactory.getLogger(ProviderFeign.class);      @Override      public String timeout(int sleepTime) &#123;        logger.error(&quot;error info: &quot; + cause.getMessage());        System.out.printf(&quot;server unavailable&quot;);        return &quot;server unavailable&quot;;      &#125;    &#125;  &#125;&#125;</code></pre></li><li><p>然后配置<code>@feignClient</code>属性<code>fallbackFactory</code>值</p><pre><code class="java">@FeignClient(    name = &quot;provider-server&quot;,    configuration = ProviderFeignConfig.class,    fallbackFactory = ProviderFeignFallbackFactory.class)</code></pre></li></ol><h4 id="超时配置"><a href="#超时配置" class="headerlink" title="超时配置"></a>超时配置</h4><ul><li><p>全局配置</p><pre><code class="yml">#hystrix 配置hystrix:    default:      execution:        isolation:          thread:            timeoutInMilliseconds: 6000 ##hystrix 超时配置 ms#feign 配置feign:  hystrix:    enabled: true  #开启hystrix熔断功能  client:   config:     default:       connectTimeout: 1000 #ribbon连接超时配置       readTimeout: 1000 #ribbon响应超时配置#配置ribbon重试ribbon:    MaxAutoRetries: 3    MaxAutoRetriesNextServer: 0    OkToRetryOnAllOperations: true</code></pre></li><li><p>指定配置</p><pre><code class="yml">hystrix:  command:      #指定某个方法的hystrix配置，格式如下    &quot;ProviderFeign#timeout(int)&quot;:      execution:        isolation:          thread:            timeoutInMilliseconds: 10000  feign:  hystrix:    enabled: true  #开启hystrix熔断功能  client:    config:      #指定客户端名配置      bookServer:         connectTimeout: 1000        readTimeout: 2000#配置指定客户端名的ribbonbookServer:  ribbon:    MaxAutoRetries: 3    MaxAutoRetriesNextServer: 0    OkToRetryOnAllOperations: true</code></pre></li></ul><p>tips：</p><ul><li>hystrix配置的超时时间要比ribbon的（超时*重试次数）的总时间大，否则ribbon重试还没有走完hystrix就会触发超时异常了。</li><li>要启动ribbon的重试机制，要导入spring-retry依赖</li><li>如果要给每个客户端都分配不同的hystrix配置，参考issue：<a href="https://github.com/spring-cloud/spring-cloud-openfeign/issues/548">can’t set per client hystrix configuration #548</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Feign是一个声明式的HTTP客户端，相比于RestTemplate，它更加容易维护及使用&lt;/p&gt;
&lt;h4 id=&quot;引入Feign&quot;&gt;&lt;a href=&quot;#引入Feign&quot; class=&quot;headerlink&quot; title=&quot;引入Feign&quot;&gt;&lt;/a&gt;引入Feign&lt;/h4</summary>
      
    
    
    
    <category term="spring cloud" scheme="http://soda1.github.io/categories/spring-cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>Ribbon(Hoxton.SR8)</title>
    <link href="http://soda1.github.io/2023/03/31/spring/spring%20cloud/Ribbon/"/>
    <id>http://soda1.github.io/2023/03/31/spring/spring%20cloud/Ribbon/</id>
    <published>2023-03-31T12:05:31.000Z</published>
    <updated>2023-04-13T11:54:18.700Z</updated>
    
    <content type="html"><![CDATA[<p>多个相同的微服务实例，当被调用时，如何做到负载均衡呢？Spring Cloud 集成了ribbon，它是一个在客户端侧的负载均衡组件。由Netflix发布。</p><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>客户端负载均衡器的实现原理是通过注册中心，如 Eureka，将可用的服务列表拉取到本地（客户端），再通过客户端负载均衡器（设置的负载均衡策略）获取到某个服务器的具体 ip 和端口，然后再通过 Http 框架请求服务并得到结果，其执行流程如下图所示：</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230331123612.png" loading="lazy"></p><h4 id="引入Ribbon"><a href="#引入Ribbon" class="headerlink" title="引入Ribbon"></a>引入Ribbon</h4><ol><li><p>加入依赖</p><p>依赖<code>spring-cloud-starter-netflix-eureka-client</code>即可，它已经包含了<code>spring-cloud-starter-netfilx-ribbon</code></p></li><li><p>配置</p><pre><code class="java">   @Bean   @LoadBalanced   public RestTemplate getRestTemplate() &#123;       return new RestTemplate();   &#125;</code></pre><p>加入<code>@LoadBalanced</code>注解</p></li><li><p>调用</p><pre><code class="java">   @GetMapping(&quot;/admin/&quot;)   public String loadedBalance() &#123;       String forObject = restTemplate.getForObject(&quot;http://provider-server/admin/&quot;, String.class);       return forObject;   &#125;</code></pre></li></ol><h4 id="内置负载均衡"><a href="#内置负载均衡" class="headerlink" title="内置负载均衡"></a>内置负载均衡</h4><ul><li><p><code>RoundRobinRule</code> </p><p>轮询策略轮 轮询index，选择index对应位置的Server。它经常被用作默认策略或更高级策略的后备策略</p></li><li><p><code>WeightedResponseTimeRule</code></p><p>根据平均响应时间分配一个 Weight（权重），响应时间越长，Weight 越小。该策略会依靠权重来随机对实例进行选择，权重越低，被选择的可能性越小</p></li><li><p><code>RandomRule</code></p><p>随机策略，随机选择一个实例</p></li><li><p><code>BestAvailableRule</code></p><p>选择一个最小的并发请求的Server，逐个考察Server，如果Server被tripped了，则跳过</p></li><li><p><code>RetryRule</code></p><p>对选定的负载均衡策略提供重试机制</p></li><li><p><code>AvailabilityFilteringRule</code></p><p>过滤一直连接失败的被标记为circuit tripped的服务实例，并过滤掉那些高并发的服务实例</p></li><li><p><code>ZoneAvoidanceRule</code></p><p>基于zone和available来过滤实例，通过组合<code>ZoneAvoidancePredicate</code>和<code>AvailabilityPredicate</code>，过滤掉连接失败的和连接数过多的实例，同时也会过滤不符合zone要求的节点</p><pre><code class="java"> public ZoneAvoidanceRule() &#123;        super();        ZoneAvoidancePredicate zonePredicate = new ZoneAvoidancePredicate(this);        AvailabilityPredicate availabilityPredicate = new AvailabilityPredicate(this);        compositePredicate = createCompositePredicate(zonePredicate, availabilityPredicate);    &#125;</code></pre></li></ul><h4 id="配置负载均衡策略"><a href="#配置负载均衡策略" class="headerlink" title="配置负载均衡策略"></a>配置负载均衡策略</h4><ol><li><p>按实例配置</p><p><code>&lt;clientName&gt;.ribbon.</code> 如下属性</p><ul><li><code>NFLoadBalancerClassName</code>: should implement <code>ILoadBalancer</code></li><li><code>NFLoadBalancerRuleClassName</code>: should implement <code>IRule</code></li><li><code>NFLoadBalancerPingClassName</code>: should implement <code>IPing</code></li><li><code>NIWSServerListClassName</code>: should implement <code>ServerList</code></li><li><code>NIWSServerListFilterClassName</code> should implement <code>ServerListFilter</code></li></ul><pre><code class="yaml">provider-server:  ribbon:    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule</code></pre></li><li><p>全局配置</p><pre><code class="java">@RibbonClients(defaultConfiguration = DefaultRibbonConfig.class)public class RibbonClientDefaultConfigurationTestsConfig &#123;&#125;@Configurationclass DefaultRibbonConfig &#123;  @Bean  public IRule ribbonRule() &#123;    return new RandomRule();  &#125;&#125;</code></pre></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;多个相同的微服务实例，当被调用时，如何做到负载均衡呢？Spring Cloud 集成了ribbon，它是一个在客户端侧的负载均衡组件。由Netflix发布。&lt;/p&gt;
&lt;h4 id=&quot;原理&quot;&gt;&lt;a href=&quot;#原理&quot; class=&quot;headerlink&quot; title=&quot;原理</summary>
      
    
    
    
    <category term="spring cloud" scheme="http://soda1.github.io/categories/spring-cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>Eureka(Hoxton.SR8)</title>
    <link href="http://soda1.github.io/2023/03/29/spring/spring%20cloud/Eureka/"/>
    <id>http://soda1.github.io/2023/03/29/spring/spring%20cloud/Eureka/</id>
    <published>2023-03-29T18:17:31.000Z</published>
    <updated>2023-04-13T11:54:18.700Z</updated>
    
    <content type="html"><![CDATA[<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>Eureka是Netflix开源的服务发现组件，本身是一个基于REST的服务，包含Server和Client两部分，Spring Cloud将它集成在子项目Spring Cloud Netflix中。</p><ul><li>Server：提供服务发现能力，各个微服务启动时，会向Eureka Server注册自己的信息（例如IP、端口、微服务名称等），Eureka Server会存储这些信息；</li><li>Client：用于简化与Eureka Server的交互，<strong>Eureka Client会缓存服务注册表中的信息</strong>，从而减轻Server的压力</li></ul><h4 id="交互方式"><a href="#交互方式" class="headerlink" title="交互方式"></a>交互方式</h4><ul><li><p>微服务启动后，会周期性（<strong>默认30秒</strong>）地向Eureka Server发送心跳以续约自己的“租期”；</p></li><li><p>如果Eureka Server在一定时间内没有接收到某个微服务实例的心跳，Eureka Server将会注销该实例（<strong>默认90秒</strong>）；</p></li><li><p>自我保护模式</p><p>默认情况下，如果90秒内没有接收到实例的心跳包，那么Server就会将实例移除。考虑如下情况：实例正常运行，但由于分区发生故障时，短时间内无法于Server通信，如果断然将实例移除，这种行为将是有害的。Eureka采用自我保护模式来解决此问题，从而使集群更加健壮的运行</p></li></ul><p><strong>开启配置</strong></p><p>配置<code>eureka.server.enable-self-preservation = true</code>开启</p><p><strong>激活条件</strong></p><p>在1分钟后<code>Renew(last min) &lt; Renew threshold</code></p><ul><li><code>Renews threshold</code>：<strong>Eureka Server 期望每分钟收到客户端实例续约的最小值</strong>。</li><li><code>Renews (last min)</code>：<strong>Eureka Server 最后 1 分钟收到客户端实例续约的总数</strong>。</li></ul><p>计算公式</p><pre><code>this.expectedNumberOfRenewsPerMin = count * expectedClientRenewalIntervalSeconds / 60;this.numberOfRenewsPerMinThreshold = (int) (this.expectedNumberOfRenewsPerMin * serverConfig.getRenewalPercentThreshold());</code></pre><p><code>count</code>为注册的服务数量，<code>expectedClientRenewalIntervalSeconds</code>是心跳发送间隔，<code>serverConfig.getRenewalPercentThreshold()</code>默认是 0.85（可以通过<code>eureka.server.renewal-percent-threshold</code>配置。</p><p>例子：</p><p>假设<code>count = 10</code>， <code>expectedClientRenewalIntervalSeconds = 30s</code> ，则<code>Renews threshold = 10 * 2 * 0.85 = 17</code>，如果每分钟收到的实例续约值小于17，就会触发自我保护模式</p><h4 id="Eureka集群引入"><a href="#Eureka集群引入" class="headerlink" title="Eureka集群引入"></a>Eureka集群引入</h4><ol><li><p>加依赖</p><pre><code class="xml">   &lt;dependencies&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;           &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;       &lt;/dependency&gt;   &lt;/dependencies&gt;</code></pre></li><li><p>加注解</p><pre><code class="java">@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123;   public static void main(String[] args) &#123;       SpringApplication.run(EurekaServerApplication.class,args);   &#125;&#125;</code></pre></li><li><p>配置</p><p>```yml<br>spring:<br> application:<br>   name: microservice-discovery-eureka-ha<br>eureka:<br> client:<br>   registerWithEureka: true<br>   fetchRegistry: false<br>   serviceUrl:</p><pre><code> defaultZone: http://peer2:8086/eureka/,http://peer1:8085/eureka/</code></pre><p> server:<br>   enable-self-preservation: false #关闭自我保护<br>   eviction-interval-timer-in-ms: 1000</p><h1 id="renewal-threshold-update-interval-ms-2000"><a href="#renewal-threshold-update-interval-ms-2000" class="headerlink" title="renewal-threshold-update-interval-ms: 2000"></a>renewal-threshold-update-interval-ms: 2000</h1><p>   expected-client-renewal-interval-seconds: 15 #心跳间隔时间<br>   wait-time-in-ms-when-sync-empty: 60000 #自我保护触发后等待多长时间提示消息</p></li></ol><hr><p>  spring:<br>    profiles: peer1<br>  server:<br>    port: 8085<br>  eureka:<br>    instance:<br>      hostname: peer1</p><hr><p>  spring:<br>    profiles:  peer2<br>  server:<br>    port: 8086<br>  eureka:<br>    instance:<br>      hostname: peer2</p><pre><code>`peer1,peer2`为主机名#### Eureka客户端引入1. 加依赖```xml    &lt;dependencies&gt;           &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;            &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;</code></pre><ol start="2"><li><p>加注解</p><pre><code class="java">@SpringBootApplication@EnableEurekaClientpublic class ProviderApplication &#123;   public static void main(String[] args) &#123;       SpringApplication.run(ProviderApplication.class);   &#125;&#125;</code></pre></li><li><p>添加配置</p><pre><code class="yml">eureka: client:   service-url:     defaultZone: http://peer1:8085/eureka/   register-with-eureka: true</code></pre></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h4&gt;&lt;p&gt;Eureka是Netflix开源的服务发现组件，本身是一个基于REST的服务，包含Server和Client两部分，Spring Cloud</summary>
      
    
    
    
    <category term="spring cloud" scheme="http://soda1.github.io/categories/spring-cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>开篇</title>
    <link href="http://soda1.github.io/2023/03/29/spring/spring%20cloud/%E5%BC%80%E7%AF%87/"/>
    <id>http://soda1.github.io/2023/03/29/spring/spring%20cloud/%E5%BC%80%E7%AF%87/</id>
    <published>2023-03-29T17:52:58.000Z</published>
    <updated>2023-04-13T11:54:18.700Z</updated>
    
    <content type="html"><![CDATA[<h4 id="微服务概念"><a href="#微服务概念" class="headerlink" title="微服务概念"></a>微服务概念</h4><p>微服务是以业务为维度将单体应用拆分为多个应用，每个应用独立运行，它们之间通过HTTP或RPC进行通信。从而使得开发变得灵活</p><p>微服务的特点：</p><ul><li>单一职责：微服务中每一个服务都对应唯一的业务能力，做到单一职责</li><li>微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务。每个服务虽小，但“五脏俱全”。</li><li>面向服务：面向服务是说每个服务都要对外暴露Rest风格服务接口API。并不关心服务的技术实现，做到与平台和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可。</li><li>自治：自治是说服务间互相独立，互不干扰</li></ul><h4 id="Spring-Cloud"><a href="#Spring-Cloud" class="headerlink" title="Spring Cloud"></a>Spring Cloud</h4><p>Spring Cloud是基于Spring Boot实现的微服务开发工具集，它提供了包括服务发现、负载均衡、配置管理、断路器等功能。为微服务开发提供的整套解决方案</p><h5 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h5><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230329180517.png" loading="lazy"></p><p>以<strong>伦敦的地铁名+  小版本</strong>的命名方式，RC（Release Candidate）表示接近准备发正式版的版本，SR（Service Release）表示主版本。Spring Cloud是一个综合项目，它包含很多的子项目，每个子项目下维护着自己的版本号，采用这种方式可以避免和子项目版本混淆</p><h5 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h5><ol><li><p><strong>对于懒人，可使用Spring Initilizr</strong>（IDEA、Spring Tool Suite等IDE上均有集成，也可在<a href="http://start.spring.io/">http://start.spring.io</a> 使用网页版）创建应用，它会给你生成项目的依赖以及项目的骨架。</p></li><li><p>创建Maven工程，在POM文件中使用如下配置</p><pre><code class="xml">&lt;properties&gt;    &lt;spring.cloud-version&gt;Hoxton.SR8&lt;/spring.cloud-version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;            &lt;version&gt;$&#123;spring.cloud-version&#125;&lt;/version&gt;            &lt;type&gt;pom&lt;/type&gt;            &lt;scope&gt;import&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/dependencyManagement&gt;</code></pre><p>至此可以可以使用你要使用的组件了，比如依赖Eureka</p><pre><code class="xml">&lt;dependencies&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;微服务概念&quot;&gt;&lt;a href=&quot;#微服务概念&quot; class=&quot;headerlink&quot; title=&quot;微服务概念&quot;&gt;&lt;/a&gt;微服务概念&lt;/h4&gt;&lt;p&gt;微服务是以业务为维度将单体应用拆分为多个应用，每个应用独立运行，它们之间通过HTTP或RPC进行通信。从而使得开发变</summary>
      
    
    
    
    <category term="spring cloud" scheme="http://soda1.github.io/categories/spring-cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>JVM调优</title>
    <link href="http://soda1.github.io/2023/03/12/java/jvm/JVM%E8%B0%83%E4%BC%98/"/>
    <id>http://soda1.github.io/2023/03/12/java/jvm/JVM%E8%B0%83%E4%BC%98/</id>
    <published>2023-03-12T02:26:35.000Z</published>
    <updated>2023-04-13T11:54:18.696Z</updated>
    
    <content type="html"><![CDATA[<h4 id="调优原则"><a href="#调优原则" class="headerlink" title="调优原则"></a>调优原则</h4><p>JVM调优不是常规手段，性能问题一般第一选择是优化程序，最后的选择才是进行JVM调优。</p><h4 id="调优时机"><a href="#调优时机" class="headerlink" title="调优时机"></a>调优时机</h4><ul><li>Heap内存（老年代）持续上涨达到设置的最大内存值；</li><li>Full GC 次数频繁；</li><li>GC 停顿时间过长（超过1秒）；</li><li>应用出现OutOfMemory 等内存异常；</li><li>应用中有使用本地缓存且占用大量内存空间；</li><li>系统吞吐量与响应性能不高或下降。</li></ul><h4 id="调优指标"><a href="#调优指标" class="headerlink" title="调优指标"></a>调优指标</h4><ul><li>延迟：GC低停顿和GC低频率</li><li>低内存占用</li><li>高吞吐量</li></ul><p>三者不可兼得，任何一个属性提高，几乎是于其他属性的性能损失为代价</p><h4 id="调优步骤"><a href="#调优步骤" class="headerlink" title="调优步骤"></a>调优步骤</h4><p>一般情况下，JVM调优可通过以下步骤进行：</p><ul><li>分析GC日志及dump文件，判断是否需要优化，确定瓶颈问题点；</li><li>确定JVM调优量化目标；</li><li>确定JVM调优参数（根据历史JVM参数来调整）；</li><li>依次调优内存、延迟、吞吐量等指标；</li><li>对比观察调优前后的差异；</li><li>不断的分析和调整，直到找到合适的JVM参数配置；</li><li>找到最合适的参数，将这些参数应用到所有服务器，并进行后续跟踪。</li></ul><h4 id="JVM参数"><a href="#JVM参数" class="headerlink" title="JVM参数"></a>JVM参数</h4><p>一般调优都是调整JVM堆参数</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230312025734.png" loading="lazy"></p><p><strong>1.8版本</strong></p><p>在1.8版本中Permanent generation已经被Meta space替换了，Meta space参数如下</p><table><thead><tr><th align="left">参数名称</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">-XX:MetaspaceSize</td><td align="left">初始元空间大小</td></tr><tr><td align="left">-XX:MaxMetaspaceSize</td><td align="left">最大元空间</td></tr></tbody></table><p><strong>语法规则</strong></p><p>布尔类型参数值：</p><ul><li>-XX:+ ‘+’表示启用该选项</li><li>-XX:- ‘-‘表示关闭该选项</li></ul><p>数字类型参数值：</p><ul><li>-XX:=给选项设置一个数字类型值，可跟随单位，例如：’m’或’M’表示兆字节;’k’或’K’千字节;’g’或’G’千兆字节。32K与32768是相同大小的。</li></ul><p>字符串类型参数值：</p><ul><li>-XX:=给选项设置一个字符串类型值，通常用于指定一个文件、路径或一系列命令列表。例如：-XX:HeapDumpPath=./dump.core</li></ul><p>示例：</p><pre><code class="bash">java  -Xmx4g –Xms4g –Xmn1200m –Xss512k -XX:NewRatio=4 -XX:SurvivorRatio=8 -XX:PermSize=100m -XX:MaxPermSize=256m -XX:MaxTenuringThreshold=15 -jar xxx.jar</code></pre><h4 id="性能监控工具"><a href="#性能监控工具" class="headerlink" title="性能监控工具"></a>性能监控工具</h4><p><strong>JDK自带工具</strong></p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230312031532.png" loading="lazy"></p><p>Linux命令行工具</p><table><thead><tr><th align="left">命令</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">top</td><td align="left">实时显示正在执行进程的 CPU 使用率、内存使用率以及系统负载等信息</td></tr><tr><td align="left">vmstat</td><td align="left">对操作系统的虚拟内存、进程、CPU活动进行监控</td></tr><tr><td align="left">pidstat</td><td align="left">监控指定进程的上下文切换</td></tr><tr><td align="left">iostat</td><td align="left">监控磁盘IO</td></tr></tbody></table><p>参考：</p><p><a href="https://www.alibabacloud.com/blog/how-to-properly-plan-jvm-performance-tuning_594663" title="How to Properly Plan JVM Performance Tuning">How to Properly Plan JVM Performance Tuning</a></p><p><a href="https://cloud.tencent.com/developer/article/1812722" title="JVM调优总结">JVM调优总结</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;调优原则&quot;&gt;&lt;a href=&quot;#调优原则&quot; class=&quot;headerlink&quot; title=&quot;调优原则&quot;&gt;&lt;/a&gt;调优原则&lt;/h4&gt;&lt;p&gt;JVM调优不是常规手段，性能问题一般第一选择是优化程序，最后的选择才是进行JVM调优。&lt;/p&gt;
&lt;h4 id=&quot;调优时机&quot;&gt;</summary>
      
    
    
    
    <category term="java" scheme="http://soda1.github.io/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>JVM Architecture</title>
    <link href="http://soda1.github.io/2023/03/10/java/jvm/jvm%20architecture/"/>
    <id>http://soda1.github.io/2023/03/10/java/jvm/jvm%20architecture/</id>
    <published>2023-03-10T13:20:55.000Z</published>
    <updated>2023-04-13T11:54:18.696Z</updated>
    
    <content type="html"><![CDATA[<h4 id="结构图"><a href="#结构图" class="headerlink" title="结构图"></a>结构图</h4><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230310143101.png" loading="lazy"></p><p>JVM架构如图所示，主要分为ClassLoader Subsystem， Runtime Data Area，Execution Engine</p><h4 id="ClassLoader-Subsystem"><a href="#ClassLoader-Subsystem" class="headerlink" title="ClassLoader Subsystem"></a>ClassLoader Subsystem</h4><p>它的职能主要是动态加载创建类对象，类在第一次被引用时就需要创建类对象，一个类对象被创建包含Loading、Linking、initialization三个阶段。</p><h5 id="Loading"><a href="#Loading" class="headerlink" title="Loading"></a>Loading</h5><p>在Loading阶段有3个类加载器用来加载Class文件</p><ol><li><p>BootStrap ClassLoader（启动类加载器）</p><p>加载<code>$JAVA_HOME/jre/lib</code>路径的核心类（rt.jar etc)，它是所有加载器的顶级父类</p></li><li><p>Extension ClassLoader（扩展类加载器）</p><p>加载<code>$JAVA_HOME/jre/lib/ext</code>路径下的类或在系统属性<code>java.ext.dirs</code>列出的目录，它的上层父类是BootStrap ClassLoader</p></li><li><p>Application ClassLoader（应用程序类加载器）</p><p>现在叫做System ClassLoader，用于加载应用路径下的类，它的上层父类是Extension ClassLoader</p></li></ol><h5 id="Delegation-Hierarchy-Algorithm"><a href="#Delegation-Hierarchy-Algorithm" class="headerlink" title="Delegation Hierarchy Algorithm"></a><strong>Delegation Hierarchy Algorithm</strong></h5><p>中文习惯叫双亲委派机制，哪个家伙起的名，真的谢谢。<strong>主要思想就是在需要加载一个类的时候优先由其父类加载器进行尝试加载，如果父类加载器不能加载才有当前类路径下的加载器进行加载</strong></p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230310173929.jpg" loading="lazy"></p><p>目的：避免同一个类被多次加载，保证Java稳定允许</p><h5 id="Linking"><a href="#Linking" class="headerlink" title="Linking"></a>Linking</h5><ol><li><p>Verify</p><p>验证class文件中的字节流是否符合虚拟机的要求，包括有<strong>文件格式的验证，元数据的验证，字节码验证，符号引用验证</strong></p></li><li><p>Prepare</p><p>对静态变量进行内存分配，并赋予初始值</p></li><li><p>Resolve</p><p>将方法区对象内的运行时常量池中的符号引用解析成直接引用</p><blockquote><p>When a Java class is compiled, all references to variables and methods are stored in the class’s constant pool as a symbolic reference. A symbolic reference is a logical reference not a reference that actually points to a physical memory location. The JVM implementation can choose when to resolve symbolic references, this can happen when the class file is verified, after being loaded, called eager or static resolution, instead this can happen when the symbolic reference is used for the first time called lazy or late resolution. However the JVM has to behave as if the resolution occurred when each reference is first used and throw any resolution errors at this point. Binding is the process of the field, method or class identified by the symbolic reference being replaced by a direct reference, this only happens once because the symbolic reference is completely replaced. If the symbolic reference refers to a class that has not yet been resolved then this class will be loaded. Each direct reference is stored as an offset against the storage structure associated with the runtime location of the variable or method.</p></blockquote></li></ol><h5 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h5><p>所有静态变量都会被赋予初始值，静态代码块将会被执行</p><h4 id="Runtime-Data-Area"><a href="#Runtime-Data-Area" class="headerlink" title="Runtime Data Area"></a>Runtime Data Area</h4><p>这个是Java内存管理区域，以下图分析会比较清晰</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230311015106.png" loading="lazy"></p><p><strong>Non Heap</strong></p><ul><li><p>method area</p><p>方法区用于存储每个Class对象的信息：</p><ul><li>Classloader Reference</li><li>Field data</li><li>Run Time Constant Pool</li><li>Method data</li><li>Method code</li></ul></li><li><p>interned String 字符串常量池，在1.8版本它被移到Heap里面了</p></li></ul><p>**Heap **</p><p>所有的对象实例都会存储在堆这里，为所有线程共享</p><p>generation及垃圾回收内容查看<a href="#Garbage-Collector">Garbage Collector</a></p><p><strong>Stack</strong></p><p>每个线程都有以下三个组件</p><ol><li><p>Program Counter</p><p>PC用于存储当前指令运行位置的，如果当前调用的native方法，那么PC值为undefine，JVM用PC来跟踪其执行指令位置，方便在线程在获得cpu时间片后继续运行下去</p></li><li><p>Stack</p><p>按照先进后出规则执行，由存储调用方法的栈帧组成，每个栈帧包含如下信息：</p><ul><li>本地变量数组（基本类型，对象引用）</li><li>返回值</li><li>操作数栈</li><li>执行方法地址</li></ul></li><li><p>Native Stack</p><p>类似于Stack</p></li></ol><h4 id="Execution-Engine"><a href="#Execution-Engine" class="headerlink" title="Execution Engine"></a>Execution Engine</h4><h5 id="Interpreter"><a href="#Interpreter" class="headerlink" title="Interpreter"></a><strong>Interpreter</strong></h5><p>用于解释字节码，将其转换成系统识别指令，使其能运行。缺点在于每次执行方法都要先解释一遍</p><h5 id="JIT-Compiler"><a href="#JIT-Compiler" class="headerlink" title="JIT Compiler"></a><strong>JIT Compiler</strong></h5><p>用于改正解释器缺点，当代码第一次运行时会使用解释器来解释代码，后面如果发现有重复代码时，会使用JIT编译器，将代码编译成native code。native code将直接用于重复方法的调用，从而提高系统性能</p><h5 id="Garbage-Collector"><a href="#Garbage-Collector" class="headerlink" title="Garbage Collector"></a><strong>Garbage Collector</strong></h5><p>垃圾回收器用于回收无用对象，从而释放内存，防止内存泄露。Java中的垃圾回收是自动的，也可以通过调用<code>System.gc()</code>来触发</p><h6 id="无用对象定义"><a href="#无用对象定义" class="headerlink" title="无用对象定义"></a><strong>无用对象定义</strong></h6><p>在Java中有一些对象被称为 <strong>Garbage Collection Roots</strong>（GC Roots)，它们在垃圾回收中被作为Root对象来用于进行可达性分析。如下图所示，如果一个对象和任何GC Root间不存在<strong>引用链</strong>，那么就说明该对象是无用对象</p><blockquote><p>Every object tree must have one or more root objects. As long as the application can reach those roots, the whole tree is reachable.But when are those root objects considered reachable? Special objects called garbage-collection roots (GC roots; see Figure below) are always reachable and so is any object that has a garbage-collection root at its own root.</p></blockquote><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230311031540.jpg" loading="lazy"></p><p>有4种类型GC Roots</p><ul><li>Local variables</li><li>Static variables</li><li>Active Java threads </li><li>JNI References</li></ul><p><strong>回收器针对Java引用类型回收策略</strong></p><ul><li><p>Strong Reference（强引用）</p><p>只要可达GC root就不会回收</p></li><li><p>Soft Reference（软引用）</p><p>内存空间不足的时候就会被回收</p></li><li><p>Weak Reference（弱应用）</p><p>只要被垃圾回收期扫描到就会回收</p></li><li><p>Phantom Reference（虚引用）</p><p>任何时候都会被回收</p></li></ul><h6 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h6><ul><li><p>标记 — 清除算法</p><p>将可回收对象先标记出来，然后再清除。这种算法会造成内存碎片，导致本来有足够的容量来分配给新的对象，但却无法分配</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230311033334.png" loading="lazy"></p></li><li><p>复制算法</p><p>复制算法从标记-清除算法演进而来，解决了内存碎片化问题。将内存分为均等两块，每次只用一块，当一块内存用完时，就将存活的对象搬到另一块去，然后把直接清理内存空间。算法的弊端在于只能使用一半的内存</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230311033405.png" loading="lazy"></p></li><li><p>标记整理算法</p><p>标记整理算法中标记过程和标记清除算法一致，然后整理时存活对象会向一端移动，最后清除存活对象边界以外的内存区域。由于内存的频繁移动，在效率上会比复制算法差</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230311033431.png" loading="lazy"></p></li></ul><h6 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h6><p>大多数对象的生命周期都是非常短的，只有少部分的对象会一直存在，因此JVM将Heap分成了几部分，如下面官方图所示</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230311160312.png" loading="lazy"></p><ul><li><p>Young Generation</p><p>新创建对象会被分配在年轻代的Eden区里面，当Eden区满后会触发Minor GC，存活下来的对象会进入Survivor区且被标记年龄 = 1，而原先在Survivor区继续存活下来的对象则年龄+1，然后将Eden区清空</p><p>Survivor区又细分为S0和S1两个区，原因在于Survivor区的对象也会有被清理掉的可能性，这样会产生内存碎片，JVM采用了复制算法来整理内存</p><p>在经历多轮的GC后，Survivor中存活的对象一旦达到年轻代设置的年龄上限后会进入老年代，还有一些特殊的情况会直接进入老年区：</p><ul><li>当对象无法放入Survivor区</li><li>当大对象无法放入清理后的Eden区</li></ul><p>年轻代Minor GC具体流程查看<a href="https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html">Java Garbage Collection Basics</a></p></li><li><p>Old Generation</p><p>老年代用于放置长期存活的对象，当老年代无法存放新的对象时会触发Major GC，对老年代进行垃圾回收，释放内存</p></li><li><p>Permanent generation</p><p>永久代存储的是Class对象及方法，对应JVM结构中的方法区，触发Full GC时会对永久代进行垃圾回收</p><p>永久代不属于Heap，上面的官方图是从generation的角度来解释其内存结构，下面图可以很好描述</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230311171414.png" loading="lazy"></p><p>在1.8版本使用 Meta space来替代Permanent generation</p></li></ul><h6 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h6><ul><li><p>The Serial GC</p><p>串行化收集器，Minor 和Major GC都是串行进行的，即单线程。使用标记整理算法，存在Stop The World问题</p><p>应用场景：适合客户端模式下的虚拟机（需要比较少的内存）</p><p>使用：<code>-XX:+UseSerialGC</code></p></li><li><p>The Parallel GC</p><p>并行收集器使用多线程来对年轻代进行垃圾回收，默认使用CPU个数的线程进程回收，存在Stop The World问题</p><p>应用场景：适用于追求高吞吐量，不需要太多交互</p><p>使用：</p><ul><li><code>-XX:+UseParallelGC</code>：年轻代回收使用多线程，老年代回收使用的单线程</li><li><code>-XX:+UseParallelOldGC</code>：年轻代老年代都是用多线程</li></ul><p>老年代都使用标记-整理算法，年轻代用复制算法</p></li><li><p>The Concurrent Mark Sweep (CMS) Collector</p><p>CMS是一种以并发的方式进行垃圾回收，以最短回收卡顿时间为目标的收集器，主要用于老年代，采用标记-清除算法，会造成碎片化问题，引发Full GC，导致临时使用Serial GC进行老年代垃圾回收</p><p>CMS用于年轻代时和并行收集器采用同样算法</p><p>应用场景：重视服务器响应速度，要求系统停顿时间最短。</p><p>使用：<code>-XX:+UseConcMarkSweepGC</code></p></li><li><p>The G1 Garbage Collector</p><p>G1收集器设计用于取代CMS，具有并发、并行，低卡顿时间等特点。G1整体来看使用标记-整理算法，局部使用复制算法</p><p>应用场景：面向服务端应用</p><p>使用：<code>-XX:+UseG1GC</code></p></li></ul><p>参考：</p><p><a href="https://dzone.com/articles/jvm-architecture-explained" title="The JVM Architecture Explained">The JVM Architecture Explained</a></p><p><a href="https://blog.jamesdbloom.com/JVMInternals.html" title="JVM Internals">JVM Internals</a></p><p><a href="https://dzone.com/articles/jvm-memory-architecture-and-gc" title="JVM Memory Architecture and GC Algorithm Basics">JVM Memory Architecture and GC Algorithm Basics</a></p><p><a href="https://dzone.com/articles/java-memory-management" title="Java Memory Management">Java Memory Management</a></p><p><a href="https://www.w3resource.com/java-tutorial/garbage-collection-in-java.php" title="Garbage Collection in Java">Garbage Collection in Java</a></p><p><a href="https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html" title="Java Garbage Collection Basics">Java Garbage Collection Basics</a></p><p><a href="https://blog.jamesdbloom.com/JVMInternals.html" title="JVM Internals"></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;结构图&quot;&gt;&lt;a href=&quot;#结构图&quot; class=&quot;headerlink&quot; title=&quot;结构图&quot;&gt;&lt;/a&gt;结构图&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/soda1/img/main/2023031</summary>
      
    
    
    
    <category term="java" scheme="http://soda1.github.io/categories/java/"/>
    
    
  </entry>
  
  <entry>
    <title>mysql扩容</title>
    <link href="http://soda1.github.io/2023/03/09/mysql/%E9%AB%98%E7%BA%A7/mysql%E6%89%A9%E5%AE%B9/"/>
    <id>http://soda1.github.io/2023/03/09/mysql/%E9%AB%98%E7%BA%A7/mysql%E6%89%A9%E5%AE%B9/</id>
    <published>2023-03-09T19:03:42.000Z</published>
    <updated>2022-05-28T20:34:11.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h4><p>当单表数据量过大时，性能会受到比较大的影响。分库分表指的是将单表的数据通过某种规则平均的分散在多个数据库或多张表中。</p><h4 id="水平分"><a href="#水平分" class="headerlink" title="水平分"></a><strong>水平分</strong></h4><h5 id="水平分表"><a href="#水平分表" class="headerlink" title="水平分表"></a><strong>水平分表</strong></h5><p>场景：当单表仅仅是因为数据量过大时，影响SQL查询效率</p><p>理论：以字段为依据，按照一定策略（hash、range等），将一个表中的数据以行为单位拆分到多个表中，尽可能的让数据均匀分布</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230310104313.jpg" loading="lazy"></p><h5 id="水平分库"><a href="#水平分库" class="headerlink" title="水平分库"></a>水平分库</h5><p>场景：系统绝对并发量上来了，网络IO成为了瓶颈</p><p>理论：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中，从而将网络请求摊分到多个库中</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230310104511.jpg" loading="lazy"></p><h4 id="垂直分"><a href="#垂直分" class="headerlink" title="垂直分"></a>垂直分</h4><h5 id="垂直分表"><a href="#垂直分表" class="headerlink" title="垂直分表"></a>垂直分表</h5><p>场景：当表中记录不多时，由于字段比较多，单行存储空间比较大，产生IO瓶颈</p><p>理论：以字段为依据，按字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中，一般用主键来将主表和扩展表关联在一起</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230310105634.jpg" loading="lazy"></p><h5 id="垂直分库"><a href="#垂直分库" class="headerlink" title="垂直分库"></a>垂直分库</h5><p>场景：系统绝对并发量上来了，并且可以按业务抽象出单独的模块</p><p>理论：以表为依据，按业务归属，将不同表划分到不同库中</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230310110314.jpg" loading="lazy"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;分库分表&quot;&gt;&lt;a href=&quot;#分库分表&quot; class=&quot;headerlink&quot; title=&quot;分库分表&quot;&gt;&lt;/a&gt;分库分表&lt;/h4&gt;&lt;p&gt;当单表数据量过大时，性能会受到比较大的影响。分库分表指的是将单表的数据通过某种规则平均的分散在多个数据库或多张表中。&lt;/p&gt;</summary>
      
    
    
    
    <category term="mysql" scheme="http://soda1.github.io/categories/mysql/"/>
    
    <category term="adv" scheme="http://soda1.github.io/categories/mysql/adv/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka进阶</title>
    <link href="http://soda1.github.io/2023/03/01/kafka/02.%E8%BF%9B%E9%98%B6/"/>
    <id>http://soda1.github.io/2023/03/01/kafka/02.%E8%BF%9B%E9%98%B6/</id>
    <published>2023-03-01T15:15:20.000Z</published>
    <updated>2023-03-06T19:56:48.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="分区机制"><a href="#分区机制" class="headerlink" title="分区机制"></a>分区机制</h4><p>分区的作用主要是为了提高负载均衡的能力，数据的读写都是在分区这个粒度上进行的，从而实现了系统的可伸缩性</p><h5 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h5><p>分区策略决定者生产者将消息发送至哪个区，如果生产者要定义一个分区策略，要在客户端实现<code>org.apache.kafka.clients.producer.Partitioner</code>接口，常见分区策略如下：</p><ul><li><p>轮询策略（ Round-robin）</p><p>Kafka默认策略，顺序分配，就是取余操作，$ partition_index = n % partition_num $，n表示第n条消息。轮询策略有着很好的负载均衡表现。</p></li><li><p>随机策略（Randomness）</p><p>随机返回一个partition</p></li><li><p>按消息键保序策略</p><p>Kafka允许为每条消息都定义一个消息键，可以通过对键进行hash从而保存到特定的partition中。这也是Kafka的默认策略之一，假设客户端没有自定义策略，如果是消息中带着Key，那么就会执行这个策略，否则就使用轮询策略</p></li></ul><p>spring boot实现例子</p><pre><code class="java">public class MyPartitioner implements Partitioner &#123;    @Override    public int partition(String s, Object o, byte[] bytes, Object o1, byte[] bytes1, Cluster cluster) &#123;        List&lt;PartitionInfo&gt; partitionInfos = cluster.availablePartitionsForTopic(s);        int num = ThreadLocalRandom.current().nextInt(partitionInfos.size());        System.out.println(num);        return num;    &#125;    .........&#125;</code></pre><p>配置partitioner路径，这个在yml中没有找到属性，用代码来配置</p><pre><code class="java">    @Bean    public Map&lt;String, Object&gt; producerConfigs() &#123;        Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;192.168.3.100:9092&quot;);        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class);        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);        props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyPartitioner.class);        // See https://kafka.apache.org/documentation/#producerconfigs for more properties        return props;    &#125;    @Bean    public ProducerFactory&lt;Integer, String&gt; producerFactory() &#123;        return new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs());    &#125;    @Bean    public KafkaTemplate&lt;Integer, String&gt; kafkaTemplate() &#123;        return new KafkaTemplate&lt;Integer, String&gt;(producerFactory());    &#125;</code></pre><h4 id="消息解压缩"><a href="#消息解压缩" class="headerlink" title="消息解压缩"></a>消息解压缩</h4><ul><li><p>Producer端压缩</p><p>Producer客户端开启压缩算法只要在<code>compression.type</code>配置指定的类型算法即可，在Producer端配置好处在于有利于网络传输</p></li><li><p>Broker端压缩</p><p>Broker也有可能会对消息进行压缩，有如下情况</p><p>情况1：Broker端和Producer端压缩算法不一致产生</p><p>情况2：因消息版本不同原因发生的兼容格式转换产生</p></li><li><p>Broker端解压</p><p>Broker端需要对接收到的消息进行验证，比如CRC校验，因此会解压消息</p></li><li><p>Consumer端解压</p><p>Consumer消费消息需要先解压还原消息</p></li></ul><p>消息解压缩整个流程可以概况为一句话：Producer 端压缩、Broker 端保持、Consumer 端解压。</p><p>压缩算法比较</p><p>吞吐量：LZ4 &gt; Snappy &gt; zstd 和 GZIP</p><p>压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy</p><h4 id="无消息丢失配置"><a href="#无消息丢失配置" class="headerlink" title="无消息丢失配置"></a>无消息丢失配置</h4><p>Producer</p><ul><li>Producer发送消息要使用带回调的send(msg, callback)</li><li>Producer设置acks=all，表示所有in-sync replicas都已经接收到消息了，消息才算发送成功</li><li>Producers设置retries，消息发送失败时应当重试多次，还不行再另作处理</li></ul><p>Broker端</p><ul><li><p>unclean.leader.election.enable = false，落后太多的副本不应当竞选leader</p></li><li><p>replication.factor &gt;= 3，将副本多保存几份</p></li><li><p>min.insync.replicas &gt; 1，这个配置是保证当Producer的ack=all时，Broker端至少存在多少个in-sync replicas才能进行写入。可参考<a href="https://accu.org/journals/overload/28/159/kozlovski/" title="Kafka Acks Explained">文章</a>。</p><p>要配置replication.factor &gt; min.insync.replicas，否则一个副本挂了分区就不可用了。推荐成replication.factor = min.insync.replicas + 1</p></li></ul><p>Consumer</p><ul><li>enable.auto.commit设置为false，改为手动提交，并采用手动提交位移</li></ul><h4 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h4><p>todo</p><h4 id="Producer一次发送流程"><a href="#Producer一次发送流程" class="headerlink" title="Producer一次发送流程"></a>Producer一次发送流程</h4><p>步骤如下：</p><ol><li>构造生产者对象所需的参数对象</li><li>根据参数创建KafkaProducer对象实例</li><li>调用send方法发送消息</li><li>调用close方法释放资源</li></ol><p>深入：</p><ol><li>在创建KafkaProducer对象时后台会创建一个名为Seeder的线程，该线程会与 bootstrap.servers配置的所有Broker进行Tcp连接，用于获取集群元数据信息。</li><li>Producer会通过metadata.max.age.ms 参数来定期地去更新元数据信息，默认时5分钟。</li><li>在发送消息时，Producer会从元数据缓存中找到需要发送的Broker信息，建立Tcp连接来发送信息</li></ol><h4 id="Message-Delivery-Semantics"><a href="#Message-Delivery-Semantics" class="headerlink" title="Message Delivery Semantics"></a>Message Delivery Semantics</h4><p>有如下三种语义保证：</p><ul><li><p>最多一次（at most once）：消息可能会丢失，但绝不会被重复发送</p></li><li><p>至少一次（at least once）：消息不会丢失，但有可能被重复发送</p></li><li><p>精确一次（exactly once）：消息不会丢失，也不会被重复发送</p></li></ul><p>Kafka默认提供at least once的可靠性保证，提供了重试的机制。</p><h5 id="Kafka如何保证exactly-once"><a href="#Kafka如何保证exactly-once" class="headerlink" title="Kafka如何保证exactly once"></a>Kafka如何保证exactly once</h5><h6 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h6><p>在0.11版本开始支持，Broker给每个Producer分配一个ID，且Producer的每条信息都会有一个序列号用来去重信息。可以通过指定<code>enable.idempotence=true</code>来配置幂等Producer</p><p>Kafka只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区 上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不 能实现跨会话的幂等性。这里的会话，你可以理解为 Producer 进程的一次运行。当你重启了 Producer 进程之后，这种幂等性保证就丧失了。</p><h6 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h6><p>从0.11版本开始支持，通过<code>置 isolation.level</code>来设置事务级别，有以下参数</p><ul><li>read_uncommitted：默认值，表明Consumer可以读取事务型Producer写入的任何消息</li><li>read_committed：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消 息</li></ul><p>事务型Producer通过流程代码控制，类似mysql那样(begin, commit)</p><p>事务可以保证跨分区，跨会话的幂等。</p><h4 id="消费机制"><a href="#消费机制" class="headerlink" title="消费机制"></a>消费机制</h4><h5 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h5><p>Consumer Group 是 Kafka 提供的可扩展且具 有容错性的消费者机制。每个组都有一个Group ID， 组内存在多个消费实例共同消费Topic所有的Partition，<strong>一个Partition只能被分配给组内一个Consumer消费</strong>。</p><h6 id="实现两大模型"><a href="#实现两大模型" class="headerlink" title="实现两大模型"></a>实现两大模型</h6><p>Consumer Group是Kafka实现两个模型的机制</p><ul><li>只有一个组进行消费Topic，那么就是队列模型</li><li>多个组消费Topic，那么就是发布/订阅模型</li></ul><h5 id="Standalone-Consumer"><a href="#Standalone-Consumer" class="headerlink" title="Standalone Consumer"></a>Standalone Consumer</h5><p>相当于只有一个Consumer的消费组，也需要Group ID标识</p><h5 id="consumer-offsets"><a href="#consumer-offsets" class="headerlink" title="_consumer_offsets"></a>_consumer_offsets</h5><p>_consumer_offsets是Kafka内部Topic，它的主要作用就是为了保持Consumer消费的位移信息，它是一个普通的Topic，可以对它进行操作，但请不要这么做</p><ol><li><p>创建时机</p><p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题，默认分区数是50，副本数3。可以通过<code>offsets.topic.num.partitions</code>、<code>offsets.topic.replication.factor</code>配置，但不建议</p></li><li><p>消息格式</p><ul><li><p>位移信息格式</p><p>保存的消息格式是KV对，Key用&lt;Group ID, Topic, Partition&gt;来标识， Value保存位移值</p></li><li><p>保存 Consumer Group 信息的消息</p><p>用于注册Consumer Group</p></li><li><p>tombstone消息</p><p>删除 Group 过期位移甚至是删除 Group 的消息</p></li></ul></li><li><p>Group数据保存在哪个区？</p><p>$$partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)$$</p></li><li><p>Compact 策略</p><p>Kafka 使用Compact 策略来删除位移主题中的过期消息，避免该主题无限期 膨胀。过期定义：对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志 的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。</p><p>Kafka 提供了专门的后台线程（ Log Cleaner）定期地巡检待 Compact 的主题，看看是否存在满足条件的可删 除数据</p></li></ol><h5 id="Coordinator组件"><a href="#Coordinator组件" class="headerlink" title="Coordinator组件"></a>Coordinator组件</h5><p>每个Broker都有各自的Coordinator组件，它是专门为Consumer Group服务的，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理</p><p>如何知道Group被哪个Coordinator管理？</p><ol><li>确定由的哪个_consumer_offsets分区来保存该 Group 数据（_consumer_offsets保存算法）</li><li>找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。</li></ol><h5 id="Rebalance"><a href="#Rebalance" class="headerlink" title="Rebalance"></a>Rebalance</h5><p>Kafka对Consumer Group重新分配Partition的过程称为Rebalance。Rebalance 发生时，Group 下所有的 Consumer 实例都会协调在一起共同参与，在协调者组件的帮助下，完成订阅主题分区的分配</p><ol><li><p>何时触发？</p><ul><li>组成员数改变</li><li>订阅主题数改变</li><li>订阅主题分区数改变</li></ul></li><li><p>产生影响</p><p>在Rebalance过程中，所有的Consumer都会停止消费，如果有Consumer正在消费消息的话，将会导致消息重复消费问题</p></li><li><p>Coordinator如何判断Consumer实例退组</p><p>心跳机制，每个Consumer都会定期的向Coordinator发送心跳，如果不能及时发送心跳，那么Coordinator就会认为该Consumer退组，进而开始Rebalance。</p><p>Consumer端相关参数</p><ul><li><code>heartbeat.interval.ms</code>：心跳请求频率参数</li><li><code>max.poll.interval.ms</code>： 两次调 用 poll 方法的最大时间间隔。它的默认值是 5 分钟。在两次调用poll的间隔间，业务逻辑处理时间过长，超出配置值，那么Consumer就会自动退组</li><li><code>session.timout.ms</code>：存活时间间隔，默认10s。表明如果10s内没有任何心跳请求，Coordinator就判断Consumer已经退出</li></ul><p>推荐配置：</p><p><code>session.timeout.ms = 6s</code></p><p><code> heartbeat.interval.ms = 2s</code></p><p><code>max.poll.interval.ms</code>设置为业务逻辑处理最长时间</p></li></ol><h6 id="Rebalance要点"><a href="#Rebalance要点" class="headerlink" title="Rebalance要点"></a>Rebalance要点</h6><ul><li><p>通知机制</p><p>当发生Rebalance时，Coordinator将”REBALANCE_IN_PROGRESS“封装进心跳请求响应里面，Consumer也因此知道了重平衡马上就要开始了</p></li><li><p>Consumer Group状态机</p><p>Kafka为消费组定义了5种状态</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230303190703.png" loading="lazy"></p><p>状态机流转如下</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230303190823.png" loading="lazy"></p><p>一个消费者组最开始是 Empty 状态，当重平衡过程开启后，它会被置于 PreparingRebalance 状态等待成员加入，之后变更到 CompletingRebalance 状态等待分配方案，最后流转到 Stable 状态完成重平衡</p><p>如果组在Empty状态下的存在很长时间（整个组停掉长时间不在消费），位移数据可能会被删除</p></li></ul><h6 id="Consumer重平衡步骤"><a href="#Consumer重平衡步骤" class="headerlink" title="Consumer重平衡步骤"></a>Consumer重平衡步骤</h6><ol><li><p>加入组（JoinGroup请求）</p><p>每个组员都会将自己订阅信息上报，Coordinator会从组员中选出Leader Consumer，一般的第一个请求者。选举完后会将所有的订阅信息发送的Leaders Consumer，由其制定分配</p></li><li><p>等待Leader Consumers分配方案（SyncGroup请求）</p><p>Leaders Consumer完成分配方案后向Coordinate发送SyncGroup请求，同时其他组员也会发送SyncGroup请求，但没有实际内容。最后统一以响应的方式分发给所有组员</p></li></ol><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230303192421.png" loading="lazy"></p><center>JoinGroup请求</center><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230303192537.png" loading="lazy"></p><center>SyncGroup请求</center><h5 id="位移提交"><a href="#位移提交" class="headerlink" title="位移提交"></a>位移提交</h5><p><strong>Consumer需要为分配给它的每个分区提交各自的位移数据</strong>，用来表示消费进度。比如提交位移进度X表示X以下都已经被消费</p><p>提交方式：</p><ol><li><p>自动提交</p><p>自动提交保证at least one，这就意味着可能存在消息重复消费，比如Consumer 正在消费时宕机了，产生了Rebalance，分配完后其他Consumer会从它消费的所有Partition的最近一次提交位移处开始消费，从而导致重复消费</p><blockquote><p>By default, the consumer is configured to auto-commit offsets. Using auto-commit gives you “at least once” delivery: Kafka guarantees that no messages will be missed, but duplicates are possible. Auto-commit basically works as a cron with a period set through the <code>auto.commit.interval.ms</code> configuration property. If the consumer crashes, then after a restart or a rebalance, the position of all partitions owned by the crashed consumer will be reset to the last committed offset. When this happens, the last committed position may be as old as the auto-commit interval itself. Any messages which have arrived since the last commit will have to be read again. <a href="https://docs.confluent.io/platform/current/clients/consumer.html#ak-consumer-configuration">consumer doc</a></p></blockquote><p>通过<code> enable.auto.commit</code>设置是否开启，默认是开启的</p><p><code>auto.commit.interval.ms</code>表示自动提交间隔，默认值为5s</p><p>自动提交逻辑是在poll方法里面执行的，每次poll的时候都会判断是否需要自动提交，大概逻辑如下</p><pre><code>第一次poll        设置提交时间为5s后    +10s 第二次poll        两次poll间隔为10s，比5s大就自动提交，然后设置下次提交时间为15s</code></pre></li><li><p>手动提交</p><p>将<code>enable.auto.commit</code>设置为false即可，Kafka提供同步和异步提交两种方式</p><ul><li><p>同步提交</p><p>使用KafkaConsumer#commitSync方法，提供重试机制，同步提交会影响TPS</p></li><li><p>异步提交</p><p>使用 KafkaConsumer#commitAsync()方法，没有重试机制，异步方式重试机制是没有意义的</p><p>异步提交可能会导致消息丢失，Kafka提供回调函数，可以通过回调函数时进行失败逻辑处理</p></li></ul><p>将同步提交和异步提交结合</p><pre><code class="java">try&#123;    while (true) &#123;        ConsumerRecords&lt;String, String&gt; records =         consumer.poll(Duration.ofSeconds(1));         process(records); // 处理消息         commitAysnc(); // 使用异步提交规避阻塞     &#125;&#125; catch (Exception e) &#123;     handle(e); // 处理异常&#125; finally &#123;     try &#123;         consumer.commitSync(); // 最后一次提交使用同步阻塞式提交    &#125; finally &#123;         consumer.close();    &#125;&#125;</code></pre><p>也可以使用<code>commitSync(final Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</code>及<code>commitAsync(final Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, OffsetCommitCallback callback)</code>进行小批量提交，比如每消费一百条提交一次</p><pre><code class="java">private Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = new HashMap&lt;&gt;();int count = 0;……while (true) &#123;     ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));     for (ConsumerRecord&lt;String, String&gt; record: records) &#123;         process(record); // 处理消息         offsets.put(new TopicPartition(record.topic(), record.partition()),         new OffsetAndMetadata(record.offset() + 1)；         if（count % 100 == 0）             consumer.commitAsync(offsets, null); // 回调处理逻辑是 n         count++;    &#125;&#125;</code></pre></li></ol><p>自动提交和手动提交都无法避免消息重复消息问题，需要在业务上做去重</p><h5 id="Consumer建立TCP连接种类"><a href="#Consumer建立TCP连接种类" class="headerlink" title="Consumer建立TCP连接种类"></a>Consumer建立TCP连接种类</h5><p>有3类TCP连接</p><ol><li><p>发起 FindCoordinator 请求时（第一类）</p><p>创建TCP连接，发送FindCoordinator请求到<code>bootstrap.servers</code>的任意服务器，得到管理它的Broker元数据</p></li><li><p>连接Coordinator（第二类）</p><p>创建与Coordinator的TCP连接，这样才能开启组协调操作</p></li><li><p>消费消息时（第三类）</p><p>Consumer为每个要消费的分区创建于该分区领导者副本所在的Broker连接的TCP</p></li></ol><p>当第三类连接建立时，Consumer会kill掉第一类TCP连接</p><h5 id="消费进度监控"><a href="#消费进度监控" class="headerlink" title="消费进度监控"></a>消费进度监控</h5><ul><li>Lag：表示消费消息落后生产消息程度，比如产生了100万条消息，当前消费了80万条，那么消息滞后了20万条，即Lag=20w</li><li>Lead：表示最新消费消息的位移和分区第一条位移的差值，比如当前消费位移为5，第一条位移为0，那么Lead=5</li></ul><p>使用JMX监控</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230303160430.png" alt="image-20230303160423390" loading="lazy"></p><h4 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h4><p> Kafka采用了基于领导者的（Leader-based）的副本机制。</p><ol><li>副本分为Leader和Follower副本，Follower会自动追随Leader</li><li>只有Leader对外提供服务，Follower从Leader异步拉取消息</li><li>如果Leader挂了，Kafka会进行重新选举</li></ol><h5 id="In-sync-Replicas（ISR）"><a href="#In-sync-Replicas（ISR）" class="headerlink" title="In-sync Replicas（ISR）"></a>In-sync Replicas（ISR）</h5><p>与Leader保持同步的副本称为ISR，是否保持同步的标准就是Broker 端参数 <code>replica.lag.time.max.ms </code>参数值，默认10s。它表示的是Follower能够落后Leader的最长时间</p><p>Kafka在启动时会开启两个任务，一是定期检查是否需要缩减或扩大ISR集合，周期是<code>是replica.lag.time.max.ms</code>一半；二是定期检查isrChangeSet（缓存ISR变更记录集合），如果Set有变更记录，那么会在zk中持久化一个节点 。controller节点注册的watcher能感知到ISR的变化然后向它所管理的Broker节点发送更新元数据请求，最后删除处理过的节点</p><ul><li><p>踢出ISR</p><p>如果Follower在超出了<code>replica.lag.time.max.ms</code>时间后还出于落后状态，那就会被踢出ISR。</p></li><li><p>进入ISR</p><p>当检查到Follower的High Watermark追赶上Leader时就扩充ISR</p></li></ul><h5 id="Unclean-Leader-Election"><a href="#Unclean-Leader-Election" class="headerlink" title="Unclean Leader Election"></a>Unclean Leader Election</h5><p>Unclean Leader Election指的是当ISR为空（Leader也不在了）时，是否允许Kafka在非同步副本中选举新的Leader，如果不允许，那么分区就失效了。</p><p>通过Broker 端参数 <code>unclean.leader.election.enable</code>控制是否开启</p><p>开启选项可能会造成数据丢夫，好处在于提高了可用性</p><h5 id="High-Watermark-HW"><a href="#High-Watermark-HW" class="headerlink" title="High Watermark(HW)"></a>High Watermark(HW)</h5><p>Kafka用High Watermark来表征消息位移，有以下作用</p><ul><li>定义消息可见性，即分区哪些消息可被消费</li><li>帮助Kafka完成副本同步</li></ul><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230305165243.png" loading="lazy"></p><p>同一个副本对象，其高 水位值不会大于 LEO（Log End Offset) 值</p><h6 id="更新机制"><a href="#更新机制" class="headerlink" title="更新机制"></a>更新机制</h6><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230305165811.png" loading="lazy"></p><p>每个副本都会保存HW和LEO两个属性，而Leader所在的Broker也会保存所有Follower的副本，用于帮助Leader确定其HW。</p><p><strong>Leader下更新逻辑</strong></p><p>处理Producer消息</p><ol><li>消息写入磁盘</li><li>更新分区HW<ol><li>获取Leader所在Broker保存的Followers的LEO值{LEO-1，LEO-2…}</li><li>更新HW=min(leader-LEO, LEO-1, LEO-2…..)</li></ol></li></ol><p>处理Follower拉取消息</p><ol><li>根据Follower发送来的LEO读取消息数据</li><li>将Follower发送来的LEO更新到Broker保存的对应副本中</li><li>更新分区HW（同上）</li></ol><p><strong>Follower下更新逻辑</strong></p><p>从Leader处拉取消息：</p><ol><li>将消息写入磁盘</li><li>更新LEO</li><li>更新HW<ol><li>获取Leader发送来的leader-LEO</li><li>获取更新过的currentLEO</li><li>更新高水位为min(leader-LEO, currentLEO)</li></ol></li></ol><p><strong>更新存在问题</strong></p><p>HW的更新通常需要额外一轮的拉取请求才能完成，容易引发以下问题</p><ul><li><p>备份数据丢失</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230305172705.png" loading="lazy"></p><p>如图所示，当A更新完HW后，B还未来得及更新就宕机了，重启后HW还是为1，此时向A发送Fetch请求，如果A恰好又宕机了，那么B就会成为Leader，后面A重启后向B发送Fetch请求，HW将更新为1，从而丢失数据</p></li><li><p>备份数据不一致</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230305235446.png" loading="lazy"></p><p>如图所示，当A的HW=2 和B的HW=1时同时发生了宕机，B重启后成为了Leader，此时Producer发送了消息给B，B就会覆盖消息2且HW也会更新为2，后面A重启回来会执行日志截断，但发现分区的HW和自己的HW都是2，故不作任何调整，从而引起数据不一致</p><p><strong>leader epoch</strong></p><p>Kafka从0.11引入leader epoch，从而规避以上问题。leader epoch实际是一对值（epoch， offset），epoch表示版本号，从0开始，每当leader角色发生变更就+1，offset表示写入该epoch的第一条消息位移。</p><p>Kafka Broker 会在内存中为每个分区都缓存  epoch 数据，同时它还将这些 信息持久化到一个 checkpoint 文件中。如果Leader 是首次写入消息，那么Broker会向缓存中增加一个 epoch 条目，否则就不做更新。</p><p>解决数据丢失</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230306010801.png" loading="lazy"></p><p>副本B重启后向A发送LeaderEpochRequest获取A的LEO值，发现A的LEO不比自己的小，且epoch中的offset也没有比2大，因此无需执行任何日志截断</p><p>当B成为Leader时,[epoch = 1, offset = 3],A重启后会向B发送LeaderEpochRequest去获取Leader的LEO值，发现其LEO比B的小且epoch中的offset也没有比3大，因此也无需截断</p><p>注意只有Follower才会执行日志截断，Leader是不会执行日志截断的</p></li></ul><h4 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h4><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230306151424.png" loading="lazy"></p><p>todo：外网暂未找到相关资料</p><h5 id="Broker网络模型"><a href="#Broker网络模型" class="headerlink" title="Broker网络模型"></a>Broker网络模型</h5><p>Broker网络层采用了Reactor模式，有个核心组件SocketServer，线程模型如下：</p><ul><li>一个Acceptor线程接收请求</li><li>N个Processor线程,每个Processor都有自己的selector,从每个连接中读取请求</li><li>M个Handler线程处理请求,并将产生的请求返回给Processor线程用于写回客户端</li></ul><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230303184103.png" loading="lazy"></p><h4 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h4><p>控制器组件（Controller）是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。Kafka集群通过选举选出Controller。JMX指标为<code>activeController</code></p><h5 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h5><ol><li><p>主题管理（创建、删除、增加分区）</p></li><li><p>分区重分配</p></li><li><p>.Preferred 领导者选举</p><p>Preferred选举是Kafka为了避免部分Broker负载过重而提供的一种换Leader方案</p></li><li><p>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）</p></li><li><p>数据服务（集群元数据信息）</p><p>Controller会有整个集群最完整的元数据信息，Zookeeper也会保存一份，Controller的初始化元数据信息由Zookeeper提供</p></li></ol><h5 id="如何选举"><a href="#如何选举" class="headerlink" title="如何选举"></a>如何选举</h5><p>当Broker启动时，会尝试在Zookeeper中/controller节点，第一个创建成功的Broker会被选举为Controller</p><h5 id="失效处理"><a href="#失效处理" class="headerlink" title="失效处理"></a>失效处理</h5><p>当Controller所在的Broker出现异常退出了集群，Zookeeper通过Watch机制感应并将/controller节点删除，之后存活的Broker会开始进行选举，选举成功的Broker会从Zookeeper中读取元数据信息，进行初始化。</p><h5 id="内部设计结构"><a href="#内部设计结构" class="headerlink" title="内部设计结构"></a>内部设计结构</h5><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230304145246.png" loading="lazy"></p><h4 id="动态Broker参数"><a href="#动态Broker参数" class="headerlink" title="动态Broker参数"></a>动态Broker参数</h4><p>从1.1版本开始， Brokers Configs增加Update Model列，有三类值</p><ul><li>read-olny：表示修改只能重启Broker后才能生效</li><li>per-broker: 属于动态参数，修改后只在对应Broker上生效</li><li>cluster-wide：属于动态参数，修改后整个集群生效</li></ul><p><del>优先级别： per-broker &gt; cluster-wide &gt; read-only&gt; Kafka默认值</del></p><p><strong>使用场景</strong></p><ul><li>动态调整 Broker 端各种线程池大小，实时应对突发流量</li><li> 动态调整 Broker 端连接信息或安全配置信息</li><li> 动态更新 SSL Keystore 有效期</li><li> 动态调整 Broker 端 Compact 操作性能</li><li> 实时变更 JMX 指标收集器 (JMX Metrics Reporter)</li></ul><p><strong>如何配置</strong></p><p>使用kafka-config.sh</p><h4 id="重设消费组位移"><a href="#重设消费组位移" class="headerlink" title="重设消费组位移"></a>重设消费组位移</h4><p><strong>策略</strong></p><ul><li>Earliest：把位移调整到当前最早位移处</li><li>Latest：把位移调整到当前最新位移处</li><li>Current：把位移调整到当前最新提交位移处</li><li>Specified-Offset：把位移调整到指定位移处</li><li>Shift-By-N：把位移调整到当前位移 +N处（N可为负值）</li><li>DateTime：把位移调整到大于给定时间的最小位移处</li><li>Duration：把位移调整到距离当前时间指定间隔位移处</li></ul><p><strong>方法</strong></p><ul><li>通过Java API重设位移：调用KafkaConsumer的seek方法，或者它的变种方法seekToBeginning和seekToEnd</li><li>用脚本kafka-consumer-groups脚本</li></ul><h4 id="脚本工具"><a href="#脚本工具" class="headerlink" title="脚本工具"></a>脚本工具</h4><ul><li><p>kafka-acls：设置Kafka权限</p></li><li><p>kafka-broker-api-versions：验证不同Kafka版本直接服务器与客户端的适配性</p></li><li><p>kafka-config：动态参数配置</p></li><li><p>kafka-console-consumer：消费组脚本</p><pre><code class="bash">bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false #指定了 group 信息。如果没有指定的话，每次运行 Console Consumer，它都会自动生成一个新的消费者组来消费</code></pre></li><li><p>kafka-console-producer：生产者脚本</p><pre><code class="bash">bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4&gt;#指定生产者参数 acks 为 -1，同时启用了 LZ4 的压缩算法。这个脚本可以很方便地让我们使用控制台来向 Kafka 的指定主题发送消息  </code></pre></li><li><p>kafka-producer-perf-test：生产者测试工具</p><pre><code class="bash">bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 linger.ms=2000 compression.type=lz4#向指定主题发送了 1 千万条消息，每条消息大小是 1KB。</code></pre></li><li><p>kafka-consumer-perf-test：消费者测试工具</p><pre><code class="bash">bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic</code></pre></li><li><p>kafka-consumer-groups：查看消费组位移</p><pre><code class="bash">bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group test-group</code></pre></li><li><p>kafka-dump-log：查看kafka消息文件内容，包含各自元数据信息</p><pre><code class="bash">$ bin/kafka-dump-log.sh --files ../data_dir/kafka_1/test-topic-1/00000000000000000000.log </code></pre></li><li><p>kafka-log-dirs：查询各个Broker上日志路线下的磁盘占用情况</p></li><li><p>kafka-mirror-maker：实现集群消息同步</p></li><li><p>kafka-preferred-replica-election：执行 Preferred Leader 选举的</p></li><li><p>kafka-reassign-partitions：执行分区副本迁移及副本文件路径迁移</p></li><li><p>kafka-topics：主题管理</p></li></ul><p>所有的脚本都可以用 –help来查看选项，比如<code>./kafka-console-consumer.sh --help</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;分区机制&quot;&gt;&lt;a href=&quot;#分区机制&quot; class=&quot;headerlink&quot; title=&quot;分区机制&quot;&gt;&lt;/a&gt;分区机制&lt;/h4&gt;&lt;p&gt;分区的作用主要是为了提高负载均衡的能力，数据的读写都是在分区这个粒度上进行的，从而实现了系统的可伸缩性&lt;/p&gt;
&lt;h5 id</summary>
      
    
    
    
    <category term="Kafka" scheme="http://soda1.github.io/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka入门</title>
    <link href="http://soda1.github.io/2023/02/28/kafka/01.kafka%E5%85%A5%E9%97%A8/"/>
    <id>http://soda1.github.io/2023/02/28/kafka/01.kafka%E5%85%A5%E9%97%A8/</id>
    <published>2023-02-28T18:47:50.000Z</published>
    <updated>2023-03-06T19:56:40.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>Kafka是以消息引擎起家，在设计之初旨在实现以下三大特性：</p><ul><li>提供一套 API 实现生产者和消费者；</li><li>降低网络传输和磁盘存储开销；</li><li>实现高伸缩性架构</li></ul><p>到现如今发展成一个分布式流处理平台</p><h4 id="消息模型"><a href="#消息模型" class="headerlink" title="消息模型"></a>消息模型</h4><ul><li><p>Producer/Consumer Model（队列模型）:</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230301145154.png" loading="lazy"></p><p>生产者产生消息放在队列一端，消费者从队列的另一端进行消费，如果没有消费者，那么消息就会保存在队列中直到队列满或者有消费者上线</p></li><li><p>Publisher/Subscriber Model（发布/订阅模型）</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230301145213.png" loading="lazy"></p></li></ul><p>Kafka同时支持以上两种模型</p><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230228191503.png" loading="lazy"></p><p>图片展示了Kafka作为消息引擎的大致结构，术语解释如下：</p><ul><li>Broker：表示的是一个Kafka实例</li><li>Record：Kafka处理的主要对象，由Producer产生，&lt;key, value&gt;形式，key可以为空</li><li>Topic：作为Record的容器，多用来区分不同的业务</li><li>Partition：每一个Partition下的消息都是有序的，Topic下可以有多个Partition</li><li>Offset：表示的是消息的位置信息</li><li>Replica：副本，每个分区都可以保存多个副本，从而实现高可用</li><li>Producer：可以向主题<strong>发布</strong>消息的客户端</li><li>Consumer：向主题<strong>订阅</strong>消息的客户端，同一时间内一个Partition只能被一个Consumer消费  </li><li>Consumer Offset：表示的是消费者的消费进度</li><li>Consumer Group：由多个Consumer组成,同时消费多个分区</li><li>Leader副本：对位提供数据读写服务的分区副本称为Leader，其余的称为Follower</li></ul><h4 id="参数描述"><a href="#参数描述" class="headerlink" title="参数描述"></a>参数描述</h4><p>Kafka有着很多的配置参数，下面是一些比较重要的参数</p><h5 id="Broke-config"><a href="#Broke-config" class="headerlink" title="Broke config"></a>Broke config</h5><ul><li><p>broker.id：broker id，用于集群标识实例，不可重复，默认值为0</p></li><li><p>log.dirs：日志数据路径，这个是没有默认值的，需要自己去指定，可以指定多个路径，用逗号隔开。/home/kafka1/,/home/kafak2/</p></li><li><p>log.dir：这个用于指定单个路径，如果log.dirs没有设置的话就会使用这个</p></li><li><p>zookeeper.connect：zookeeper连接配置，以hostname:port的格式配置，配置多个是以逗号隔开</p></li><li><p>listeners：监听器,多个以逗号隔开，格式为<code>协议://hostname:port</code>，比如 <code>PLAINTEXT://myhost:9092</code>。协议如果不写，那么就必须要配置listener.security.protocol.map</p></li><li><p>advertised.listeners：这个是用于客户端的，客户端在做初始连接时获取的元信息会包含这些配置，这样客户端才会知道它需要请求的broker地址。当客户端和Kafka在不同的网络中就需要配置</p><p>listeners和advertised.listeners的区别参考<a href="https://rmoff.net/2018/08/02/kafka-listeners-explained/" title="Kafka Listeners - Explained">这篇文章</a></p></li><li><p>allow.auto.create.topics：是否允许自动创建Topic，default：true，建议false，避免创建一些奇怪的Topic</p></li><li><p>unclean.leader.election.enable：是否允许Unclean Leader选举，default：false。该选项决定同步落后太多的副本是否可以参与选举</p></li><li><p>auto.leader.rebalance.enable：允许Kafka定期对一些Topic分区进行Leader重选， default：true，建议生产环境中设为false</p></li><li><p>log.retention.{hour|minutes|ms}：数据留存时间，优先级上来说 ms 设置最高、minutes 次之、hour 最低。Kafka数据默认保存7天</p></li><li><p>log.retention.bytes：限制Broker保存数据的总容量大小，default：-1（无限制）</p></li><li><p>message.max.bytes：消息能正常接收的最大值</p></li><li><pre><code>num.network.threads：接收和响应请求线程数num.io.threads：处理请求的线程数这两个参数理解需要看Broker内部结构，num.network.threads对应Network Layer层Processor Thread线程数，num.io.threads是API Layer层的API Thread数</code></pre></li></ul><h5 id="Topic-config"><a href="#Topic-config" class="headerlink" title="Topic config"></a>Topic config</h5><ul><li>retention.ms：设置该Topic消息保存时长，该值会覆盖Broker端的全局参数配置</li><li>retention.bytes：设置为该Topic预留多少磁盘空间</li><li>max.message.bytes：该Topic可以正常接收到消息的最大值，会覆盖全局参数</li></ul><h5 id="JVM-config"><a href="#JVM-config" class="headerlink" title="JVM config"></a>JVM config</h5><p>Kafka是运行在JVM上的，因此配置JVM参数的重要性就不言而喻了</p><ul><li>KAFKA_HEAP_OPTS：指定堆大小，业界推荐6GB</li><li>KAFKA_JVM_PERFORMANCE_OPTS：指定GC参数，一般配置收集器为G1</li></ul><p>配置示例</p><pre><code class="bash">export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6gexport  KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true#启动bin/kafka-server-start.sh config/server.properties</code></pre><p>更多参数参考<a href="https://kafka.apache.org/28/documentation.html#brokerconfigs">Kafka Doc</a>，这个文档写的很好，结构很清晰</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;Kafka是以消息引擎起家，在设计之初旨在实现以下三大特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提供一套 API 实现生产者和消费者；&lt;/li&gt;
&lt;</summary>
      
    
    
    
    <category term="Kafka" scheme="http://soda1.github.io/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>性能指标</title>
    <link href="http://soda1.github.io/2023/01/14/linux/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/"/>
    <id>http://soda1.github.io/2023/01/14/linux/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/</id>
    <published>2023-01-14T21:33:41.000Z</published>
    <updated>2023-01-15T00:07:56.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h4><ol><li><p>QPS：每秒请求数</p></li><li><p>TPS：每秒事务数，一个事务可能会包含多个请求，比如一个页面加载会发送多个请求至后端</p></li><li><p>RT：系统响应时间，执行一个请求从开始到最后收到响应数据所花费的总体时间</p></li><li><p>Concurrency：并发数，系统同时处理的请求数量，也反应了系统的负载能力</p></li><li><p>吞吐量：系统吞吐量和CPU消耗、外部接口、IO等因素等紧密关联。</p><p>重要指标参数：QPS（TPS）、并发数、平均响应时间</p></li></ol><p>关系：<br>$$<br>QPS(TPS) = 并发数 / 平均响应时间<br>$$</p><h4 id="QPS压测实验"><a href="#QPS压测实验" class="headerlink" title="QPS压测实验"></a>QPS压测实验</h4><p>压测工具：wrk</p><p>环境：ubuntu（wsl subSystem), 6核 11线程</p><p>并发200测试</p><pre><code class="shell">root@LAPTOP-6HNUFCIN:/usr/bin# wrk -t 11 -c 200 -d 30s --latency  http://127.0.0.1:8281/api/testRunning 30s test @ http://127.0.0.1:8281/api/test  11 threads and 200 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    43.81ms   26.20ms 259.14ms   69.79%    Req/Sec   419.92     56.97   680.00     68.39%  Latency Distribution     50%   44.25ms     75%   60.54ms     90%   76.10ms     99%  109.90ms  138097 requests in 30.05s, 40.98MB read  Non-2xx or 3xx responses: 138097Requests/sec:   4596.04 //QPSTransfer/sec:      1.36MB</code></pre><p>avgRT为43ms，则在1s单位时间内，能串行处理23个请求。因此QPS = 23 * 200 = 4600个，和测试结果差不多。但在真实环境应该会更低。</p><p>并发300测试</p><pre><code class="shell">root@LAPTOP-6HNUFCIN:/usr/bin# wrk -t 11 -c 300 -d 30s --latency  http://127.0.0.1:8281/api/testRunning 30s test @ http://127.0.0.1:8281/api/test  11 threads and 300 connections  Thread Stats   Avg      Stdev     Max   +/- Stdev    Latency    63.50ms   35.50ms 358.22ms   58.62%    Req/Sec   432.67     56.40     0.92k    69.47%  Latency Distribution     50%   64.55ms     75%   87.37ms     90%  108.46ms     99%  155.62ms  142058 requests in 30.03s, 42.16MB read  Non-2xx or 3xx responses: 142058Requests/sec:   4729.85Transfer/sec:      1.40MB</code></pre><p>增加并发数QPS基本保持不变，验证了<code>QPS(TPS) = 并发数 / 平均响应时间</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;指标&quot;&gt;&lt;a href=&quot;#指标&quot; class=&quot;headerlink&quot; title=&quot;指标&quot;&gt;&lt;/a&gt;指标&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;QPS：每秒请求数&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TPS：每秒事务数，一个事务可能会包含多个请求，比如一个页面加载会发</summary>
      
    
    
    
    <category term="linux" scheme="http://soda1.github.io/categories/linux/"/>
    
    
  </entry>
  
  <entry>
    <title>behavioral patterns</title>
    <link href="http://soda1.github.io/2023/01/08/design%20pattern/behavioral%20patterns/"/>
    <id>http://soda1.github.io/2023/01/08/design%20pattern/behavioral%20patterns/</id>
    <published>2023-01-08T00:41:59.000Z</published>
    <updated>2023-01-09T00:17:25.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h4><p>一对多依赖关系，被依赖对象叫做被观察者，依赖对象叫做观察者。也被称为<strong>发布订阅模式</strong></p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108144537.png" alt="image-20230108144537852" loading="lazy"></p><h4 id="模板模式"><a href="#模板模式" class="headerlink" title="模板模式"></a>模板模式</h4><p>定义一个骨架算法（业务步骤），然后具体的算法由子类去实现。</p><p>假如有一批不同格式的数据需要处理，处理的步骤基本一致，差异在于数据提取细节不同。这时候就可以使用模板模式来定义业务步骤，将数据提取这一步骤由子类去实现。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108152126.png" loading="lazy"></p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108152407.png" loading="lazy"></p><h4 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h4><p>定义一族算法类，将每个算法分别封装起来，让它们可以互相替换。策略模式可以使算法的变化独立于使用它们的客户端（这里的客户端代指使用算法的代码）</p><p>一般策略模式会配合工厂模式一起使用，根据条件来选用不同的策略。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108155021.png" loading="lazy"></p><h4 id="责任链模式"><a href="#责任链模式" class="headerlink" title="责任链模式"></a>责任链模式</h4><p>将请求的发送和接收解耦，让多个接收对象都有机会处理同一个请求。将这些接收对象串成一条链，并沿着这条链传递这个请求，直到链上的某个接收对象能够处理它为止。链上的每个处理器都有自己的职责。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108155846.png" loading="lazy"></p><h4 id="状态模式"><a href="#状态模式" class="headerlink" title="状态模式"></a>状态模式</h4><p>一般用于状态机，将状态转换逻辑拆分到不同的状态类中，从而消除if-else（switch-case）条件</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108171118.png" loading="lazy"></p><h4 id="迭代器模式"><a href="#迭代器模式" class="headerlink" title="迭代器模式"></a>迭代器模式</h4><p>对于集合，可能会有不同的方式来遍历元素，数组和链表比较简单，直接遍历即可，但对于tree这种结构有多种遍历方式（前序，后序，中序），这时候就需要使用迭代器模式。具体来说就是在<strong>集合类组合一个迭代类</strong>。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108223336.png" loading="lazy"></p><h4 id="访问者模式（TODO）"><a href="#访问者模式（TODO）" class="headerlink" title="访问者模式（TODO）"></a>访问者模式（TODO）</h4><h4 id="备忘录模式"><a href="#备忘录模式" class="headerlink" title="备忘录模式"></a>备忘录模式</h4><p>在不违背封装原则的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便之后恢复对象为先前的状态。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108225709.png" loading="lazy"></p><h4 id="命令模式（不太明白）"><a href="#命令模式（不太明白）" class="headerlink" title="命令模式（不太明白）"></a>命令模式（不太明白）</h4><p>将请求转换为一个包含与请求相关的所有信息的独立对象。 该转换让你能根据不同的请求将方法参数化、 延迟请求执行或将其放入队列中， 且能实现可撤销操作。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108235041.png" loading="lazy"></p><ol><li><p>The <strong>Sender</strong> class (aka <em>invoker</em>) is responsible for initiating requests. This class must have a field for storing a reference to a command object. The sender triggers that command instead of sending the request directly to the receiver. Note that the sender isn’t responsible for creating the command object. Usually, it gets a pre-created command from the client via the constructor.</p></li><li><p>The <strong>Command</strong> interface usually declares just a single method for executing the command.</p></li><li><p><strong>Concrete Commands</strong> implement various kinds of requests. A concrete command isn’t supposed to perform the work on its own, but rather to pass the call to one of the business logic objects. However, for the sake of simplifying the code, these classes can be merged.</p><p>Parameters required to execute a method on a receiving object can be declared as fields in the concrete command. You can make command objects immutable by only allowing the initialization of these fields via the constructor.</p></li><li><p>The <strong>Receiver</strong> class contains some business logic. Almost any object may act as a receiver. Most commands only handle the details of how a request is passed to the receiver, while the receiver itself does the actual work.</p></li><li><p>The <strong>Client</strong> creates and configures concrete command objects. The client must pass all of the request parameters, including a receiver instance, into the command’s constructor. After that, the resulting command may be associated with one or multiple senders.</p></li></ol><h4 id="解释器模式"><a href="#解释器模式" class="headerlink" title="解释器模式"></a>解释器模式</h4><p>解释器模式为某个语言定义它的语法（或者叫文法）表示，并定义一个解释器用来处理这个语法。</p><pre><code class="java">public interface Expression &#123;  long interpret();&#125;public class NumberExpression implements Expression &#123;  private long number;  public NumberExpression(long number) &#123;    this.number = number;  &#125;  public NumberExpression(String number) &#123;    this.number = Long.parseLong(number);  &#125;  @Override  public long interpret() &#123;    return this.number;  &#125;&#125;public class AdditionExpression implements Expression &#123;  private Expression exp1;  private Expression exp2;  public AdditionExpression(Expression exp1, Expression exp2) &#123;    this.exp1 = exp1;    this.exp2 = exp2;  &#125;  @Override  public long interpret() &#123;    return exp1.interpret() + exp2.interpret();  &#125;&#125;// SubstractionExpression/MultiplicationExpression/DivisionExpression与AdditionExpression代码结构类似，这里就省略了public class ExpressionInterpreter &#123;  private Deque&lt;Expression&gt; numbers = new LinkedList&lt;&gt;();  public long interpret(String expression) &#123;    String[] elements = expression.split(&quot; &quot;);    int length = elements.length;    for (int i = 0; i &lt; (length+1)/2; ++i) &#123;      numbers.addLast(new NumberExpression(elements[i]));    &#125;    for (int i = (length+1)/2; i &lt; length; ++i) &#123;      String operator = elements[i];      boolean isValid = &quot;+&quot;.equals(operator) || &quot;-&quot;.equals(operator)              || &quot;*&quot;.equals(operator) || &quot;/&quot;.equals(operator);      if (!isValid) &#123;        throw new RuntimeException(&quot;Expression is invalid: &quot; + expression);      &#125;      Expression exp1 = numbers.pollFirst();      Expression exp2 = numbers.pollFirst();      Expression combinedExp = null;      if (operator.equals(&quot;+&quot;)) &#123;        combinedExp = new AdditionExpression(exp1, exp2);      &#125; else if (operator.equals(&quot;-&quot;)) &#123;        combinedExp = new AdditionExpression(exp1, exp2);      &#125; else if (operator.equals(&quot;*&quot;)) &#123;        combinedExp = new AdditionExpression(exp1, exp2);      &#125; else if (operator.equals(&quot;/&quot;)) &#123;        combinedExp = new AdditionExpression(exp1, exp2);      &#125;      long result = combinedExp.interpret();      numbers.addFirst(new NumberExpression(result));    &#125;    if (numbers.size() != 1) &#123;      throw new RuntimeException(&quot;Expression is invalid: &quot; + expression);    &#125;    return numbers.pop().interpret();  &#125;&#125;</code></pre><h4 id="中介模式"><a href="#中介模式" class="headerlink" title="中介模式"></a>中介模式</h4><p>定义了一个单独的（中介）对象，来封装一组对象之间的交互。将这组对象之间的交互委派给与中介对象交互，来避免对象之间的直接交互。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230109001300.png" loading="lazy"></p><ol><li><p><strong>Components</strong> are various classes that contain some business logic. Each component has a reference to a mediator, declared with the type of the mediator interface. The component isn’t aware of the actual class of the mediator, so you can reuse the component in other programs by linking it to a different mediator.</p></li><li><p>The <strong>Mediator</strong> interface declares methods of communication with components, which usually include just a single notification method. Components may pass any context as arguments of this method, including their own objects, but only in such a way that no coupling occurs between a receiving component and the sender’s class.</p></li><li><p><strong>Concrete Mediators</strong> encapsulate relations between various components. Concrete mediators often keep references to all components they manage and sometimes even manage their lifecycle.</p></li><li><p>Components must not be aware of other components. If something important happens within or to a component, it must only notify the mediator. When the mediator receives the notification, it can easily identify the sender, which might be just enough to decide what component should be triggered in return.</p><p>From a component’s perspective, it all looks like a total black box. The sender doesn’t know who’ll end up handling its request, and the receiver doesn’t know who sent the request in the first place.</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;观察者模式&quot;&gt;&lt;a href=&quot;#观察者模式&quot; class=&quot;headerlink&quot; title=&quot;观察者模式&quot;&gt;&lt;/a&gt;观察者模式&lt;/h4&gt;&lt;p&gt;一对多依赖关系，被依赖对象叫做被观察者，依赖对象叫做观察者。也被称为&lt;strong&gt;发布订阅模式&lt;/strong&gt;&lt;</summary>
      
    
    
    
    <category term="design_pattern" scheme="http://soda1.github.io/categories/design-pattern/"/>
    
    
  </entry>
  
  <entry>
    <title>UML对象关系</title>
    <link href="http://soda1.github.io/2023/01/08/design%20pattern/UML/"/>
    <id>http://soda1.github.io/2023/01/08/design%20pattern/UML/</id>
    <published>2023-01-08T00:04:26.000Z</published>
    <updated>2023-01-08T00:34:54.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>泛化关系(generalization) </p><p> 继承（is-a）</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108001753.png" alt="image-20230108001753062" loading="lazy"></p></li><li><p>实现关系(realize)</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108001934.png" alt="image-20230108001934839" loading="lazy"></p></li><li><p>聚合关系(aggregation)</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108002139.png" alt="image-20230108002139588" loading="lazy"></p><p>表示A组成B，不是强依赖关系，比如部门撤销了，但人还存在</p></li><li><p>组合关系(composition)</p><p><img src="C:\Users\f\AppData\Roaming\Typora\typora-user-images\image-20230108002049034.png" alt="image-20230108002049034" loading="lazy"></p><p>表示A组成B，强依赖关系，比如公司不存在了，部门也会不存在</p></li><li><p>关联关系(association)</p><p>用直线表示，如果强调方向则在一端加上箭头</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108002502.png" alt="image-20230108002502073" loading="lazy"></p><p>表示A知道B</p><p>关联对象通常是以成员变量的形式实现的；</p></li><li><p>依赖关系(dependency)</p><p>这种关系具有临时性，在代码上的表现一般为函数参数，局部变量，对静态方法的调用。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108003156.png" alt="image-20230108003156835" loading="lazy"></p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;&lt;p&gt;泛化关系(generalization) &lt;/p&gt;
&lt;p&gt; 继承（is-a）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/soda1/img/main/20230108001753.png&quot; alt</summary>
      
    
    
    
    <category term="design_pattern" scheme="http://soda1.github.io/categories/design-pattern/"/>
    
    
  </entry>
  
  <entry>
    <title>structural patterns</title>
    <link href="http://soda1.github.io/2023/01/03/design%20pattern/structural%20patterns/"/>
    <id>http://soda1.github.io/2023/01/03/design%20pattern/structural%20patterns/</id>
    <published>2023-01-03T23:10:15.000Z</published>
    <updated>2023-01-08T00:41:51.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h4><p>在不改变原始类功能代码下，<strong>通过代理类来增加附加功能</strong>，具体可以通过实现相同的接口/继承原始类来实现。</p><p>出现的意义就是为了避免功能耦合，比如业务代码和非业务（日志等）代码应剥离。</p><pre><code class="java">public interface IUserController &#123;  UserVo login(String telephone, String password);  UserVo register(String telephone, String password);&#125;//业务接口public class UserController implements IUserController &#123;  //...省略其他属性和方法...  @Override  public UserVo login(String telephone, String password) &#123;    //...省略login逻辑...    //...返回UserVo数据...  &#125;&#125;//业务代理接口public class UserControllerProxy implements IUserController &#123;    //接口统计  private MetricsCollector metricsCollector;  private UserController userController;  public UserControllerProxy(UserController userController) &#123;    this.userController = userController;    this.metricsCollector = new MetricsCollector();  &#125;  @Override  public UserVo login(String telephone, String password) &#123;    long startTimestamp = System.currentTimeMillis();    // 委托    UserVo userVo = userController.login(telephone, password);    long endTimeStamp = System.currentTimeMillis();    long responseTime = endTimeStamp - startTimestamp;    RequestInfo requestInfo = new RequestInfo(&quot;login&quot;, responseTime, startTimestamp);    metricsCollector.recordRequest(requestInfo);    return userVo;  &#125;</code></pre><p>对于非业务代码，比如接口调用记录这些功能，由于接口比较多，更多的是使用<strong>动态代理</strong></p><h4 id="桥接模式"><a href="#桥接模式" class="headerlink" title="桥接模式"></a>桥接模式</h4><p><strong>让两个/多个维度的独立变化</strong>，避免类指数式增加。</p><p>比如下图，如果颜色和形状增加就会造成类的快速增加</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230103234923.png" alt="image-20230103234916879" loading="lazy"></p><p>桥接模式结构如下图</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230103235251.png" alt="image-20230103235251475" loading="lazy"></p><p>总的就是让一个维度变化通过接口的方式注入到主体类中，所有的行为都依赖具体的桥接类</p><pre><code class="java">public interface MsgSender &#123;  void send(String message);&#125;public class TelephoneMsgSender implements MsgSender &#123;  private List&lt;String&gt; telephones;  public TelephoneMsgSender(List&lt;String&gt; telephones) &#123;    this.telephones = telephones;  &#125;  @Override  public void send(String message) &#123;    //...  &#125;&#125;public class EmailMsgSender implements MsgSender &#123;  // 与TelephoneMsgSender代码结构类似，所以省略...&#125;public class WechatMsgSender implements MsgSender &#123;  // 与TelephoneMsgSender代码结构类似，所以省略...&#125;public abstract class Notification &#123;  protected MsgSender msgSender;  public Notification(MsgSender msgSender) &#123;    this.msgSender = msgSender;  &#125;  public abstract void notify(String message);&#125;public class SevereNotification extends Notification &#123;  public SevereNotification(MsgSender msgSender) &#123;    super(msgSender);  &#125;  @Override  public void notify(String message) &#123;    msgSender.send(message);  &#125;&#125;public class UrgencyNotification extends Notification &#123;  // 与SevereNotification代码结构类似，所以省略...&#125;public class NormalNotification extends Notification &#123;  // 与SevereNotification代码结构类似，所以省略...&#125;public class TrivialNotification extends Notification &#123;  // 与SevereNotification代码结构类似，所以省略...&#125;//这样就可以进行任意组合</code></pre><h4 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h4><p><strong>使用组合关系替代继承关系来对功能进行增强</strong>，java 的IO流就是使用了装饰器模式</p><pre><code class="java">InputStream in = new FileInputStream(&quot;/user/wangzheng/test.txt&quot;);InputStream bin = new BufferedInputStream(in);DataInputStream din = new DataInputStream(bin);</code></pre><p>上述代码din是一个带有缓存的基本数据读取流，将增强的功能拆分开来进行任意组合从而避免类爆炸式增长。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230107175908.png" alt="image-20230107175900955" loading="lazy"></p><h4 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h4><p>将不兼容的接口转为可兼容，通过定义一个新的接口，然后实现接口并继承或组合不兼容的类来实现兼容</p><ul><li><p>类适配器（继承）</p><pre><code class="java">// 类适配器: 基于继承public interface ITarget &#123;  void f1();  void f2();  void fc();&#125;public class Adaptee &#123;  public void fa() &#123; //... &#125;  public void fb() &#123; //... &#125;  public void fc() &#123; //... &#125;&#125;public class Adaptor extends Adaptee implements ITarget &#123;  public void f1() &#123;    super.fa();  &#125;  public void f2() &#123;    //...重新实现f2()...  &#125;  // 这里fc()不需要实现，直接继承自Adaptee，这是跟对象适配器最大的不同点&#125;</code></pre></li></ul><ul><li><p>对象适配器（组合）</p><pre><code class="java">public class Adaptor implements ITarget &#123;  private Adaptee adaptee;  public Adaptor(Adaptee adaptee) &#123;    this.adaptee = adaptee;  &#125;  public void f1() &#123;    adaptee.fa(); //委托给Adaptee  &#125;  public void f2() &#123;    //...重新实现f2()...  &#125;  public void fc() &#123;    adaptee.fc();  &#125;&#125;</code></pre><ul><li><p>如果 Adaptee 接口并不多，那两种实现方式都可以。</p></li><li><p>如果 Adaptee 接口很多，而且 Adaptee 和 ITarget 接口定义大部分都相同，那我们推荐使用类适配器，因为 Adaptor 复用父类 Adaptee 的接口，比起对象适配器的实现方式，Adaptor 的代码量要少一些。</p></li><li><p>如果 Adaptee 接口很多，而且 Adaptee 和 ITarget 接口定义大部分都不相同，那我们推荐使用对象适配器，因为组合结构相对于继承更加灵活。</p></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230107232252.png" alt="image-20230107232252473" loading="lazy"></p><h4 id="门面模式"><a href="#门面模式" class="headerlink" title="门面模式"></a>门面模式</h4><p>将多个接口重新包裹成一个接口，让调用方更方便使用。</p><h4 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h4><p>当一组对象需要组成树形结构时，使用此模式。比如部门，文件系统就是一个树形结构。</p><pre><code class="java">public abstract class FileSystemNode &#123;  protected String path;  public FileSystemNode(String path) &#123;    this.path = path;  &#125;  public abstract int countNumOfFiles();  public abstract long countSizeOfFiles();  public String getPath() &#123;    return path;  &#125;&#125;public class File extends FileSystemNode &#123;  public File(String path) &#123;    super(path);  &#125;  @Override  public int countNumOfFiles() &#123;    return 1;  &#125;  @Override  public long countSizeOfFiles() &#123;    java.io.File file = new java.io.File(path);    if (!file.exists()) return 0;    return file.length();  &#125;&#125;public class Directory extends FileSystemNode &#123;  private List&lt;FileSystemNode&gt; subNodes = new ArrayList&lt;&gt;();  public Directory(String path) &#123;    super(path);  &#125;  @Override  public int countNumOfFiles() &#123;    int numOfFiles = 0;    for (FileSystemNode fileOrDir : subNodes) &#123;      numOfFiles += fileOrDir.countNumOfFiles();    &#125;    return numOfFiles;  &#125;  @Override  public long countSizeOfFiles() &#123;    long sizeofFiles = 0;    for (FileSystemNode fileOrDir : subNodes) &#123;      sizeofFiles += fileOrDir.countSizeOfFiles();    &#125;    return sizeofFiles;  &#125;  public void addSubNode(FileSystemNode fileOrDir) &#123;    subNodes.add(fileOrDir);  &#125;  public void removeSubNode(FileSystemNode fileOrDir) &#123;    int size = subNodes.size();    int i = 0;    for (; i &lt; size; ++i) &#123;      if (subNodes.get(i).getPath().equalsIgnoreCase(fileOrDir.getPath())) &#123;        break;      &#125;    &#125;    if (i &lt; size) &#123;      subNodes.remove(i);    &#125;  &#125;&#125;</code></pre><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230107235138.png" alt="image-20230107235138772" loading="lazy"></p><h4 id="享元模式"><a href="#享元模式" class="headerlink" title="享元模式"></a>享元模式</h4><p>复用对象，从而节约内存。复用的对象都是不可变对象，比如游戏中的象棋，一个棋盘中变化的只是棋子的位置，其他信息是不变，将这些不变信息定义为一个元对象来被所有棋盘引用，从而达到节约内存的目的。</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20230108003621.png" alt="image-20230108003621007" loading="lazy"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;代理模式&quot;&gt;&lt;a href=&quot;#代理模式&quot; class=&quot;headerlink&quot; title=&quot;代理模式&quot;&gt;&lt;/a&gt;代理模式&lt;/h4&gt;&lt;p&gt;在不改变原始类功能代码下，&lt;strong&gt;通过代理类来增加附加功能&lt;/strong&gt;，具体可以通过实现相同的接口/继承原始类</summary>
      
    
    
    
    <category term="design_pattern" scheme="http://soda1.github.io/categories/design-pattern/"/>
    
    
  </entry>
  
  <entry>
    <title>creator patterns</title>
    <link href="http://soda1.github.io/2022/12/12/design%20pattern/creator%20patterns/"/>
    <id>http://soda1.github.io/2022/12/12/design%20pattern/creator%20patterns/</id>
    <published>2022-12-12T22:54:54.000Z</published>
    <updated>2023-01-03T23:11:11.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h4><p>只允许类创建一个实例</p><h5 id="创建方式"><a href="#创建方式" class="headerlink" title="创建方式"></a>创建方式</h5><ul><li><p>饿汉式</p><pre><code class="java">public class IdGenerator &#123;   private AtomicLong id = new AtomicLong(0);  private static final IdGenerator instance = new IdGenerator();  private IdGenerator() &#123;&#125;  public static IdGenerator getInstance() &#123;    return instance;  &#125;  public long getId() &#123;     return id.incrementAndGet();  &#125;&#125;</code></pre></li><li><p>懒汉式</p><p>双重检测</p><pre><code class="java">public class IdGenerator &#123;   private AtomicLong id = new AtomicLong(0);  private static IdGenerator instance;  private IdGenerator() &#123;&#125;  public static IdGenerator getInstance() &#123;    if (instance == null) &#123;      synchronized(IdGenerator.class) &#123; // 此处为类级别的锁        if (instance == null) &#123;          instance = new IdGenerator();        &#125;      &#125;    &#125;    return instance;  &#125;  public long getId() &#123;     return id.incrementAndGet();  &#125;&#125;</code></pre><p>静态内部类</p><pre><code class="java">public class IdGenerator &#123;   private AtomicLong id = new AtomicLong(0);  private IdGenerator() &#123;&#125;  private static class SingletonHolder&#123;    private static final IdGenerator instance = new IdGenerator();  &#125;  public static IdGenerator getInstance() &#123;    return SingletonHolder.instance;  &#125;  public long getId() &#123;     return id.incrementAndGet();  &#125;&#125;</code></pre></li></ul><h5 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h5><ol><li>单例对OOP特性的支持不友好，通过类的直接使用违反了基于接口而非实现的原则，比如ID生成器，如果未来每个业务需要不同的ID生成器算法，就需要进行重构来支持这个需求变化，所有用到之前静态类的地方都需要更改</li><li>单例会隐藏类之间的依赖关系，需要通过阅读代码才能发现</li><li>对代码扩展性不友好</li><li>对代码可测性不友好 无法mock</li></ol><p>如果单例并没有后续扩展需求，并且不依赖外部系统，那么设计成单例类是没有问题的，否则尽量不要使用单例类</p><h4 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h4><h5 id="简单工厂"><a href="#简单工厂" class="headerlink" title="简单工厂"></a>简单工厂</h5><pre><code class="java">public class RuleConfigParserFactory &#123;  public static IRuleConfigParser createParser(String configFormat) &#123;    IRuleConfigParser parser = null;    if (&quot;json&quot;.equalsIgnoreCase(configFormat)) &#123;      parser = new JsonRuleConfigParser();    &#125; else if (&quot;xml&quot;.equalsIgnoreCase(configFormat)) &#123;      parser = new XmlRuleConfigParser();    &#125; else if (&quot;yaml&quot;.equalsIgnoreCase(configFormat)) &#123;      parser = new YamlRuleConfigParser();    &#125; else if (&quot;properties&quot;.equalsIgnoreCase(configFormat)) &#123;      parser = new PropertiesRuleConfigParser();    &#125;    return parser;  &#125;&#125;</code></pre><p>通过传入简单参数来返回对象，如果对象是可以复用的，还可以事先使用map缓存起来</p><h5 id="工厂方法"><a href="#工厂方法" class="headerlink" title="工厂方法"></a>工厂方法</h5><pre><code class="java">public interface IRuleConfigParserFactory &#123;  IRuleConfigParser createParser();&#125;public class JsonRuleConfigParserFactory implements IRuleConfigParserFactory &#123;  @Override  public IRuleConfigParser createParser() &#123;    return new JsonRuleConfigParser();  &#125;&#125;public class XmlRuleConfigParserFactory implements IRuleConfigParserFactory &#123;  @Override  public IRuleConfigParser createParser() &#123;    return new XmlRuleConfigParser();  &#125;&#125;</code></pre><pre><code class="java">public class RuleConfigSource &#123;  public RuleConfig load(String ruleConfigFilePath) &#123;    String ruleConfigFileExtension = getFileExtension(ruleConfigFilePath);    IRuleConfigParserFactory parserFactory = null;    if (&quot;json&quot;.equalsIgnoreCase(ruleConfigFileExtension)) &#123;      parserFactory = new JsonRuleConfigParserFactory();    &#125; else if (&quot;xml&quot;.equalsIgnoreCase(ruleConfigFileExtension)) &#123;      parserFactory = new XmlRuleConfigParserFactory();    &#125; else if (&quot;yaml&quot;.equalsIgnoreCase(ruleConfigFileExtension)) &#123;      parserFactory = new YamlRuleConfigParserFactory();    &#125; else if (&quot;properties&quot;.equalsIgnoreCase(ruleConfigFileExtension)) &#123;      parserFactory = new PropertiesRuleConfigParserFactory();    &#125; else &#123;      throw new InvalidRuleConfigException(&quot;Rule config file format is not supported: &quot; + ruleConfigFilePath);    &#125;    IRuleConfigParser parser = parserFactory.createParser();    String configText = &quot;&quot;;    //从ruleConfigFilePath文件中读取配置文本到configText中    RuleConfig ruleConfig = parser.parse(configText);    return ruleConfig;  &#125;</code></pre><p>通过使用多态的方式来实现工厂方法，但是工厂对象的创建逻辑又耦合进load函数中了，需要再创建一个简单工厂</p><pre><code class="java">public class RuleConfigParserFactoryMap &#123; //工厂的工厂  private static final Map&lt;String, IRuleConfigParserFactory&gt; cachedFactories = new HashMap&lt;&gt;();  static &#123;    cachedFactories.put(&quot;json&quot;, new JsonRuleConfigParserFactory());    cachedFactories.put(&quot;xml&quot;, new XmlRuleConfigParserFactory());    cachedFactories.put(&quot;yaml&quot;, new YamlRuleConfigParserFactory());    cachedFactories.put(&quot;properties&quot;, new PropertiesRuleConfigParserFactory());  &#125;  public static IRuleConfigParserFactory getParserFactory(String type) &#123;    if (type == null || type.isEmpty()) &#123;      return null;    &#125;    IRuleConfigParserFactory parserFactory = cachedFactories.get(type.toLowerCase());    return parserFactory;  &#125;&#125;</code></pre><pre><code class="java">public class RuleConfigSource &#123;  public RuleConfig load(String ruleConfigFilePath) &#123;    String ruleConfigFileExtension = getFileExtension(ruleConfigFilePath);    IRuleConfigParserFactory parserFactory = RuleConfigParserFactoryMap.getParserFactory(ruleConfigFileExtension);    if (parserFactory == null) &#123;      throw new InvalidRuleConfigException(&quot;Rule config file format is not supported: &quot; + ruleConfigFilePath);    &#125;    IRuleConfigParser parser = parserFactory.createParser();    String configText = &quot;&quot;;    //从ruleConfigFilePath文件中读取配置文本到configText中    RuleConfig ruleConfig = parser.parse(configText);    return ruleConfig;  &#125;  private String getFileExtension(String filePath) &#123;    //...解析文件名获取扩展名，比如rule.json，返回json    return &quot;json&quot;;  &#125;&#125;</code></pre><p>当创建逻辑比较复杂的时候才推荐使用工厂方法。</p><h5 id="抽象工厂方法"><a href="#抽象工厂方法" class="headerlink" title="抽象工厂方法"></a>抽象工厂方法</h5><p>当类有多个类别时就需要使用到，比如配置类分为基于Rule配置和系统配置。场景比较特殊，不常用</p><pre><code class="java">针对规则配置的解析器：基于接口IRuleConfigParserJsonRuleConfigParserXmlRuleConfigParserYamlRuleConfigParserPropertiesRuleConfigParser针对系统配置的解析器：基于接口ISystemConfigParserJsonSystemConfigParserXmlSystemConfigParserYamlSystemConfigParserPropertiesSystemConfigParser</code></pre><p>工厂类接口</p><pre><code class="java">public interface IConfigParserFactory &#123;  IRuleConfigParser createRuleParser();  ISystemConfigParser createSystemParser();  //此处可以扩展新的parser类型，比如IBizConfigParser&#125;</code></pre><h4 id="建造者"><a href="#建造者" class="headerlink" title="建造者"></a>建造者</h4><p>当创建一个对象需要配置比较多的属性时，且这些属性可能会存在着一定的关系。</p><pre><code class="java">public class ResourcePoolConfig &#123;  private String name;  private int maxTotal;  private int maxIdle;  private int minIdle;  private ResourcePoolConfig(Builder builder) &#123;    this.name = builder.name;    this.maxTotal = builder.maxTotal;    this.maxIdle = builder.maxIdle;    this.minIdle = builder.minIdle;  &#125;  //...省略getter方法...  //我们将Builder类设计成了ResourcePoolConfig的内部类。  //我们也可以将Builder类设计成独立的非内部类ResourcePoolConfigBuilder。  public static class Builder &#123;    private static final int DEFAULT_MAX_TOTAL = 8;    private static final int DEFAULT_MAX_IDLE = 8;    private static final int DEFAULT_MIN_IDLE = 0;    private String name;    private int maxTotal = DEFAULT_MAX_TOTAL;    private int maxIdle = DEFAULT_MAX_IDLE;    private int minIdle = DEFAULT_MIN_IDLE;    public ResourcePoolConfig build() &#123;      // 校验逻辑放到这里来做，包括必填项校验、依赖关系校验、约束条件校验等      if (StringUtils.isBlank(name)) &#123;        throw new IllegalArgumentException(&quot;...&quot;);      &#125;      if (maxIdle &gt; maxTotal) &#123;        throw new IllegalArgumentException(&quot;...&quot;);      &#125;      if (minIdle &gt; maxTotal || minIdle &gt; maxIdle) &#123;        throw new IllegalArgumentException(&quot;...&quot;);      &#125;      return new ResourcePoolConfig(this);    &#125;    public Builder setName(String name) &#123;      if (StringUtils.isBlank(name)) &#123;        throw new IllegalArgumentException(&quot;...&quot;);      &#125;      this.name = name;      return this;    &#125;    public Builder setMaxTotal(int maxTotal) &#123;      if (maxTotal &lt;= 0) &#123;        throw new IllegalArgumentException(&quot;...&quot;);      &#125;      this.maxTotal = maxTotal;      return this;    &#125;    public Builder setMaxIdle(int maxIdle) &#123;      if (maxIdle &lt; 0) &#123;        throw new IllegalArgumentException(&quot;...&quot;);      &#125;      this.maxIdle = maxIdle;      return this;    &#125;    public Builder setMinIdle(int minIdle) &#123;      if (minIdle &lt; 0) &#123;        throw new IllegalArgumentException(&quot;...&quot;);      &#125;      this.minIdle = minIdle;      return this;    &#125;  &#125;&#125;// 这段代码会抛出IllegalArgumentException，因为minIdle&gt;maxIdleResourcePoolConfig config = new ResourcePoolConfig.Builder()        .setName(&quot;dbconnectionpool&quot;)        .setMaxTotal(16)        .setMaxIdle(10)        .setMinIdle(12)        .build();</code></pre><h4 id="原型模式"><a href="#原型模式" class="headerlink" title="原型模式"></a>原型模式</h4><p>如果对象的创建成本比较大，而同一个类的不同对象之间差别不大（大部分字段都相同），在这种情况下，我们可以利用对已有对象（原型）进行复制（或者叫拷贝）的方式，来创建新对象，以达到节省创建时间的目的。这种基于原型来创建对象的方式就叫作原型设计模式，简称原型模式。</p><p>原型模式有两种实现方法，深拷贝和浅拷贝。浅拷贝只会复制对象中基本数据类型数据和引用对象的内存地址，不会递归地复制引用对象，以及引用对象的引用对象……而深拷贝得到的是一份完完全全独立的对象。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;单例模式&quot;&gt;&lt;a href=&quot;#单例模式&quot; class=&quot;headerlink&quot; title=&quot;单例模式&quot;&gt;&lt;/a&gt;单例模式&lt;/h4&gt;&lt;p&gt;只允许类创建一个实例&lt;/p&gt;
&lt;h5 id=&quot;创建方式&quot;&gt;&lt;a href=&quot;#创建方式&quot; class=&quot;headerlink</summary>
      
    
    
    
    <category term="design_pattern" scheme="http://soda1.github.io/categories/design-pattern/"/>
    
    
  </entry>
  
  <entry>
    <title>code quality checkList</title>
    <link href="http://soda1.github.io/2022/12/12/design%20pattern/checkList/"/>
    <id>http://soda1.github.io/2022/12/12/design%20pattern/checkList/</id>
    <published>2022-12-12T22:47:39.000Z</published>
    <updated>2022-12-12T22:55:15.000Z</updated>
    
    <content type="html"><![CDATA[<h5 id="常规checkList"><a href="#常规checkList" class="headerlink" title="常规checkList"></a>常规checkList</h5><ul><li>目录设置是否合理、模块划分是否清晰、代码结构是否满足“高内聚、松耦合”？</li><li>是否遵循经典的设计原则和设计思想（SOLID、DRY、KISS、YAGNI、LOD 等）？</li><li>设计模式是否应用得当？是否有过度设计？</li><li>代码是否容易扩展？如果要添加新功能，是否容易实现？</li><li>代码是否可以复用？是否可以复用已有的项目代码或类库？是否有重复造轮子？</li><li>代码是否容易测试？单元测试是否全面覆盖了各种正常和异常的情况？</li><li>代码是否易读？是否符合编码规范（比如命名和注释是否恰当、代码风格是否一致等）？</li></ul><h5 id="业务需求checkList"><a href="#业务需求checkList" class="headerlink" title="业务需求checkList"></a>业务需求checkList</h5><ul><li>代码是否实现了预期的业务需求？</li><li>逻辑是否正确？是否处理了各种异常情况？</li><li>日志打印是否得当？是否方便 debug 排查问题？</li><li>接口是否易用？是否支持幂等、事务等？</li><li>代码是否存在并发问题？是否线程安全？</li><li>性能是否有优化空间，比如，SQL、算法是否可以优化？</li><li>是否有安全漏洞？比如输入输出校验是否全面？</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h5 id=&quot;常规checkList&quot;&gt;&lt;a href=&quot;#常规checkList&quot; class=&quot;headerlink&quot; title=&quot;常规checkList&quot;&gt;&lt;/a&gt;常规checkList&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;目录设置是否合理、模块划分是否清晰、代码结构是否满足“高</summary>
      
    
    
    
    <category term="design_pattern" scheme="http://soda1.github.io/categories/design-pattern/"/>
    
    
  </entry>
  
  <entry>
    <title>refactoring</title>
    <link href="http://soda1.github.io/2022/12/11/design%20pattern/refactoring/"/>
    <id>http://soda1.github.io/2022/12/11/design%20pattern/refactoring/</id>
    <published>2022-12-11T23:07:49.000Z</published>
    <updated>2023-01-03T23:11:45.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="重构规模"><a href="#重构规模" class="headerlink" title="重构规模"></a>重构规模</h4><h5 id="大规模重构"><a href="#大规模重构" class="headerlink" title="大规模重构"></a>大规模重构</h5><ul><li>重构手段有：分层、模块化、解耦、抽象可复用组件</li><li>改动大，易引入bug，重构时需要有完善的计划</li></ul><h5 id="小规模重构"><a href="#小规模重构" class="headerlink" title="小规模重构"></a>小规模重构</h5><ul><li>主要指代码细节的重构，针对类，函数，变量的代码级别重构。一般根据编程规范作为指导即可</li><li>改动小且比较集中，风险小。如果觉得需要重构就可以直接着手</li></ul><h4 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h4><ol><li>它是保证代码重构时不出错的有效保证</li><li>编写单元测试能帮你发现设计上的问题，如果一段代码很难去编写单元测试，往往会意味着代码的设计不够合理，比如说使用了静态方法、没有依赖注入等等，进而促使你去重构代码</li><li>单元测试可以帮助你快速熟悉代码</li><li>单元测试是TDD可落地执行的改进方案</li></ol><h5 id="常见的anti-patterns"><a href="#常见的anti-patterns" class="headerlink" title="常见的anti-patterns"></a>常见的anti-patterns</h5><ol><li>未决行为（代码输出具有随机性）</li><li>全局变量（滥用全局变量会使测试变得困难，每个测试用例可能都要重置全局变量）</li><li>静态方法（静态方法比较难mock，比如依赖外部资源的静态函数）</li><li>复杂继承（如果一个父类需要mock某个依赖对象才能进行单元测试，那么所有子类在编写单元测试的时候都要去mock这个对象）</li><li>高耦合代码（一个类依赖很多外部对象，可能也需要mock这些外部对象，这本身设计不合理）</li></ol><h4 id="解耦技巧"><a href="#解耦技巧" class="headerlink" title="解耦技巧"></a>解耦技巧</h4><ol><li><p>封装与抽象</p><p>当功能改动时，上层依赖不需要改动</p></li><li><p>引用中间层</p><p>通过中间层来简化依赖关系</p><p><img src="https://raw.githubusercontent.com/soda1/img/main/20221211234625.png" alt="image-20221211234618738" loading="lazy"></p></li><li><p>模块化</p><p>构建复杂系统的主要手段，相关人员只要专注于自己负责的模块即可</p></li><li><p>利用设计思想和原则</p><ul><li>单一职责原则</li><li>基于接口而非实现编程</li><li>依赖注入</li><li>多用组合少用继承</li><li>迪米特法则</li></ul></li></ol><h4 id="编程规范"><a href="#编程规范" class="headerlink" title="编程规范"></a>编程规范</h4><ol><li><p>命名</p><ul><li>命名的关键是能准确达意。对于不同作用域的命名，我们可以适当地选择不同的长度。作用域小的变量（比如临时变量），可以适当地选择短一些的命名方式。除此之外，命名中也可以使用一些耳熟能详的缩写。</li><li>我们可以借助类的信息来简化属性、函数的命名，利用函数的信息来简化函数参数的命名。</li><li>命名要可读、可搜索。不要使用生僻的、不好读的英文单词来命名。除此之外，命名要符合项目的统一规范，不要用些反直觉的命名。</li><li>接口有两种命名方式：一种是在接口中带前缀“I”；另一种是在接口的实现类中带后缀“Impl”。对于抽象类的命名，也有两种方式，一种是带上前缀“Abstract”，一种是不带前缀。这两种命名方式都可以，关键是要在项目中统一。</li></ul></li><li><p>注释</p><ul><li>注释的目的就是让代码更容易看懂。只要符合这个要求的内容，你就可以将它写到注释里。总结一下，注释的内容主要包含这样三个方面：做什么、为什么、怎么做。对于一些复杂的类和接口，我们可能还需要写明“如何用”。</li><li>注释本身有一定的维护成本，所以并非越多越好。类和函数一定要写注释，而且要写得尽可能全面、详细，而函数内部的注释要相对少一些，一般都是靠好的命名、提炼函数、解释性变量、总结性注释来提高代码可读性。</li></ul></li><li><p>函数的代码不要超过一屏幕大小，类比较难确定</p></li><li><p>一行代码不要超过IDE显示宽度</p></li><li><p>善用空行分割单元块</p></li><li><p>把代码分割成更小的单元块</p></li><li><p>函数参数不要过多，大于五个就有点多</p><ul><li>考虑函数职责是否单一，能否拆成多个函数的方式来减少参数</li><li>封装成对象</li></ul></li><li><p>勿用函数参数来控制逻辑，尽量拆成多个函数</p></li><li><p>函数设计要职责单一</p></li><li><p>移除过深嵌套层次</p><ul><li>去掉多余if/else语句</li><li>使用关键字continue，break，return提前退出嵌套</li><li>调整执行顺序，判断逻辑（如判空）放在前面</li><li>将部分嵌套逻辑封装成函数</li></ul></li><li><p>学会使用解释性变量</p><ul><li><p>常量代替魔法数字</p></li><li><p>使用解释性变量来解释负责表达式</p><pre><code class="java">boolean isSummer = date.after(SUMMER_START)&amp;&amp;date.before(SUMMER_END);</code></pre></li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;重构规模&quot;&gt;&lt;a href=&quot;#重构规模&quot; class=&quot;headerlink&quot; title=&quot;重构规模&quot;&gt;&lt;/a&gt;重构规模&lt;/h4&gt;&lt;h5 id=&quot;大规模重构&quot;&gt;&lt;a href=&quot;#大规模重构&quot; class=&quot;headerlink&quot; title=&quot;大规模重构&quot;&gt;</summary>
      
    
    
    
    <category term="design_pattern" scheme="http://soda1.github.io/categories/design-pattern/"/>
    
    
  </entry>
  
  <entry>
    <title>design principal</title>
    <link href="http://soda1.github.io/2022/11/26/design%20pattern/design%20principal/"/>
    <id>http://soda1.github.io/2022/11/26/design%20pattern/design%20principal/</id>
    <published>2022-11-26T20:32:33.000Z</published>
    <updated>2022-12-11T23:08:50.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="SOLID原则"><a href="#SOLID原则" class="headerlink" title="SOLID原则"></a>SOLID原则</h4><p>SOLID原则是由5个原则的首字母组成的原则，由Robert C.Martin提出来的五大原则。 <strong>SOLID</strong> is a <a href="https://en.wikipedia.org/wiki/Mnemonic">mnemonic</a> <a href="https://en.wikipedia.org/wiki/Acronym">acronym</a> for five design principles intended to make <a href="https://en.wikipedia.org/wiki/Object-oriented">object-oriented</a> designs more understandable, flexible, and <a href="https://en.wikipedia.org/wiki/Software_maintenance">maintainable</a>. </p><ol><li><p>The <strong>S</strong>ingle Responsibility Principle  SRP单一职责原则</p><blockquote><p>A module should be responsible to one, and only one, actor</p></blockquote><p>一个类只负责完成一个职责或者功能。不要设计大而全的类，要设计粒度小、功能单一的 类。单一职责原则是为了实现代码高内聚、低耦合，提高代码的复用性、可读性、可维护 性。</p><p>一个类是否单一要看具体的业务需求，随着业务的发展当类变得臃肿的就要考虑进行拆分，设计更小粒度的类。</p><p>下列情况可能会说明类职责不够单一</p><ul><li>类中的代码行数、函数或者属性过多；</li><li> 类依赖的其他类过多，或者依赖类的其他类过多；</li><li> 私有方法过多； 比较难给类起一个合适的名字； </li><li>类中大量的方法都是集中操作类中的某几个属性。</li></ul></li><li><p>The <strong>O</strong>pen-Closed Principle  OCP开闭原则</p><blockquote><p>Software entities … should be open for extension, but closed for modification</p></blockquote><blockquote><p>A module will be said to be open if it is still available for extension. For example, it should be possible to add fields to the data structures it contains, or new elements to the set of functions it performs.</p><p>A module will be said to be closed if [it] is available for use by other modules. This assumes that the module has been given a well-defined, stable description (the interface in the sense of information hiding).</p></blockquote><p>只要新增的功能涉及修改的地方没有破坏原有的代码的功能运行、功能测试，那它就是符合OCP的</p><blockquote><p>对拓展开放是为了应对变化(需求)，对修改关闭是为了保证已有代码的稳定性；最终结果是 为了让系统更有弹性！</p></blockquote></li><li><p>The <strong>L</strong>iskov Substitution Principle LSP里氏替换原则</p><blockquote><p>Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it.</p></blockquote><p>LSP和多态有点像，但侧重点不一样。多态着重的是父类引用可以使用子类对象，LSP也是通过多态这一特性来使用子对象。但它强调的是功能上的一致，比如父类的function中没有定义要抛出的异常，子类实现此function时如果抛出了未定义的异常，那就是违背LSP</p><p>违背LSP的一些例子</p><ul><li>子类违背父类声明要实现的功能</li><li>子类违背父类对输入、输出、异常的约定</li><li>子类违背父类注释中所罗列的任何特殊说明</li></ul></li><li><p>The <strong>I</strong>nterface Segregation Principle ISP接口隔离原则</p><blockquote><p>Clients should not be forced to depend upon interfaces that they do not use.</p></blockquote><blockquote><p>ISP can be seen as similar to SRP for interfaces; but it is more than that. ISP generalizes into: “Don’t depend on more than you need.” SRP generalizes to “Gather together things that change for the same reasons and at the same times.”</p><p>Imagine a stack class with both push and pop. Imagine a client that only pushes. If that client depends upon the stack interface, it depends upon pop, which it does not need. SRP would not separate push from pop; ISP would.</p></blockquote><p>ISP和RSP有点像，SRP侧重于module，职责是否保持单一化。ISP侧重调用者是否需要接口所有功能。SRP可以说是ISP的冗余。</p></li><li><p>The <strong>D</strong>ependency Inversion Principle  DIP依赖倒置原则</p><blockquote><ol><li>High-level modules should not import anything from low-level modules. Both should depend on abstractions (e.g., interfaces).</li><li>Abstractions should not depend on details. Details (concrete implementations) should depend on abstractions.</li></ol></blockquote><p>上层服务应该依赖于底层接口，且底层接口不应该依赖于具体的实现（即通过构造器之类的方式注入到上层服务中）</p></li></ol><h4 id="KISS"><a href="#KISS" class="headerlink" title="KISS"></a>KISS</h4><blockquote><p>keep it simple and stupid</p></blockquote><p>写的功能代码尽可能的简单，不要用一些增加理解困难度的trick</p><ul><li>不要使用同事可能不懂的技术来实现代码。比如前面例子中的正则表达式，还有一些编程语言中过于高级的语法等。</li><li>不要重复造轮子，要善于使用已经有的工具类库。经验证明，自己去实现这些类库，出 bug 的概率会更高，维护的成本也比较高。</li><li>不要过度优化。不要过度使用一些奇技淫巧（比如，位运算代替算术运算、复杂的条件语句代替 if-else、使用一些过于底层的函数等）来优化代码，牺牲代码的可读性。</li></ul><h4 id="YAGNI"><a href="#YAGNI" class="headerlink" title="YAGNI"></a>YAGNI</h4><blockquote><p>You aren’t gonna need it</p></blockquote><p>不要过度设计，当然接口扩展这些是可以做的</p><h4 id="DRY"><a href="#DRY" class="headerlink" title="DRY"></a>DRY</h4><blockquote><p>Don’t repeat yourself</p></blockquote><p>不要写重复代码</p><p>有三种典型情况</p><ul><li><p>逻辑重复</p><p>若语义不重复不违反DRY</p></li><li><p>功能语义重复</p><p>违反DRY</p></li><li><p>代码执行重复</p><p>在执行中多次执行相同代码（函数）违反DRY</p></li></ul><p>是否违法DRY，主要看语义</p><h4 id="LOD"><a href="#LOD" class="headerlink" title="LOD"></a>LOD</h4><blockquote><p><strong>Law of Demeter</strong> or <strong>principle of least knowledge</strong></p><ul><li>Each unit should have only limited knowledge about other units: only units “closely” related to the current unit.</li><li>Each unit should only talk to its friends; don’t talk to strangers.</li><li>Only talk to your immediate friends.</li></ul></blockquote><p>不该有直接依赖关系的类之间，不要有依赖；有依赖关系的类之间，尽量只依赖必要的接口。迪米特法则是希望减少类之间的耦合，让类越独立越好。每个类都应该少了解系统的其他部分。一旦发生变化，需要了解这一变化的类就会比较少。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;SOLID原则&quot;&gt;&lt;a href=&quot;#SOLID原则&quot; class=&quot;headerlink&quot; title=&quot;SOLID原则&quot;&gt;&lt;/a&gt;SOLID原则&lt;/h4&gt;&lt;p&gt;SOLID原则是由5个原则的首字母组成的原则，由Robert C.Martin提出来的五大原则。 &lt;</summary>
      
    
    
    
    <category term="design_pattern" scheme="http://soda1.github.io/categories/design-pattern/"/>
    
    
  </entry>
  
</feed>
